{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b359750-81d1-48c1-a863-296635114ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Initialization Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5ce6c-55cb-45b7-9ad1-370ee54bf5c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install a Spark docker using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ac48-b14e-4e01-8290-b9799ba6e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker pull bitnami/spark && \\\n",
    "docker network create spark_network && \\\n",
    "docker run -d --name spark --network=spark_network -e SPARK_MODE=master bitnami/spark\n",
    "! ln -s /opt/conda/lib/libtinfo.so /opt/conda/lib/libtinfor.so.6\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659dd20-a9ab-4008-8bce-a5ff5acf5690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb46e-7eef-4af7-bd41-587e716e3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "def install(package):\n",
    "    if hasattr(pip, 'main'):\n",
    "        pip.main(['install', package])\n",
    "    else:\n",
    "        pip._internal.main(['install', package])\n",
    "\n",
    "install('pyspark')\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140ae18-4293-4560-91d6-4324e41fb0b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialize the Spark context variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6573258c-97d5-4282-9278-cfe9ad82a186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing pyspark\n",
      "pyspark initialized\n",
      "<SparkContext master=local[*] appName=Notebook> <pyspark.sql.session.SparkSession object at 0x7fbc44c16b90>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def initspark(appname = \"Notebook\", servername = \"local[*]\"):\n",
    "    print ('initializing pyspark')\n",
    "    conf = SparkConf().setAppName(appname).setMaster(servername)\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession.builder.appName(appname).enableHiveSupport().getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "    print ('pyspark initialized')\n",
    "    return sc, spark, conf\n",
    "\n",
    "sc, spark, conf = initspark()\n",
    "print(sc, spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbca6a8-f8cc-45ac-8a62-0d14bfb665d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialize helper functions to run Java inside cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "79d334c3-e064-4241-aa70-26d939b3e166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/get-started/try-apache-beam-java.ipynb#scrollTo=CgTXBdTsBn1F\n",
    "# Run and print a shell command.\n",
    "def run(cmd, progress = True, verbose = False):\n",
    "  if progress:\n",
    "      print('>> {}'.format(cmd))\n",
    "    \n",
    "  if verbose:\n",
    "      !{cmd}  # This is magic to run 'cmd' in the shell.\n",
    "      print('')\n",
    "  else:\n",
    "      ! {cmd} > /dev/null 2>&1\n",
    "\n",
    "import os\n",
    "\n",
    "# Download the gradle source.\n",
    "gradle_version = 'gradle-5.0'\n",
    "gradle_path = f\"/opt/{gradle_version}\"\n",
    "if not os.path.exists(gradle_path):\n",
    "  run(f\"wget -q -nc -O gradle.zip https://services.gradle.org/distributions/{gradle_version}-bin.zip\")\n",
    "  run('unzip -q -d /opt gradle.zip')\n",
    "  run('rm -f gradle.zip')\n",
    "\n",
    "# We're choosing to use the absolute path instead of adding it to the $PATH environment variable.\n",
    "def gradle(args):\n",
    "  run(f\"{gradle_path}/bin/gradle --console=plain {args}\")\n",
    "\n",
    "gradle('-v')\n",
    "print('Done')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716a7d4-28ea-40e7-90db-3e762b7dbcf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Definition for %%java Python magic cell function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8a97925b-df54-4700-bb8b-d4a3e2305b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_magic, register_cell_magic, register_line_cell_magic\n",
    "@register_cell_magic\n",
    "def java(line, cell):\n",
    "    \"\"\"\n",
    "    Written by Joseph Gagliardo Jr.\n",
    "    joegagliardo@gmail.com\n",
    "    2021-12-22\n",
    "    \"\"\"\n",
    "    text = \"\"\"\n",
    "plugins {\n",
    "  // id 'idea'     // Uncomment for IntelliJ IDE\n",
    "  // id 'eclipse'  // Uncomment for Eclipse IDE\n",
    "\n",
    "  // Apply java plugin and make it a runnable application.\n",
    "  id 'java'\n",
    "  id 'application'\n",
    "\n",
    "  // 'shadow' allows us to embed all the dependencies into a fat jar.\n",
    "  id 'com.github.johnrengelman.shadow' version '4.0.3'\n",
    "}\n",
    "\n",
    "// This is the path of the main class, stored within ./src/main/java/\n",
    "mainClassName = 'samples.quickstart.{class_name}'\n",
    "\n",
    "// Declare the sources from which to fetch dependencies.\n",
    "repositories {\n",
    "  mavenCentral()\n",
    "}\n",
    "\n",
    "// Java version compatibility.\n",
    "sourceCompatibility = 1.8\n",
    "targetCompatibility = 1.8\n",
    "\n",
    "// Use the latest Apache Beam major version 2.\n",
    "// You can also lock into a minor version like '2.9.+'.\n",
    "ext.apacheBeamVersion = '2.+'\n",
    "\n",
    "// Declare the dependencies of the project.\n",
    "dependencies {\n",
    "  shadow \"org.apache.beam:beam-sdks-java-core:$apacheBeamVersion\"\n",
    "\n",
    "  runtime \"org.apache.beam:beam-runners-direct-java:$apacheBeamVersion\"\n",
    "  runtime \"org.slf4j:slf4j-api:1.+\"\n",
    "  runtime \"org.slf4j:slf4j-jdk14:1.+\"\n",
    "\n",
    "  testCompile \"junit:junit:4.+\"\n",
    "}\n",
    "\n",
    "// Configure 'shadowJar' instead of 'jar' to set up the fat jar.\n",
    "shadowJar {\n",
    "  baseName = '{class_name}' // Name of the fat jar file.\n",
    "  classifier = null       // Set to null, otherwise 'shadow' appends a '-all' to the jar file name.\n",
    "  manifest {\n",
    "    attributes('Main-Class': mainClassName)  // Specify where the main class resides.\n",
    "  }\n",
    "}\n",
    "\"\"\"   \n",
    "    start = cell.find('class ')\n",
    "    end = cell.find(' {')\n",
    "    class_name = cell[start+6:end]\n",
    "    progress = 'noprogress' not in line.lower()\n",
    "    verbose = 'verbose' in line.lower()\n",
    "    output = 'nooutput' not in line.lower()\n",
    "\n",
    "    # if len(line) == 0:\n",
    "    #     start = cell.find('class ')\n",
    "    #     end = cell.find(' {')\n",
    "    #     class_name = cell[start+6:end]\n",
    "    # else:\n",
    "    #     class_name = line\n",
    "        \n",
    "    \n",
    "    run('rm src/main/java/samples/quickstart/*.java')\n",
    "    run('rm build/libs/*.jar')\n",
    "    run('rm -rf /tmp/outputs*', progress = progress, verbose = verbose)\n",
    "\n",
    "    with open('build.gradle', 'w') as f:\n",
    "        f.write(text.replace('{class_name}', class_name))\n",
    "\n",
    "    with open(f'src/main/java/samples/quickstart/{class_name}.java', 'w') as f:\n",
    "        f.write(cell)\n",
    "        \n",
    "    # Build the project.\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain build\", progress = progress, verbose = verbose)\n",
    "    run('ls -lh build/libs/', progress = progress, verbose = verbose)\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain runShadow\", progress = progress, verbose = verbose)\n",
    "    # run('head -n 20 /tmp/outputs*')\n",
    "    if output:\n",
    "        run('cat /tmp/outputs*', progress = False, verbose = True)\n",
    "\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf532-1859-4134-a64f-63b6f14f4268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Create allows you to upload data into a PCollection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f8b59-343b-45c9-b02d-7399bceefbe0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1397c54-3ff7-4188-bc9e-c72bef0d2670",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Non Beam example of applying a map function to a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ceb0dd11-7c70-4a35-bc61-51d36bcfaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Two', 'Three', 'Four']\n"
     ]
    }
   ],
   "source": [
    "x = ['one', 'two', 'three', 'four']\n",
    "print(list(map(str.title, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb1aad-7fe0-4b99-96f4-b30fbaae23ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation, turn the local collection into a PCollection and apply a Map PTransform on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "faedc12b-27d2-4098-85f0-feba2f9e14f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n",
      "lines =  PCollection[[230]: Map(print).None]\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(str.title)\n",
    "          | beam.Map(print)\n",
    "    )\n",
    "\n",
    "# lines is a PCollection object\n",
    "print('lines = ', lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c8ecc-a678-48eb-9ae8-7fd3e34b8a6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a lambda instead of a built in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8bd9b54f-3a72-4688-a5d1-545077e6b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(lambda x : x.title())\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dfeee-d660-47fb-92f7-7a0c3bcbb302",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4bf4cad9-4ed9-4c26-8894-e7d84eff8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def title(x):\n",
    "    return x.title()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(title)\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f09af7-2678-4b0c-879e-c567625a4a83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Python the pipe `|` is actually just an operator overload to call the apply method of the pipeline. You would never do this in python, but it helps to understand what is going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "292e7a3d-99fc-4904-a1cd-baf93d088b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = ((p | beam.Create(['one', 'two', 'three', 'four']))\n",
    "             .apply(beam.Map(str.title)) \n",
    "             .apply(beam.Map(print))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057071-63e3-4414-820d-71e07ed0959d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Spark equivalent would be to pload a local Python list into a Spark RDD and do a simple transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "67b110e0-45a0-476b-a2ca-d33cecaec241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three', 'four']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = ( sc.parallelize(['one', 'two', 'three', 'four'])\n",
    "        \n",
    "#           .map(str.title)\n",
    "       )\n",
    "rdd1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebfb43-8dd1-491e-9422-350ecda44d1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33b715-0a74-4b46-8736-7798c51b313a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8420314f-13dd-410f-90a8-569c9f3770ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "THREE\n",
      "ONE\n",
      "FOUR\n",
      "TWO\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create1 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.into(TypeDescriptors.strings()).via((String line) -> line.toUpperCase()));\n",
    "        lines.apply(TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db7b6-c42d-4268-847c-24a9c39df7e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using SimpleFunction instead of lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7ff75092-0480-4784-afba-9616e9e60d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 9 executed\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "total 43M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 18:32 Create2.jar\n",
      "-rw-r--r-- 1 root root 2.1K Dec 23 18:32 Dataflowclass1.jar\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 01cfd49a-ef0e-4ec7-aa6e-47d3a0f215f2 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 24c589c6-1d31-411c-b84e-aca239c54630 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer fa33e597-1212-4c6a-8648-7a3b7882239e for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/fa33e597-1212-4c6a-8648-7a3b7882239e\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/24c589c6-1d31-411c-b84e-aca239c54630\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/01cfd49a-ef0e-4ec7-aa6e-47d3a0f215f2\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Creating 1 empty output shards in addition to 3 written for destination null.\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Opening empty writer 527fe827-d34b-47f4-874d-22be74dd6565 for destination null\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/527fe827-d34b-47f4-874d-22be74dd6565\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/fa33e597-1212-4c6a-8648-7a3b7882239e, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00003-of-00004\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/01cfd49a-ef0e-4ec7-aa6e-47d3a0f215f2, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00001-of-00004\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/24c589c6-1d31-411c-b84e-aca239c54630, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00002-of-00004\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/527fe827-d34b-47f4-874d-22be74dd6565, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00000-of-00004\n",
      "Dec 23, 2021 6:32:30 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/tmp/.temp-beam-70cf55b6-58e8-4f29-957a-4760e88b12d0/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      "TWO\n",
      "FOUR\n",
      "ONE\n",
      "THREE\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create2 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return line.toUpperCase();\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27aee-6b1c-44a5-815d-31d039c24475",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Java simple transformation using SimpleFunction to wrap a User Defined Function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "da5c178e-2cfa-4316-95de-5779b243f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "FOUR\n",
      "TWO\n",
      "THREE\n",
      "ONE\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create3 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return upper(line);\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    public static String upper(String line) {\n",
    "        return line.toUpperCase();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864aa22-07d5-493c-830c-fa8ec01fca33",
   "metadata": {},
   "source": [
    "## Python read from CSV and use Map with lambda.\n",
    "### Also it's a good idea to name the steps so it's easier to debug and monitor them later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931beffe-4cf4-48e4-a28d-8a2dfaed62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. ReadFromText allows you to read a text file into a PCollection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db17f3-ea3a-4418-b12e-5b859d1e9856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab382f85-16e9-4544-a56b-06c6d4edc7b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### It's a good idea to start naming the steps for debugging and monitoring later. Names must be unique in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "53066990-43fc-42c0-9545-ddf723145fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'EASTERN')\n",
      "(2, 'WESTERN')\n",
      "(3, 'NORTHERN')\n",
      "(4, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "! rm /tmp/outputs*\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.Map(lambda x : x.split(','))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "          | 'Write' >> WriteToText('/tmp/outputs')\n",
    "#          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "    #p.run() # implicit in Python when using with block\n",
    "\n",
    "! cat /tmp/outputs*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88479c-60c3-48c3-b8c1-3e8113f0d39a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Read from CSV and use ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "94887a8a-f945-414f-bfaa-2e72fa1aa746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Eastern')\n",
      "(2, 'Western')\n",
      "(3, 'Northern')\n",
      "(4, 'Southern')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionParseTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "#        yield (int(regionid), regionname.upper()) # Include a transformation instead of doing it as a separate step\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.ParDo(RegionParseTuple())\n",
    "          #| 'Write' >> WriteToText('regions.out')\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3fd79-61c1-4d9f-acf1-5ee7af3ff832",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d05cc4-e81e-44d7-adad-d38ee19848c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read from CSV and use Map with lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "28492eea-c43a-43ab-aa7f-ceca3f199a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "3,NORTHERN\n",
      "1,EASTERN\n",
      "4,SOUTHERN\n",
      "2,WESTERN\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "\n",
    "public class ReadRegions {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", MapElements.into(TypeDescriptors.strings()).via((String element) -> element.toUpperCase()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd1da-0fed-43c9-8ab1-e1b73cc9534f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ParDo Example using anonymous class inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14327a97-f8cd-489b-87eb-82ad962f701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 8 executed, 1 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 212M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 4.0K Dec 23 14:35 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:35 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove 'outputs/*': No such file or directory\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern regions.csv matched 1 files with total size 42\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern regions.csv into bundles of size 10 took 1 ms and produced 1 files and 5 bundles\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 5ef63099-385e-4416-9488-b96a7f4d8884 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 5746cfc9-a691-4891-8f70-6eadea28a563 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer ac71c854-9354-4516-82cd-a5a5d6a70996 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5746cfc9-a691-4891-8f70-6eadea28a563\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/ac71c854-9354-4516-82cd-a5a5d6a70996\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5ef63099-385e-4416-9488-b96a7f4d8884\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/ac71c854-9354-4516-82cd-a5a5d6a70996, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5746cfc9-a691-4891-8f70-6eadea28a563, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5ef63099-385e-4416-9488-b96a7f4d8884, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2,Western*\n",
      "4,Southern*\n",
      "3,Northern*\n",
      "1,Eastern*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class Read1 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new DoFn<String, String>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    String element = c.element();\n",
    "                    // String[] elements = element.split(\",\");\n",
    "                    c.output(element + \"*\");\n",
    "                }\n",
    "            }));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc4515-7a9b-40f9-99cf-c456065c3e11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ParDo using a defined class instead of an anonynous class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb8543a5-9d2e-4a6e-81f4-5ae59aedcf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 8 executed, 1 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 254M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 5.8K Dec 23 14:46 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:35 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:47 Read2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:47:17 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern regions.csv matched 1 files with total size 42\n",
      "Dec 23, 2021 2:47:17 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern regions.csv into bundles of size 10 took 1 ms and produced 1 files and 5 bundles\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer bb9150b6-c719-478e-82e2-c67841a4cc12 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 29a24e0c-8b5c-47d9-9ab3-f066b93db8f7 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 67d205ba-d307-4a14-a632-5d2e909c86f6 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/bb9150b6-c719-478e-82e2-c67841a4cc12\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/67d205ba-d307-4a14-a632-5d2e909c86f6\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/29a24e0c-8b5c-47d9-9ab3-f066b93db8f7\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Creating 1 empty output shards in addition to 3 written for destination null.\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Opening empty writer e3ad9c04-a2a9-49bf-a5f9-7316bd928039 for destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/e3ad9c04-a2a9-49bf-a5f9-7316bd928039\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/67d205ba-d307-4a14-a632-5d2e909c86f6, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/bb9150b6-c719-478e-82e2-c67841a4cc12, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00003-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/29a24e0c-8b5c-47d9-9ab3-f066b93db8f7, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/e3ad9c04-a2a9-49bf-a5f9-7316bd928039, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/].\n",
      "\n",
      "BUILD SUCCESSFUL in 6s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "3,Northern*\n",
      "2,Western*\n",
      "4,Southern*\n",
      "1,Eastern*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class Read2 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new AddStar()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    static class AddStar extends DoFn<String, String> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String line, OutputReceiver<String> out) {\n",
    "            out.output(line + \"*\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cae856-d38b-4ce9-a4c1-511284e1f9bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Parse into a model class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4b34a-2b4a-4f8f-aa9c-af369f7ef9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebb6b4-3c55-4b79-a0d8-4d3c017162c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a model based on typing.NamedTuple so you can use properties instead of keys and use the Filter PTransform with lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "cc0dd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter 1' >> beam.Filter(lambda x : x.regionid % 2 == 0)\n",
    "          | 'Filter 2' >> beam.Filter(lambda x : x.territoryname.startswith('S'))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230451d-cfb3-450f-82b6-e5dd24e6e2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use Filter with a UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "07089b39-7ccf-42cf-830b-3189ab269566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "def startsWithS(element):\n",
    "    return element.territoryname.startswith('S')\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.Filter(startsWithS)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac3ac5-d61b-496d-bf95-2801b014b28e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use a ParDo class to accomplish filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "54691011-9bfd-49d9-8992-ff1333c65824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "class StartsWithSFilter(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if element.territoryname.startswith('S'):\n",
    "            yield element\n",
    "            \n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.ParDo(StartsWithSFilter())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39807dbe-b99a-4767-be21-16b38ff287f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Put the parsing and filtering all into one ParDo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a2091357-5550-42fb-8810-3e5fc8d2cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        if territoryname.startswith('S'):\n",
    "            yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb0592-e4b0-4204-b4f0-775e75d8f02c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e66252-cdcd-411c-866e-44857a6b4379",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using a Pardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c7e1e99c-eece-43f4-9b8e-2ba9df28d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", ParDo.of(new FilterTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378c125-c36c-4ac0-9443-35f54539258a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using and anonymous class to create the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7292cee7-d525-44b6-a9db-36b5f3acf839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", Filter.by(new SerializableFunction<Territory, Boolean>() {\n",
    "                @Override\n",
    "                public Boolean apply(Territory t) {\n",
    "                    return t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\");\n",
    "                }\n",
    "            }))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2fc88-b027-42bf-9136-c02d6583a04c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9339e563-880b-4fae-9cc6-3e8ba50d85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "(territoryID = 48075, territoryName = Southfield, regionID = 3)\n",
      "(territoryID = 90405, territoryName = Santa Monica, regionID = 2)\n",
      "(territoryID = 94105, territoryName = San Francisco, regionID = 2)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 85251, territoryName = Scottsdale, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (territoryName.startsWith(\"S\")) {\n",
    "                    c.output(new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5c5a3-327e-4279-af35-bcf57e7ab9f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5. Create multiple outputs from a single read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc9883-ba3b-4b67-ad1c-05b281ef9474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edcd4b-aac7-412a-a728-d772fd625f56",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Send the same data down multiple paths, such as to group it on two different keys with one read from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4cfb9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower\n",
      "(1730, 'bedford', 1)\n",
      "(1581, 'westboro', 1)\n",
      "(1833, 'georgetow', 1)\n",
      "(2116, 'boston', 1)\n",
      "(2139, 'cambridge', 1)\n",
      "(2184, 'braintree', 1)\n",
      "(2903, 'providence', 1)\n",
      "(3049, 'hollis', 3)\n",
      "(3801, 'portsmouth', 3)\n",
      "(6897, 'wilton', 1)\n",
      "(7960, 'morristown', 1)\n",
      "(8837, 'edison', 1)\n",
      "(10019, 'new york', 1)\n",
      "(10038, 'new york', 1)\n",
      "(11747, 'mellvile', 1)\n",
      "(14450, 'fairport', 1)\n",
      "(19428, 'philadelphia', 3)\n",
      "(19713, 'neward', 1)\n",
      "(20852, 'rockville', 1)\n",
      "(27403, 'greensboro', 1)\n",
      "(27511, 'cary', 1)\n",
      "(29202, 'columbia', 4)\n",
      "(30346, 'atlanta', 4)\n",
      "(31406, 'savannah', 4)\n",
      "(32859, 'orlando', 4)\n",
      "(33607, 'tampa', 4)\n",
      "(40222, 'louisville', 1)\n",
      "(44122, 'beachwood', 3)\n",
      "(45839, 'findlay', 3)\n",
      "(48075, 'southfield', 3)\n",
      "(48084, 'troy', 3)\n",
      "(48304, 'bloomfield hills', 3)\n",
      "(53404, 'racine', 3)\n",
      "(55113, 'roseville', 3)\n",
      "(55439, 'minneapolis', 3)\n",
      "(60179, 'hoffman estates', 2)\n",
      "(60601, 'chicago', 2)\n",
      "(72716, 'bentonville', 4)\n",
      "(75234, 'dallas', 4)\n",
      "(78759, 'austin', 4)\n",
      "(80202, 'denver', 2)\n",
      "(80909, 'colorado springs', 2)\n",
      "(85014, 'phoenix', 2)\n",
      "(85251, 'scottsdale', 2)\n",
      "(90405, 'santa monica', 2)\n",
      "(94025, 'menlo park', 2)\n",
      "(94105, 'san francisco', 2)\n",
      "(95008, 'campbell', 2)\n",
      "(95054, 'santa clara', 2)\n",
      "(95060, 'santa cruz', 2)\n",
      "(98004, 'bellevue', 2)\n",
      "(98052, 'redmond', 2)\n",
      "(98104, 'seattle', 2)\n",
      "Upper\n",
      "(1730, 'BEDFORD', 1)\n",
      "(1581, 'WESTBORO', 1)\n",
      "(1833, 'GEORGETOW', 1)\n",
      "(2116, 'BOSTON', 1)\n",
      "(2139, 'CAMBRIDGE', 1)\n",
      "(2184, 'BRAINTREE', 1)\n",
      "(2903, 'PROVIDENCE', 1)\n",
      "(3049, 'HOLLIS', 3)\n",
      "(3801, 'PORTSMOUTH', 3)\n",
      "(6897, 'WILTON', 1)\n",
      "(7960, 'MORRISTOWN', 1)\n",
      "(8837, 'EDISON', 1)\n",
      "(10019, 'NEW YORK', 1)\n",
      "(10038, 'NEW YORK', 1)\n",
      "(11747, 'MELLVILE', 1)\n",
      "(14450, 'FAIRPORT', 1)\n",
      "(19428, 'PHILADELPHIA', 3)\n",
      "(19713, 'NEWARD', 1)\n",
      "(20852, 'ROCKVILLE', 1)\n",
      "(27403, 'GREENSBORO', 1)\n",
      "(27511, 'CARY', 1)\n",
      "(29202, 'COLUMBIA', 4)\n",
      "(30346, 'ATLANTA', 4)\n",
      "(31406, 'SAVANNAH', 4)\n",
      "(32859, 'ORLANDO', 4)\n",
      "(33607, 'TAMPA', 4)\n",
      "(40222, 'LOUISVILLE', 1)\n",
      "(44122, 'BEACHWOOD', 3)\n",
      "(45839, 'FINDLAY', 3)\n",
      "(48075, 'SOUTHFIELD', 3)\n",
      "(48084, 'TROY', 3)\n",
      "(48304, 'BLOOMFIELD HILLS', 3)\n",
      "(53404, 'RACINE', 3)\n",
      "(55113, 'ROSEVILLE', 3)\n",
      "(55439, 'MINNEAPOLIS', 3)\n",
      "(60179, 'HOFFMAN ESTATES', 2)\n",
      "(60601, 'CHICAGO', 2)\n",
      "(72716, 'BENTONVILLE', 4)\n",
      "(75234, 'DALLAS', 4)\n",
      "(78759, 'AUSTIN', 4)\n",
      "(80202, 'DENVER', 2)\n",
      "(80909, 'COLORADO SPRINGS', 2)\n",
      "(85014, 'PHOENIX', 2)\n",
      "(85251, 'SCOTTSDALE', 2)\n",
      "(90405, 'SANTA MONICA', 2)\n",
      "(94025, 'MENLO PARK', 2)\n",
      "(94105, 'SAN FRANCISCO', 2)\n",
      "(95008, 'CAMPBELL', 2)\n",
      "(95054, 'SANTA CLARA', 2)\n",
      "(95060, 'SANTA CRUZ', 2)\n",
      "(98004, 'BELLEVUE', 2)\n",
      "(98052, 'REDMOND', 2)\n",
      "(98104, 'SEATTLE', 2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (p \n",
    "                    | 'Read' >> ReadFromText(territoriesfilename) \n",
    "                    | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "                  )\n",
    "\n",
    "    # Branch 1\n",
    "    (territories \n",
    "         | 'Lowercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.lower(), x.regionid))\n",
    "         | 'Write Lower' >> WriteToText('/tmp/territories_lower.out')\n",
    "    )\n",
    "    \n",
    "    # Branch 2\n",
    "    (territories \n",
    "         | 'Uppercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.upper(), x.regionid))\n",
    "         | 'Write Upper' >> WriteToText('/tmp/territories_upper.out')\n",
    "    )\n",
    "\n",
    "! echo \"Lower\" && cat /tmp/territories_lower.out* && echo \"Upper\" && cat /tmp/territories_upper.out*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7374d-4d8b-4923-81b6-4c32e9e13c99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use TaggedOutput in the ParDo to split data into two different paths with different data on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4a7649fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evens\n",
      "Territory(territoryid=29202, territoryname='Columbia', regionid=4)\n",
      "Territory(territoryid=30346, territoryname='Atlanta', regionid=4)\n",
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=32859, territoryname='Orlando', regionid=4)\n",
      "Territory(territoryid=33607, territoryname='Tampa', regionid=4)\n",
      "Territory(territoryid=60179, territoryname='Hoffman Estates', regionid=2)\n",
      "Territory(territoryid=60601, territoryname='Chicago', regionid=2)\n",
      "Territory(territoryid=72716, territoryname='Bentonville', regionid=4)\n",
      "Territory(territoryid=75234, territoryname='Dallas', regionid=4)\n",
      "Territory(territoryid=78759, territoryname='Austin', regionid=4)\n",
      "Territory(territoryid=80202, territoryname='Denver', regionid=2)\n",
      "Territory(territoryid=80909, territoryname='Colorado Springs', regionid=2)\n",
      "Territory(territoryid=85014, territoryname='Phoenix', regionid=2)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94025, territoryname='Menlo Park', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95008, territoryname='Campbell', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98004, territoryname='Bellevue', regionid=2)\n",
      "Territory(territoryid=98052, territoryname='Redmond', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n",
      "Odds\n",
      "Territory(territoryid=1730, territoryname='Bedford', regionid=1)\n",
      "Territory(territoryid=1581, territoryname='Westboro', regionid=1)\n",
      "Territory(territoryid=1833, territoryname='Georgetow', regionid=1)\n",
      "Territory(territoryid=2116, territoryname='Boston', regionid=1)\n",
      "Territory(territoryid=2139, territoryname='Cambridge', regionid=1)\n",
      "Territory(territoryid=2184, territoryname='Braintree', regionid=1)\n",
      "Territory(territoryid=2903, territoryname='Providence', regionid=1)\n",
      "Territory(territoryid=3049, territoryname='Hollis', regionid=3)\n",
      "Territory(territoryid=3801, territoryname='Portsmouth', regionid=3)\n",
      "Territory(territoryid=6897, territoryname='Wilton', regionid=1)\n",
      "Territory(territoryid=7960, territoryname='Morristown', regionid=1)\n",
      "Territory(territoryid=8837, territoryname='Edison', regionid=1)\n",
      "Territory(territoryid=10019, territoryname='New York', regionid=1)\n",
      "Territory(territoryid=10038, territoryname='New York', regionid=1)\n",
      "Territory(territoryid=11747, territoryname='Mellvile', regionid=1)\n",
      "Territory(territoryid=14450, territoryname='Fairport', regionid=1)\n",
      "Territory(territoryid=19428, territoryname='Philadelphia', regionid=3)\n",
      "Territory(territoryid=19713, territoryname='Neward', regionid=1)\n",
      "Territory(territoryid=20852, territoryname='Rockville', regionid=1)\n",
      "Territory(territoryid=27403, territoryname='Greensboro', regionid=1)\n",
      "Territory(territoryid=27511, territoryname='Cary', regionid=1)\n",
      "Territory(territoryid=40222, territoryname='Louisville', regionid=1)\n",
      "Territory(territoryid=44122, territoryname='Beachwood', regionid=3)\n",
      "Territory(territoryid=45839, territoryname='Findlay', regionid=3)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=48084, territoryname='Troy', regionid=3)\n",
      "Territory(territoryid=48304, territoryname='Bloomfield Hills', regionid=3)\n",
      "Territory(territoryid=53404, territoryname='Racine', regionid=3)\n",
      "Territory(territoryid=55113, territoryname='Roseville', regionid=3)\n",
      "Territory(territoryid=55439, territoryname='Minneapolis', regionid=3)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class OddEvenTerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        if int(regionid) % 2 == 0:\n",
    "            yield pvalue.TaggedOutput('Even', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "        else:\n",
    "            yield pvalue.TaggedOutput('Odd', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(territoriesfilename) \n",
    "    # lines would return a tuple of the two tagged outputs\n",
    "    # unpack the two outputs to two separate variables to process differently\n",
    "    evens, odds = lines | 'Parse' >> beam.ParDo(OddEvenTerritoryParseClass()).with_outputs(\"Even\", \"Odd\")\n",
    "    \n",
    "    evens | 'Write Even' >> WriteToText('/tmp/territories_even.out')\n",
    "    \n",
    "    odds | 'Write Odd' >> WriteToText('/tmp/territories_odd.out')\n",
    "\n",
    "! echo \"Evens\" && cat /tmp/territories_even.out* && echo \"Odds\" && cat /tmp/territories_odd.out*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a3ae2-0add-4eaf-8515-d9420834fa34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ce4a7-eacc-41dd-b51b-1746546fcbcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Send the same output down two different paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4f43ccc6-3890-4349-8482-c7c2498e9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a9847873-48ba-4b10-9e17-9bfe3004ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territory\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "            \n",
    "        territories\n",
    "            .apply(\"Upper\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toUpperCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_upper\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        territories\n",
    "            .apply(\"Lower\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toLowerCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_lower\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ae170dd2-fdd2-46fc-b741-5e8423269d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper\n",
      "(territoryID = 3049, territoryName = HOLLIS, regionID = 3)\n",
      "(territoryID = 7960, territoryName = MORRISTOWN, regionID = 1)\n",
      "(territoryID = 80909, territoryName = COLORADO SPRINGS, regionID = 2)\n",
      "(territoryID = 90405, territoryName = SANTA MONICA, regionID = 2)\n",
      "(territoryID = 95008, territoryName = CAMPBELL, regionID = 2)\n",
      "(territoryID = 98004, territoryName = BELLEVUE, regionID = 2)\n",
      "(territoryID = 1833, territoryName = GEORGETOW, regionID = 1)\n",
      "(territoryID = 2184, territoryName = BRAINTREE, regionID = 1)\n",
      "(territoryID = 11747, territoryName = MELLVILE, regionID = 1)\n",
      "(territoryID = 19713, territoryName = NEWARD, regionID = 1)\n",
      "(territoryID = 27511, territoryName = CARY, regionID = 1)\n",
      "(territoryID = 31406, territoryName = SAVANNAH, regionID = 4)\n",
      "(territoryID = 40222, territoryName = LOUISVILLE, regionID = 1)\n",
      "(territoryID = 48075, territoryName = SOUTHFIELD, regionID = 3)\n",
      "(territoryID = 53404, territoryName = RACINE, regionID = 3)\n",
      "(territoryID = 60179, territoryName = HOFFMAN ESTATES, regionID = 2)\n",
      "(territoryID = 75234, territoryName = DALLAS, regionID = 4)\n",
      "(territoryID = 10019, territoryName = NEW YORK, regionID = 1)\n",
      "(territoryID = 3801, territoryName = PORTSMOUTH, regionID = 3)\n",
      "(territoryID = 85014, territoryName = PHOENIX, regionID = 2)\n",
      "(territoryID = 94025, territoryName = MENLO PARK, regionID = 2)\n",
      "(territoryID = 95054, territoryName = SANTA CLARA, regionID = 2)\n",
      "(territoryID = 98052, territoryName = REDMOND, regionID = 2)\n",
      "(territoryID = 1730, territoryName = BEDFORD, regionID = 1)\n",
      "(territoryID = 2116, territoryName = BOSTON, regionID = 1)\n",
      "(territoryID = 2903, territoryName = PROVIDENCE, regionID = 1)\n",
      "(territoryID = 14450, territoryName = FAIRPORT, regionID = 1)\n",
      "(territoryID = 20852, territoryName = ROCKVILLE, regionID = 1)\n",
      "(territoryID = 29202, territoryName = COLUMBIA, regionID = 4)\n",
      "(territoryID = 32859, territoryName = ORLANDO, regionID = 4)\n",
      "(territoryID = 44122, territoryName = BEACHWOOD, regionID = 3)\n",
      "(territoryID = 48084, territoryName = TROY, regionID = 3)\n",
      "(territoryID = 55113, territoryName = ROSEVILLE, regionID = 3)\n",
      "(territoryID = 60601, territoryName = CHICAGO, regionID = 2)\n",
      "(territoryID = 78759, territoryName = AUSTIN, regionID = 4)\n",
      "(territoryID = 10038, territoryName = NEW YORK, regionID = 1)\n",
      "(territoryID = 6897, territoryName = WILTON, regionID = 1)\n",
      "(territoryID = 85251, territoryName = SCOTTSDALE, regionID = 2)\n",
      "(territoryID = 94105, territoryName = SAN FRANCISCO, regionID = 2)\n",
      "(territoryID = 95060, territoryName = SANTA CRUZ, regionID = 2)\n",
      "(territoryID = 98104, territoryName = SEATTLE, regionID = 2)\n",
      "(territoryID = 1581, territoryName = WESTBORO, regionID = 1)\n",
      "(territoryID = 2139, territoryName = CAMBRIDGE, regionID = 1)\n",
      "(territoryID = 19428, territoryName = PHILADELPHIA, regionID = 3)\n",
      "(territoryID = 27403, territoryName = GREENSBORO, regionID = 1)\n",
      "(territoryID = 30346, territoryName = ATLANTA, regionID = 4)\n",
      "(territoryID = 33607, territoryName = TAMPA, regionID = 4)\n",
      "(territoryID = 45839, territoryName = FINDLAY, regionID = 3)\n",
      "(territoryID = 48304, territoryName = BLOOMFIELD HILLS, regionID = 3)\n",
      "(territoryID = 55439, territoryName = MINNEAPOLIS, regionID = 3)\n",
      "(territoryID = 72716, territoryName = BENTONVILLE, regionID = 4)\n",
      "(territoryID = 80202, territoryName = DENVER, regionID = 2)\n",
      "(territoryID = 8837, territoryName = EDISON, regionID = 1)\n",
      "Lower\n",
      "(territoryID = 45839, territoryName = findlay, regionID = 3)\n",
      "(territoryID = 55113, territoryName = roseville, regionID = 3)\n",
      "(territoryID = 75234, territoryName = dallas, regionID = 4)\n",
      "(territoryID = 11747, territoryName = mellvile, regionID = 1)\n",
      "(territoryID = 27403, territoryName = greensboro, regionID = 1)\n",
      "(territoryID = 32859, territoryName = orlando, regionID = 4)\n",
      "(territoryID = 3801, territoryName = portsmouth, regionID = 3)\n",
      "(territoryID = 2139, territoryName = cambridge, regionID = 1)\n",
      "(territoryID = 85251, territoryName = scottsdale, regionID = 2)\n",
      "(territoryID = 95054, territoryName = santa clara, regionID = 2)\n",
      "(territoryID = 48075, territoryName = southfield, regionID = 3)\n",
      "(territoryID = 55439, territoryName = minneapolis, regionID = 3)\n",
      "(territoryID = 78759, territoryName = austin, regionID = 4)\n",
      "(territoryID = 14450, territoryName = fairport, regionID = 1)\n",
      "(territoryID = 27511, territoryName = cary, regionID = 1)\n",
      "(territoryID = 33607, territoryName = tampa, regionID = 4)\n",
      "(territoryID = 6897, territoryName = wilton, regionID = 1)\n",
      "(territoryID = 1730, territoryName = bedford, regionID = 1)\n",
      "(territoryID = 2184, territoryName = braintree, regionID = 1)\n",
      "(territoryID = 90405, territoryName = santa monica, regionID = 2)\n",
      "(territoryID = 95060, territoryName = santa cruz, regionID = 2)\n",
      "(territoryID = 48084, territoryName = troy, regionID = 3)\n",
      "(territoryID = 60179, territoryName = hoffman estates, regionID = 2)\n",
      "(territoryID = 80202, territoryName = denver, regionID = 2)\n",
      "(territoryID = 19428, territoryName = philadelphia, regionID = 3)\n",
      "(territoryID = 29202, territoryName = columbia, regionID = 4)\n",
      "(territoryID = 40222, territoryName = louisville, regionID = 1)\n",
      "(territoryID = 7960, territoryName = morristown, regionID = 1)\n",
      "(territoryID = 1581, territoryName = westboro, regionID = 1)\n",
      "(territoryID = 2903, territoryName = providence, regionID = 1)\n",
      "(territoryID = 94025, territoryName = menlo park, regionID = 2)\n",
      "(territoryID = 98004, territoryName = bellevue, regionID = 2)\n",
      "(territoryID = 10038, territoryName = new york, regionID = 1)\n",
      "(territoryID = 48304, territoryName = bloomfield hills, regionID = 3)\n",
      "(territoryID = 60601, territoryName = chicago, regionID = 2)\n",
      "(territoryID = 8837, territoryName = edison, regionID = 1)\n",
      "(territoryID = 19713, territoryName = neward, regionID = 1)\n",
      "(territoryID = 30346, territoryName = atlanta, regionID = 4)\n",
      "(territoryID = 44122, territoryName = beachwood, regionID = 3)\n",
      "(territoryID = 1833, territoryName = georgetow, regionID = 1)\n",
      "(territoryID = 80909, territoryName = colorado springs, regionID = 2)\n",
      "(territoryID = 94105, territoryName = san francisco, regionID = 2)\n",
      "(territoryID = 98052, territoryName = redmond, regionID = 2)\n",
      "(territoryID = 53404, territoryName = racine, regionID = 3)\n",
      "(territoryID = 72716, territoryName = bentonville, regionID = 4)\n",
      "(territoryID = 10019, territoryName = new york, regionID = 1)\n",
      "(territoryID = 20852, territoryName = rockville, regionID = 1)\n",
      "(territoryID = 31406, territoryName = savannah, regionID = 4)\n",
      "(territoryID = 3049, territoryName = hollis, regionID = 3)\n",
      "(territoryID = 2116, territoryName = boston, regionID = 1)\n",
      "(territoryID = 85014, territoryName = phoenix, regionID = 2)\n",
      "(territoryID = 95008, territoryName = campbell, regionID = 2)\n",
      "(territoryID = 98104, territoryName = seattle, regionID = 2)\n"
     ]
    }
   ],
   "source": [
    "! echo \"Upper\" && cat /tmp/territories_upper* && echo \"Lower\" && cat /tmp/territories_lower*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c0f98-4b4b-4253-8045-4bb46bebfa7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use TupleTag to split the output into two separate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "25158a5b-169d-4672-9683-38732dbca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "72dde632-b934-4bf6-9a58-b551ab264385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      ">> rm build/libs/*.jar\n",
      ">> rm -rf /tmp/outputs*\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      ">> ls -lh build/libs/\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    final static TupleTag<Territory> evenTag = new TupleTag<Territory>() {};\n",
    "    final static TupleTag<Territory> oddTag = new TupleTag<Territory>() {};\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollectionTuple territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"OddEvenSplit\", ParDo.of(new ParseTerritoriesOddEvenSplit()).withOutputTags(evenTag, TupleTagList.of(oddTag)))\n",
    "        ;                   \n",
    "        \n",
    "        PCollection<Territory> evenTerritories = territories.get(evenTag);\n",
    "        evenTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_even\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        PCollection<Territory> oddTerritories = territories.get(oddTag);\n",
    "        oddTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_odd\").withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritoriesOddEvenSplit extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritoriesOddEvenSplit.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "\n",
    "\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (regionID % 2 == 0) {\n",
    "                    c.output(evenTag, new Territory(territoryID, territoryName, regionID));\n",
    "                } else {\n",
    "                    c.output(oddTag, new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fb6d6ae9-a392-4d7f-9222-017e3f2a8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd\n",
      "(territoryID = 53404, territoryName = Racine, regionID = 3)\n",
      "(territoryID = 14450, territoryName = Fairport, regionID = 1)\n",
      "(territoryID = 27511, territoryName = Cary, regionID = 1)\n",
      "(territoryID = 1581, territoryName = Westboro, regionID = 1)\n",
      "(territoryID = 2903, territoryName = Providence, regionID = 1)\n",
      "(territoryID = 8837, territoryName = Edison, regionID = 1)\n",
      "(territoryID = 45839, territoryName = Findlay, regionID = 3)\n",
      "(territoryID = 55113, territoryName = Roseville, regionID = 3)\n",
      "(territoryID = 19428, territoryName = Philadelphia, regionID = 3)\n",
      "(territoryID = 40222, territoryName = Louisville, regionID = 1)\n",
      "(territoryID = 1833, territoryName = Georgetow, regionID = 1)\n",
      "(territoryID = 3049, territoryName = Hollis, regionID = 3)\n",
      "(territoryID = 10019, territoryName = New York, regionID = 1)\n",
      "(territoryID = 48075, territoryName = Southfield, regionID = 3)\n",
      "(territoryID = 55439, territoryName = Minneapolis, regionID = 3)\n",
      "(territoryID = 19713, territoryName = Neward, regionID = 1)\n",
      "(territoryID = 44122, territoryName = Beachwood, regionID = 3)\n",
      "(territoryID = 2116, territoryName = Boston, regionID = 1)\n",
      "(territoryID = 3801, territoryName = Portsmouth, regionID = 3)\n",
      "(territoryID = 10038, territoryName = New York, regionID = 1)\n",
      "(territoryID = 48084, territoryName = Troy, regionID = 3)\n",
      "(territoryID = 20852, territoryName = Rockville, regionID = 1)\n",
      "(territoryID = 2139, territoryName = Cambridge, regionID = 1)\n",
      "(territoryID = 6897, territoryName = Wilton, regionID = 1)\n",
      "(territoryID = 48304, territoryName = Bloomfield Hills, regionID = 3)\n",
      "(territoryID = 11747, territoryName = Mellvile, regionID = 1)\n",
      "(territoryID = 27403, territoryName = Greensboro, regionID = 1)\n",
      "(territoryID = 1730, territoryName = Bedford, regionID = 1)\n",
      "(territoryID = 2184, territoryName = Braintree, regionID = 1)\n",
      "(territoryID = 7960, territoryName = Morristown, regionID = 1)\n",
      "Even\n",
      "(territoryID = 60179, territoryName = Hoffman Estates, regionID = 2)\n",
      "(territoryID = 80202, territoryName = Denver, regionID = 2)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 80909, territoryName = Colorado Springs, regionID = 2)\n",
      "(territoryID = 94105, territoryName = San Francisco, regionID = 2)\n",
      "(territoryID = 98052, territoryName = Redmond, regionID = 2)\n",
      "(territoryID = 60601, territoryName = Chicago, regionID = 2)\n",
      "(territoryID = 32859, territoryName = Orlando, regionID = 4)\n",
      "(territoryID = 85014, territoryName = Phoenix, regionID = 2)\n",
      "(territoryID = 95008, territoryName = Campbell, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 72716, territoryName = Bentonville, regionID = 4)\n",
      "(territoryID = 33607, territoryName = Tampa, regionID = 4)\n",
      "(territoryID = 85251, territoryName = Scottsdale, regionID = 2)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 75234, territoryName = Dallas, regionID = 4)\n",
      "(territoryID = 29202, territoryName = Columbia, regionID = 4)\n",
      "(territoryID = 90405, territoryName = Santa Monica, regionID = 2)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 78759, territoryName = Austin, regionID = 4)\n",
      "(territoryID = 30346, territoryName = Atlanta, regionID = 4)\n",
      "(territoryID = 94025, territoryName = Menlo Park, regionID = 2)\n",
      "(territoryID = 98004, territoryName = Bellevue, regionID = 2)\n"
     ]
    }
   ],
   "source": [
    "! echo \"Odd\" && cat /tmp/outputs_odd* && echo \"Even\" && cat /tmp/outputs_even*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184af67-b4bc-4dfc-b8c8-a85735022725",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 6. To use Group, Join, Sort you need to reshape the data into a KV pair first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c69d69-d541-4d25-aae0-6a165c2f6531",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040dd12-e0d2-4eeb-ba6f-ec490542e822",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GroupByKey will cluster the elements as a list under each unique key. The data must be in a KV tuple pair first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9bf6f82f-8a76-49b2-9fc6-d5c8c9651d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, Territory(territoryid=1730, territoryname='Bedford', regionid=1))\n",
      "(1, Territory(territoryid=1581, territoryname='Westboro', regionid=1))\n",
      "(1, Territory(territoryid=1833, territoryname='Georgetow', regionid=1))\n",
      "(1, Territory(territoryid=2116, territoryname='Boston', regionid=1))\n",
      "(1, Territory(territoryid=2139, territoryname='Cambridge', regionid=1))\n",
      "(1, Territory(territoryid=2184, territoryname='Braintree', regionid=1))\n",
      "(1, Territory(territoryid=2903, territoryname='Providence', regionid=1))\n",
      "(3, Territory(territoryid=3049, territoryname='Hollis', regionid=3))\n",
      "(3, Territory(territoryid=3801, territoryname='Portsmouth', regionid=3))\n",
      "(1, Territory(territoryid=6897, territoryname='Wilton', regionid=1))\n",
      "(1, Territory(territoryid=7960, territoryname='Morristown', regionid=1))\n",
      "(1, Territory(territoryid=8837, territoryname='Edison', regionid=1))\n",
      "(1, Territory(territoryid=10019, territoryname='New York', regionid=1))\n",
      "(1, Territory(territoryid=10038, territoryname='New York', regionid=1))\n",
      "(1, Territory(territoryid=11747, territoryname='Mellvile', regionid=1))\n",
      "(1, Territory(territoryid=14450, territoryname='Fairport', regionid=1))\n",
      "(3, Territory(territoryid=19428, territoryname='Philadelphia', regionid=3))\n",
      "(1, Territory(territoryid=19713, territoryname='Neward', regionid=1))\n",
      "(1, Territory(territoryid=20852, territoryname='Rockville', regionid=1))\n",
      "(1, Territory(territoryid=27403, territoryname='Greensboro', regionid=1))\n",
      "(1, Territory(territoryid=27511, territoryname='Cary', regionid=1))\n",
      "(4, Territory(territoryid=29202, territoryname='Columbia', regionid=4))\n",
      "(4, Territory(territoryid=30346, territoryname='Atlanta', regionid=4))\n",
      "(4, Territory(territoryid=31406, territoryname='Savannah', regionid=4))\n",
      "(4, Territory(territoryid=32859, territoryname='Orlando', regionid=4))\n",
      "(4, Territory(territoryid=33607, territoryname='Tampa', regionid=4))\n",
      "(1, Territory(territoryid=40222, territoryname='Louisville', regionid=1))\n",
      "(3, Territory(territoryid=44122, territoryname='Beachwood', regionid=3))\n",
      "(3, Territory(territoryid=45839, territoryname='Findlay', regionid=3))\n",
      "(3, Territory(territoryid=48075, territoryname='Southfield', regionid=3))\n",
      "(3, Territory(territoryid=48084, territoryname='Troy', regionid=3))\n",
      "(3, Territory(territoryid=48304, territoryname='Bloomfield Hills', regionid=3))\n",
      "(3, Territory(territoryid=53404, territoryname='Racine', regionid=3))\n",
      "(3, Territory(territoryid=55113, territoryname='Roseville', regionid=3))\n",
      "(3, Territory(territoryid=55439, territoryname='Minneapolis', regionid=3))\n",
      "(2, Territory(territoryid=60179, territoryname='Hoffman Estates', regionid=2))\n",
      "(2, Territory(territoryid=60601, territoryname='Chicago', regionid=2))\n",
      "(4, Territory(territoryid=72716, territoryname='Bentonville', regionid=4))\n",
      "(4, Territory(territoryid=75234, territoryname='Dallas', regionid=4))\n",
      "(4, Territory(territoryid=78759, territoryname='Austin', regionid=4))\n",
      "(2, Territory(territoryid=80202, territoryname='Denver', regionid=2))\n",
      "(2, Territory(territoryid=80909, territoryname='Colorado Springs', regionid=2))\n",
      "(2, Territory(territoryid=85014, territoryname='Phoenix', regionid=2))\n",
      "(2, Territory(territoryid=85251, territoryname='Scottsdale', regionid=2))\n",
      "(2, Territory(territoryid=90405, territoryname='Santa Monica', regionid=2))\n",
      "(2, Territory(territoryid=94025, territoryname='Menlo Park', regionid=2))\n",
      "(2, Territory(territoryid=94105, territoryname='San Francisco', regionid=2))\n",
      "(2, Territory(territoryid=95008, territoryname='Campbell', regionid=2))\n",
      "(2, Territory(territoryid=95054, territoryname='Santa Clara', regionid=2))\n",
      "(2, Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2))\n",
      "(2, Territory(territoryid=98004, territoryname='Bellevue', regionid=2))\n",
      "(2, Territory(territoryid=98052, territoryname='Redmond', regionid=2))\n",
      "(2, Territory(territoryid=98104, territoryname='Seattle', regionid=2))\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x.regionid)\n",
    "#                    | 'Group Territories' >> beam.GroupByKey() \n",
    "                    | 'Print Territories' >> beam.Map(print)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f5fce976-9609-402f-b2ec-a129351ec8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 One Uno\n",
      "1 One Eins\n",
      "1 One Una\n",
      "2 Two Due\n",
      "2 Two Dos\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'One'), (2, 'Two'), (4, 'Four')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : beam.Row(parent_id = x[0], parent_name = x[1]))\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Uno', 1), ('Due', 2), ('Eins', 1), ('Una', 1), ('Dos', 2), ('Tres', 3)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : beam.Row(child_name = x[0], parent_id = x[1]))\n",
    "    )\n",
    "    \n",
    "    result = ( {'parent': parent, 'child' : child} \n",
    "         | SqlTransform(\"\"\"\n",
    "             SELECT p.parent_id, p.parent_name, c.child_name \n",
    "             FROM parent as p \n",
    "             INNER JOIN child as c ON p.parent_id = c.parent_id\n",
    "             \"\"\")\n",
    "        | 'Map Join Output' >> beam.Map(lambda x : f'{x.parent_id} {x.parent_name} {x.child_name}')\n",
    "        | 'Print Join' >> beam.Map(print)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "57d90731-bacc-4b09-82d1-c16f19dce311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent(parent_id=1, parent_name='One')\n",
      "Parent(parent_id=2, parent_name='Two')\n",
      "Parent 1 count = 3\n",
      "Parent 2 count = 2\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "\n",
    "class Parent(typing.NamedTuple):\n",
    "    parent_id: int\n",
    "    parent_name: str\n",
    "beam.coders.registry.register_coder(Parent, beam.coders.RowCoder)\n",
    "\n",
    "class Child(typing.NamedTuple):\n",
    "    child_name: str\n",
    "    parent_id: int\n",
    "beam.coders.registry.register_coder(Child, beam.coders.RowCoder)\n",
    "        \n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'One'), (2, 'Two')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : Parent(parent_id = x[0], parent_name = x[1])).with_output_types(Parent)\n",
    "              | 'Print 1' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Uno', 1), ('Due', 2), ('Eins', 1), ('Una', 1), ('Dos', 2)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : Child(child_name = x[0], parent_id = x[1])).with_output_types(Child)\n",
    "              | 'SQL Child' >> SqlTransform(\"\"\"SELECT parent_id, count(*) as cnt from PCOLLECTION GROUP BY parent_id\"\"\")\n",
    "              | 'Map for Print 2' >> beam.Map(lambda x : f'Parent {x.parent_id} count = {x.cnt}')\n",
    "              | 'Print 2' >> beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbd91-e4b8-4bd1-8c75-89064613bbd8",
   "metadata": {},
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030bb71-8ee0-48e6-aa39-284b2c65c042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Apache Beam 2.34.0 for Python 3",
   "language": "python",
   "name": "01-apache-beam-2.34.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
