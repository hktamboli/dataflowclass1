{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b5ce6c-55cb-45b7-9ad1-370ee54bf5c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install a Spark docker using the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ac48-b14e-4e01-8290-b9799ba6e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker pull bitnami/spark && \\\n",
    "docker network create spark_network && \\\n",
    "docker run -d --name spark --network=spark_network -e SPARK_MODE=master bitnami/spark\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659dd20-a9ab-4008-8bce-a5ff5acf5690",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb46e-7eef-4af7-bd41-587e716e3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "def install(package):\n",
    "    if hasattr(pip, 'main'):\n",
    "        pip.main(['install', package])\n",
    "    else:\n",
    "        pip._internal.main(['install', package])\n",
    "\n",
    "install('pyspark')\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140ae18-4293-4560-91d6-4324e41fb0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize the Spark context variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6573258c-97d5-4282-9278-cfe9ad82a186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing pyspark\n",
      "pyspark initialized\n",
      "<SparkContext master=local[*] appName=Notebook> <pyspark.sql.session.SparkSession object at 0x7fbc44c16b90>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def initspark(appname = \"Notebook\", servername = \"local[*]\"):\n",
    "    print ('initializing pyspark')\n",
    "    conf = SparkConf().setAppName(appname).setMaster(servername)\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession.builder.appName(appname).enableHiveSupport().getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "    print ('pyspark initialized')\n",
    "    return sc, spark, conf\n",
    "\n",
    "sc, spark, conf = initspark()\n",
    "print(sc, spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbca6a8-f8cc-45ac-8a62-0d14bfb665d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Initialize helper functions to run Java inside cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d334c3-e064-4241-aa70-26d939b3e166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/get-started/try-apache-beam-java.ipynb#scrollTo=CgTXBdTsBn1F\n",
    "# Run and print a shell command.\n",
    "def run(cmd):\n",
    "  print('>> {}'.format(cmd))\n",
    "  !{cmd}  # This is magic to run 'cmd' in the shell.\n",
    "  print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2cc1a8-3e8e-428c-a69f-a3e51b402b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain -v\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m\n",
      "------------------------------------------------------------\n",
      "Gradle 5.0\n",
      "------------------------------------------------------------\n",
      "\n",
      "Build time:   2018-11-26 11:48:43 UTC\n",
      "Revision:     7fc6e5abf2fc5fe0824aec8a0f5462664dbcd987\n",
      "\n",
      "Kotlin DSL:   1.0.4\n",
      "Kotlin:       1.3.10\n",
      "Groovy:       2.5.4\n",
      "Ant:          Apache Ant(TM) version 1.9.13 compiled on July 10 2018\n",
      "JVM:          1.8.0_92 (Azul Systems, Inc. 25.92-b15)\n",
      "OS:           Linux 4.19.0-18-cloud-amd64 amd64\n",
      "\n",
      "\u001b[m\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Download the gradle source.\n",
    "gradle_version = 'gradle-5.0'\n",
    "gradle_path = f\"/opt/{gradle_version}\"\n",
    "if not os.path.exists(gradle_path):\n",
    "  run(f\"wget -q -nc -O gradle.zip https://services.gradle.org/distributions/{gradle_version}-bin.zip\")\n",
    "  run('unzip -q -d /opt gradle.zip')\n",
    "  run('rm -f gradle.zip')\n",
    "\n",
    "# We're choosing to use the absolute path instead of adding it to the $PATH environment variable.\n",
    "def gradle(args):\n",
    "  run(f\"{gradle_path}/bin/gradle --console=plain {args}\")\n",
    "\n",
    "gradle('-v')\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716a7d4-28ea-40e7-90db-3e762b7dbcf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Definition for %%java Python magic cell function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a97925b-df54-4700-bb8b-d4a3e2305b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_magic, register_cell_magic, register_line_cell_magic\n",
    "@register_cell_magic\n",
    "def java(line, cell):\n",
    "    \"\"\"\n",
    "    Written by Joseph Gagliardo Jr.\n",
    "    joegagliardo@gmail.com\n",
    "    2021-12-22\n",
    "    \"\"\"\n",
    "    text = \"\"\"\n",
    "plugins {\n",
    "  // id 'idea'     // Uncomment for IntelliJ IDE\n",
    "  // id 'eclipse'  // Uncomment for Eclipse IDE\n",
    "\n",
    "  // Apply java plugin and make it a runnable application.\n",
    "  id 'java'\n",
    "  id 'application'\n",
    "\n",
    "  // 'shadow' allows us to embed all the dependencies into a fat jar.\n",
    "  id 'com.github.johnrengelman.shadow' version '4.0.3'\n",
    "}\n",
    "\n",
    "// This is the path of the main class, stored within ./src/main/java/\n",
    "mainClassName = 'samples.quickstart.{class_name}'\n",
    "\n",
    "// Declare the sources from which to fetch dependencies.\n",
    "repositories {\n",
    "  mavenCentral()\n",
    "}\n",
    "\n",
    "// Java version compatibility.\n",
    "sourceCompatibility = 1.8\n",
    "targetCompatibility = 1.8\n",
    "\n",
    "// Use the latest Apache Beam major version 2.\n",
    "// You can also lock into a minor version like '2.9.+'.\n",
    "ext.apacheBeamVersion = '2.+'\n",
    "\n",
    "// Declare the dependencies of the project.\n",
    "dependencies {\n",
    "  shadow \"org.apache.beam:beam-sdks-java-core:$apacheBeamVersion\"\n",
    "\n",
    "  runtime \"org.apache.beam:beam-runners-direct-java:$apacheBeamVersion\"\n",
    "  runtime \"org.slf4j:slf4j-api:1.+\"\n",
    "  runtime \"org.slf4j:slf4j-jdk14:1.+\"\n",
    "\n",
    "  testCompile \"junit:junit:4.+\"\n",
    "}\n",
    "\n",
    "// Configure 'shadowJar' instead of 'jar' to set up the fat jar.\n",
    "shadowJar {\n",
    "  baseName = '{class_name}' // Name of the fat jar file.\n",
    "  classifier = null       // Set to null, otherwise 'shadow' appends a '-all' to the jar file name.\n",
    "  manifest {\n",
    "    attributes('Main-Class': mainClassName)  // Specify where the main class resides.\n",
    "  }\n",
    "}\n",
    "\"\"\"   \n",
    "    if len(line) == 0:\n",
    "        start = cell.find('class ')\n",
    "        end = cell.find(' {')\n",
    "        class_name = cell[start+6:end]\n",
    "    else:\n",
    "        class_name = line\n",
    "        \n",
    "    \n",
    "    with open('build.gradle', 'w') as f:\n",
    "        f.write(text.replace('{class_name}', class_name))\n",
    "\n",
    "    with open(f'src/main/java/samples/quickstart/{class_name}.java', 'w') as f:\n",
    "        f.write(cell)\n",
    "        \n",
    "    # Build the project.\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain build\")\n",
    "    run('ls -lh build/libs/')\n",
    "    run('rm outputs/*')\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain runShadow\")\n",
    "    # run('head -n 20 outputs/part*')\n",
    "    run('cat outputs/part*')\n",
    "\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1397c54-3ff7-4188-bc9e-c72bef0d2670",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A basic Python example of applying a map function to a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0dd11-7c70-4a35-bc61-51d36bcfaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['one', 'two', 'three', 'four']\n",
    "print(list(map(str.title, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb1aad-7fe0-4b99-96f4-b30fbaae23ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### To do this in Beam, turn the local collection into a PCollection and apply a Map PTransform on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedc12b-27d2-4098-85f0-feba2f9e14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(str.title)\n",
    "          | beam.Map(print)\n",
    "    )\n",
    "\n",
    "# lines is a PCollection object\n",
    "print('lines = ', lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c8ecc-a678-48eb-9ae8-7fd3e34b8a6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Simple transformation using a lambda instead of a built in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd9b54f-3a72-4688-a5d1-545077e6b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(lambda x : x.title())\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dfeee-d660-47fb-92f7-7a0c3bcbb302",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple transformation using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf4cad9-4ed9-4c26-8894-e7d84eff8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def title(x):\n",
    "    return x.title()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(title)\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f09af7-2678-4b0c-879e-c567625a4a83",
   "metadata": {},
   "source": [
    "## The pipe `|` is actually just an operator overload to call the apply method of the pipeline. You would never do this in python, but it helps to understand what is going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e7a3d-99fc-4904-a1cd-baf93d088b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = ((p | beam.Create(['one', 'two', 'three', 'four']))\n",
    "             .apply(beam.Map(str.title)) \n",
    "             .apply(beam.Map(print)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057071-63e3-4414-820d-71e07ed0959d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### The Spark equivalent would be to pload a local Python list into a Spark RDD and do a simple transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b110e0-45a0-476b-a2ca-d33cecaec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = ( sc.parallelize(['one', 'two', 'three', 'four'])\n",
    "        \n",
    "#           .map(str.title)\n",
    "       )\n",
    "rdd1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33b715-0a74-4b46-8736-7798c51b313a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple Java transformation using a lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420314f-13dd-410f-90a8-569c9f3770ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create1 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.into(TypeDescriptors.strings()).via((String line) -> line.toUpperCase()));\n",
    "        lines.apply(TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db7b6-c42d-4268-847c-24a9c39df7e8",
   "metadata": {},
   "source": [
    "## Simple transformation using SimpleFunction instead of lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff75092-0480-4784-afba-9616e9e60d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 9 executed\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 127M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root 8.0K Dec 23 07:02 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove 'outputs/*': No such file or directory\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer e5172a42-6008-491d-8567-7121dfdc6915 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 3795d635-529a-4bab-b391-ab5d0e77077b for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 690253de-9ec1-44c9-afd0-219a622ea540 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/3795d635-529a-4bab-b391-ab5d0e77077b\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/690253de-9ec1-44c9-afd0-219a622ea540\n",
      "Dec 23, 2021 7:03:05 AM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/e5172a42-6008-491d-8567-7121dfdc6915\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Creating 1 empty output shards in addition to 3 written for destination null.\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Opening empty writer b440c64c-95c3-4e1a-8d17-dc4d30013d75 for destination null\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/b440c64c-95c3-4e1a-8d17-dc4d30013d75\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/e5172a42-6008-491d-8567-7121dfdc6915, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00004\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/3795d635-529a-4bab-b391-ab5d0e77077b, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00004\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/690253de-9ec1-44c9-afd0-219a622ea540, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00003-of-00004\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/b440c64c-95c3-4e1a-8d17-dc4d30013d75, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00004\n",
      "Dec 23, 2021 7:03:06 AM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-986e4b3d-7d5f-466b-a165-09136850b113/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> head -n 20 outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "==> outputs/part-00000-of-00004 <==\n",
      "THREE\n",
      "\n",
      "==> outputs/part-00001-of-00004 <==\n",
      "\n",
      "==> outputs/part-00002-of-00004 <==\n",
      "TWO\n",
      "FOUR\n",
      "\n",
      "==> outputs/part-00003-of-00004 <==\n",
      "ONE\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create2 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(\"Create\", Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(\"Uppercase\", MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return line.toUpperCase();\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27aee-6b1c-44a5-815d-31d039c24475",
   "metadata": {},
   "source": [
    "## Simple transformation using SimpleFunction to wrap a User Defined Function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da5c178e-2cfa-4316-95de-5779b243f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 20s\n",
      "9 actionable tasks: 9 executed\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 212M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 2.2K Dec 23 14:26 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:04 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove 'outputs/*': No such file or directory\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 8e7084a9-2c9b-4422-b659-6c23da1419c6 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 0097aeac-6375-4175-8e45-3eb86b8ac1e4 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 8f7c1e70-ef11-42ac-a314-f03b9b8e199e for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/8f7c1e70-ef11-42ac-a314-f03b9b8e199e\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/8e7084a9-2c9b-4422-b659-6c23da1419c6\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/0097aeac-6375-4175-8e45-3eb86b8ac1e4\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/8e7084a9-2c9b-4422-b659-6c23da1419c6, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00003\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/8f7c1e70-ef11-42ac-a314-f03b9b8e199e, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00003\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/0097aeac-6375-4175-8e45-3eb86b8ac1e4, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@4b520ea8, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00003\n",
      "Dec 23, 2021 2:26:48 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-008be86c-4757-48ef-9811-8e7c6d8e6fc4/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> head -n 20 outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "==> outputs/part-00000-of-00003 <==\n",
      "TWO\n",
      "\n",
      "==> outputs/part-00001-of-00003 <==\n",
      "ONE\n",
      "\n",
      "==> outputs/part-00002-of-00003 <==\n",
      "THREE\n",
      "FOUR\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create3 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(\"Create\", Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(\"Uppercase\", MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return upper(line);\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    public static String upper(String line) {\n",
    "        return line.toUpperCase();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864aa22-07d5-493c-830c-fa8ec01fca33",
   "metadata": {},
   "source": [
    "## Read from CSV and use Map with lambda.\n",
    "### Also it's a good idea to name the steps so it's easier to debug and monitor them later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53066990-43fc-42c0-9545-ddf723145fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.Map(lambda x : x.split(','))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "          | 'Write' >> WriteToText(regionsfilename + '.out')\n",
    "#          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "    #p.run() # implicit in Python when using with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a83b869e-3b9b-44e9-a786-7ef59882768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(1, 'EASTERN')\n",
      "(2, 'WESTERN')\n",
      "(3, 'NORTHERN')\n",
      "(4, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "! cat regions.csv.out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28492eea-c43a-43ab-aa7f-ceca3f199a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :jar UP-TO-DATE\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar UP-TO-DATE\n",
      "> Task :distZip UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :shadowDistTar UP-TO-DATE\n",
      "> Task :shadowDistZip UP-TO-DATE\n",
      "> Task :assemble UP-TO-DATE\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build UP-TO-DATE\n",
      "\n",
      "BUILD SUCCESSFUL in 1s\n",
      "9 actionable tasks: 9 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 212M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 3.9K Dec 23 14:28 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:28 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist UP-TO-DATE\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:30:34 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern regions.csv matched 1 files with total size 42\n",
      "Dec 23, 2021 2:30:34 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern regions.csv into bundles of size 10 took 0 ms and produced 1 files and 5 bundles\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 46a765d8-5f66-413a-9fb7-7afb58e5c406 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 75a67d06-4c96-457d-8e40-e60940864183 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer c088ec1f-963c-437a-9738-1b042d3de58d for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer df26af44-ba14-4b52-bf84-f2dc8e619572 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/c088ec1f-963c-437a-9738-1b042d3de58d\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/df26af44-ba14-4b52-bf84-f2dc8e619572\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/75a67d06-4c96-457d-8e40-e60940864183\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/46a765d8-5f66-413a-9fb7-7afb58e5c406\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 4 file results\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 4.\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/46a765d8-5f66-413a-9fb7-7afb58e5c406, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00004\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/df26af44-ba14-4b52-bf84-f2dc8e619572, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00004\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/75a67d06-4c96-457d-8e40-e60940864183, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00004\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/c088ec1f-963c-437a-9738-1b042d3de58d, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00003-of-00004\n",
      "Dec 23, 2021 2:30:35 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-3500c8ac-91ee-40cf-b41f-77b6eccbfa3f/].\n",
      "\n",
      "BUILD SUCCESSFUL in 4s\n",
      "5 actionable tasks: 1 executed, 4 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "4,SOUTHERN\n",
      "3,NORTHERN\n",
      "1,EASTERN\n",
      "2,WESTERN\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "\n",
    "public class Read1 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", MapElements.into(TypeDescriptors.strings()).via((String element) -> element.toUpperCase()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88479c-60c3-48c3-b8c1-3e8113f0d39a",
   "metadata": {},
   "source": [
    "## Read from CSV and use ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94887a8a-f945-414f-bfaa-2e72fa1aa746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Eastern')\n",
      "(2, 'Western')\n",
      "(3, 'Northern')\n",
      "(4, 'Southern')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionParseTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "#        yield (int(regionid), regionname.upper()) # Include a transformation instead of doing it as a separate step\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.ParDo(RegionParseTuple())\n",
    "          #| 'Write' >> WriteToText('regions.out')\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd1da-0fed-43c9-8ab1-e1b73cc9534f",
   "metadata": {},
   "source": [
    "## Java ParDo Example using anonymous class inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14327a97-f8cd-489b-87eb-82ad962f701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 8 executed, 1 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 212M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 4.0K Dec 23 14:35 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:35 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove 'outputs/*': No such file or directory\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern regions.csv matched 1 files with total size 42\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern regions.csv into bundles of size 10 took 1 ms and produced 1 files and 5 bundles\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 5ef63099-385e-4416-9488-b96a7f4d8884 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 5746cfc9-a691-4891-8f70-6eadea28a563 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer ac71c854-9354-4516-82cd-a5a5d6a70996 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5746cfc9-a691-4891-8f70-6eadea28a563\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/ac71c854-9354-4516-82cd-a5a5d6a70996\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5ef63099-385e-4416-9488-b96a7f4d8884\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/ac71c854-9354-4516-82cd-a5a5d6a70996, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5746cfc9-a691-4891-8f70-6eadea28a563, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/5ef63099-385e-4416-9488-b96a7f4d8884, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00003\n",
      "Dec 23, 2021 2:35:47 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-4d1cb4e2-d1a6-4887-8fba-ef5042c281c0/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2,Western*\n",
      "4,Southern*\n",
      "3,Northern*\n",
      "1,Eastern*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class Read1 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new DoFn<String, String>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    String element = c.element();\n",
    "                    // String[] elements = element.split(\",\");\n",
    "                    c.output(element + \"*\");\n",
    "                }\n",
    "            }));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc4515-7a9b-40f9-99cf-c456065c3e11",
   "metadata": {},
   "source": [
    "## Java ParDo using a defined class instead of an anonynous class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb8543a5-9d2e-4a6e-81f4-5ae59aedcf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 8 executed, 1 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 254M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 5.8K Dec 23 14:46 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:35 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:47 Read2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 2:47:17 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern regions.csv matched 1 files with total size 42\n",
      "Dec 23, 2021 2:47:17 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern regions.csv into bundles of size 10 took 1 ms and produced 1 files and 5 bundles\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer bb9150b6-c719-478e-82e2-c67841a4cc12 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 29a24e0c-8b5c-47d9-9ab3-f066b93db8f7 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 67d205ba-d307-4a14-a632-5d2e909c86f6 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/bb9150b6-c719-478e-82e2-c67841a4cc12\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/67d205ba-d307-4a14-a632-5d2e909c86f6\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/29a24e0c-8b5c-47d9-9ab3-f066b93db8f7\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Creating 1 empty output shards in addition to 3 written for destination null.\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Opening empty writer e3ad9c04-a2a9-49bf-a5f9-7316bd928039 for destination null\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/e3ad9c04-a2a9-49bf-a5f9-7316bd928039\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/67d205ba-d307-4a14-a632-5d2e909c86f6, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/bb9150b6-c719-478e-82e2-c67841a4cc12, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00003-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/29a24e0c-8b5c-47d9-9ab3-f066b93db8f7, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/e3ad9c04-a2a9-49bf-a5f9-7316bd928039, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@210ab13f, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00004\n",
      "Dec 23, 2021 2:47:18 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-ad56a73e-21bf-4fdd-8dd3-d036c09b1dc8/].\n",
      "\n",
      "BUILD SUCCESSFUL in 6s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "3,Northern*\n",
      "2,Western*\n",
      "4,Southern*\n",
      "1,Eastern*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class Read2 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"regions.csv\";\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new AddStar()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    static class AddStar extends DoFn<String, String> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String line, OutputReceiver<String> out) {\n",
    "            out.output(line + \"*\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cae856-d38b-4ce9-a4c1-511284e1f9bc",
   "metadata": {},
   "source": [
    "## Python parse as a model class based on typing.NamedTuple so you can use properties instead of keys and use the Filter PTransform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc0dd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "class StartsWithSFilter(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if element.territoryname.startswith('S'):\n",
    "            yield element\n",
    "            \n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter 1' >> beam.Filter(lambda x : x.regionid % 2 == 0)\n",
    "          | 'Filter 2' >> beam.Filter(lambda x : x.territoryname.startswith('S'))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7e1e99c-eece-43f4-9b8e-2ba9df28d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m\n",
      "> Task :compileJava\n",
      "Note: /home/jupyter/Dataflowclass1/src/main/java/samples/quickstart/ReadTerritories.java uses or overrides a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 8 executed, 1 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 296M\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:38 Create1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 07:02 Create2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:26 Create3.jar\n",
      "-rw-r--r-- 1 root root 5.4K Dec 23 15:53 Dataflowclass1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:35 Read1.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 14:47 Read2.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 15:54 ReadTerritories.jar\n",
      "-rw-r--r-- 1 root root  43M Dec 23 06:30 WordCount.jar\n",
      "\n",
      ">> rm outputs/*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove 'outputs/*': No such file or directory\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 23, 2021 3:54:15 PM org.apache.beam.sdk.io.FileBasedSource getEstimatedSizeBytes\n",
      "INFO: Filepattern territories.csv matched 1 files with total size 933\n",
      "Dec 23, 2021 3:54:15 PM org.apache.beam.sdk.io.FileBasedSource split\n",
      "INFO: Splitting filepattern territories.csv into bundles of size 233 took 2 ms and produced 1 files and 4 bundles\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 8f81cc36-892d-44b3-a98c-033b5bd681f1 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 54e46751-8d9c-4c47-93ce-d31ffcdf3755 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer d28026a7-675d-4f0d-ab9b-431702008e94 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 7060f44a-a933-4938-a248-82fa8ddf8860 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/d28026a7-675d-4f0d-ab9b-431702008e94\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/8f81cc36-892d-44b3-a98c-033b5bd681f1\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/54e46751-8d9c-4c47-93ce-d31ffcdf3755\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/7060f44a-a933-4938-a248-82fa8ddf8860\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 4 file results\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 4.\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/8f81cc36-892d-44b3-a98c-033b5bd681f1, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00001-of-00004\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/d28026a7-675d-4f0d-ab9b-431702008e94, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00002-of-00004\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/7060f44a-a933-4938-a248-82fa8ddf8860, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00003-of-00004\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/54e46751-8d9c-4c47-93ce-d31ffcdf3755, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@58e1d9d, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /home/jupyter/Dataflowclass1/outputs/part-00000-of-00004\n",
      "Dec 23, 2021 3:54:16 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/home/jupyter/Dataflowclass1/outputs/.temp-beam-642ee5dd-6860-4961-9509-99e4f11c616e/].\n",
      "\n",
      "BUILD SUCCESSFUL in 6s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      ">> cat outputs/part*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"outputs/part\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", Filter.by(new SerializableFunction<Territory, Boolean>() {\n",
    "                @Override\n",
    "                public Boolean apply(Territory t) {\n",
    "                    return t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\");\n",
    "                }\n",
    "            }));                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "     static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64066481-ac7d-40ce-9996-8b681775835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "! rm src/main/java/samples/quickstart/*.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d6ae9-a392-4d7f-9222-017e3f2a8d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Apache Beam 2.34.0 for Python 3",
   "language": "python",
   "name": "01-apache-beam-2.34.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
