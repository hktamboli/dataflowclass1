{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b359750-81d1-48c1-a863-296635114ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Initialization Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5ce6c-55cb-45b7-9ad1-370ee54bf5c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install a Spark docker using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ac48-b14e-4e01-8290-b9799ba6e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker pull bitnami/spark && \\\n",
    "docker network create spark_network && \\\n",
    "docker run -d --name spark --network=spark_network -e SPARK_MODE=master bitnami/spark\n",
    "! ln -s /opt/conda/lib/libtinfo.so /opt/conda/lib/libtinfor.so.6\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659dd20-a9ab-4008-8bce-a5ff5acf5690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb46e-7eef-4af7-bd41-587e716e3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "def install(package):\n",
    "    if hasattr(pip, 'main'):\n",
    "        pip.main(['install', package])\n",
    "    else:\n",
    "        pip._internal.main(['install', package])\n",
    "\n",
    "install('pyspark')\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140ae18-4293-4560-91d6-4324e41fb0b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialize the Spark context variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6573258c-97d5-4282-9278-cfe9ad82a186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing pyspark\n",
      "pyspark initialized\n",
      "<SparkContext master=local[*] appName=Notebook> <pyspark.sql.session.SparkSession object at 0x7f14f479ab50>\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def initspark(appname = \"Notebook\", servername = \"local[*]\"):\n",
    "    print ('initializing pyspark')\n",
    "    conf = SparkConf().setAppName(appname).setMaster(servername)\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession.builder.appName(appname).enableHiveSupport().getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "    print ('pyspark initialized')\n",
    "    return sc, spark, conf\n",
    "\n",
    "sc, spark, conf = initspark()\n",
    "print(sc, spark)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbca6a8-f8cc-45ac-8a62-0d14bfb665d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialize helper functions to run Java inside cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d334c3-e064-4241-aa70-26d939b3e166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /opt/gradle-5.0/bin/gradle --console=plain -v\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/get-started/try-apache-beam-java.ipynb#scrollTo=CgTXBdTsBn1F\n",
    "# Run and print a shell command.\n",
    "def run(cmd, progress = True, verbose = False):\n",
    "  if progress:\n",
    "      print('>> {}'.format(cmd))\n",
    "    \n",
    "  if verbose:\n",
    "      !{cmd}  # This is magic to run 'cmd' in the shell.\n",
    "      print('')\n",
    "  else:\n",
    "      ! {cmd} > /dev/null 2>&1\n",
    "\n",
    "import os\n",
    "\n",
    "# Download the gradle source.\n",
    "gradle_version = 'gradle-5.0'\n",
    "gradle_path = f\"/opt/{gradle_version}\"\n",
    "if not os.path.exists(gradle_path):\n",
    "  run(f\"wget -q -nc -O gradle.zip https://services.gradle.org/distributions/{gradle_version}-bin.zip\")\n",
    "  run('unzip -q -d /opt gradle.zip')\n",
    "  run('rm -f gradle.zip')\n",
    "\n",
    "# We're choosing to use the absolute path instead of adding it to the $PATH environment variable.\n",
    "def gradle(args):\n",
    "  run(f\"{gradle_path}/bin/gradle --console=plain {args}\")\n",
    "\n",
    "gradle('-v')\n",
    "\n",
    "! mkdir -p src/main/java/samples/quickstart/\n",
    "print('Done')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716a7d4-28ea-40e7-90db-3e762b7dbcf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Definition for ___%%java___ Python magic cell function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a97925b-df54-4700-bb8b-d4a3e2305b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.magic import register_line_magic, register_cell_magic, register_line_cell_magic\n",
    "@register_cell_magic\n",
    "def java(line, cell):\n",
    "    \"\"\"\n",
    "    Written by Joseph Gagliardo Jr.\n",
    "    joegagliardo@gmail.com\n",
    "    2021-12-22\n",
    "    \"\"\"\n",
    "    text = \"\"\"\n",
    "plugins {\n",
    "  // id 'idea'     // Uncomment for IntelliJ IDE\n",
    "  // id 'eclipse'  // Uncomment for Eclipse IDE\n",
    "\n",
    "  // Apply java plugin and make it a runnable application.\n",
    "  id 'java'\n",
    "  id 'application'\n",
    "\n",
    "  // 'shadow' allows us to embed all the dependencies into a fat jar.\n",
    "  id 'com.github.johnrengelman.shadow' version '4.0.3'\n",
    "}\n",
    "\n",
    "// This is the path of the main class, stored within ./src/main/java/\n",
    "mainClassName = 'samples.quickstart.{class_name}'\n",
    "\n",
    "// Declare the sources from which to fetch dependencies.\n",
    "repositories {\n",
    "  mavenCentral()\n",
    "}\n",
    "\n",
    "// Java version compatibility.\n",
    "sourceCompatibility = 1.8\n",
    "targetCompatibility = 1.8\n",
    "\n",
    "// Use the latest Apache Beam major version 2.\n",
    "// You can also lock into a minor version like '2.9.+'.\n",
    "ext.apacheBeamVersion = '2.+'\n",
    "\n",
    "// Declare the dependencies of the project.\n",
    "dependencies {\n",
    "  shadow \"org.apache.beam:beam-sdks-java-core:$apacheBeamVersion\"\n",
    "\n",
    "  runtime \"org.apache.beam:beam-runners-direct-java:$apacheBeamVersion\"\n",
    "  runtime \"org.slf4j:slf4j-api:1.+\"\n",
    "  runtime \"org.slf4j:slf4j-jdk14:1.+\"\n",
    "\n",
    "  testCompile \"junit:junit:4.+\"\n",
    "}\n",
    "\n",
    "// Configure 'shadowJar' instead of 'jar' to set up the fat jar.\n",
    "shadowJar {\n",
    "  baseName = '{class_name}' // Name of the fat jar file.\n",
    "  classifier = null       // Set to null, otherwise 'shadow' appends a '-all' to the jar file name.\n",
    "  manifest {\n",
    "    attributes('Main-Class': mainClassName)  // Specify where the main class resides.\n",
    "  }\n",
    "}\n",
    "\"\"\"   \n",
    "    start = cell.find('class ')\n",
    "    end = cell.find(' {')\n",
    "    class_name = cell[start+6:end]\n",
    "    progress = 'noprogress' not in line.lower()\n",
    "    verbose = 'verbose' in line.lower()\n",
    "    output = 'nooutput' not in line.lower()\n",
    "\n",
    "    # if len(line) == 0:\n",
    "    #     start = cell.find('class ')\n",
    "    #     end = cell.find(' {')\n",
    "    #     class_name = cell[start+6:end]\n",
    "    # else:\n",
    "    #     class_name = line\n",
    "        \n",
    "    \n",
    "    run('rm src/main/java/samples/quickstart/*.java')\n",
    "    run('rm build/libs/*.jar')\n",
    "    run('rm -rf /tmp/outputs*', progress = progress, verbose = verbose)\n",
    "\n",
    "    with open('build.gradle', 'w') as f:\n",
    "        f.write(text.replace('{class_name}', class_name))\n",
    "\n",
    "    with open(f'src/main/java/samples/quickstart/{class_name}.java', 'w') as f:\n",
    "        f.write(cell)\n",
    "        \n",
    "    # Build the project.\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain build\", progress = progress, verbose = verbose)\n",
    "    run('ls -lh build/libs/', progress = progress, verbose = verbose)\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain runShadow\", progress = progress, verbose = verbose)\n",
    "    # run('head -n 20 /tmp/outputs*')\n",
    "    if output:\n",
    "        run('cat /tmp/outputs*', progress = False, verbose = True)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2bd3e-f247-4edc-87d1-27aeb165ecc1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20303e33-eb39-459b-85cf-743209e5322d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf532-1859-4134-a64f-63b6f14f4268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. ___Create___ allows you to upload data into a PCollection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f8b59-343b-45c9-b02d-7399bceefbe0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1397c54-3ff7-4188-bc9e-c72bef0d2670",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Non Beam example of applying a map function to a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0dd11-7c70-4a35-bc61-51d36bcfaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['one', 'two', 'three', 'four']\n",
    "print(list(map(str.title, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb1aad-7fe0-4b99-96f4-b30fbaae23ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation, turn the local collection into a PCollection and apply a Map PTransform on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedc12b-27d2-4098-85f0-feba2f9e14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(str.title)\n",
    "          | beam.Map(print)\n",
    "    )\n",
    "\n",
    "# lines is a PCollection object\n",
    "print('lines = ', lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c8ecc-a678-48eb-9ae8-7fd3e34b8a6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a lambda instead of a built in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9b54f-3a72-4688-a5d1-545077e6b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(lambda x : x.title())\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dfeee-d660-47fb-92f7-7a0c3bcbb302",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4cad9-4ed9-4c26-8894-e7d84eff8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def title(x):\n",
    "    return x.title()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(title)\n",
    "          | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f09af7-2678-4b0c-879e-c567625a4a83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Python the pipe `|` is actually just an operator overload to call the apply method of the pipeline. You would never do this in python, but it helps to understand what is going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e7a3d-99fc-4904-a1cd-baf93d088b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = ((p | beam.Create(['one', 'two', 'three', 'four']))\n",
    "             .apply(beam.Map(str.title)) \n",
    "             .apply(beam.Map(print))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057071-63e3-4414-820d-71e07ed0959d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Spark equivalent would be to pload a local Python list into a Spark RDD and do a simple transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b110e0-45a0-476b-a2ca-d33cecaec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = ( sc.parallelize(['one', 'two', 'three', 'four'])\n",
    "        \n",
    "#           .map(str.title)\n",
    "       )\n",
    "rdd1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebfb43-8dd1-491e-9422-350ecda44d1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33b715-0a74-4b46-8736-7798c51b313a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using a ___lambda___.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8420314f-13dd-410f-90a8-569c9f3770ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :jar\n",
      "> Task :startScripts UP-TO-DATE\n",
      "> Task :distTar\n",
      "> Task :distZip\n",
      "> Task :shadowJar\n",
      "> Task :startShadowScripts\n",
      "> Task :shadowDistTar\n",
      "> Task :shadowDistZip\n",
      "> Task :assemble\n",
      "> Task :compileTestJava NO-SOURCE\n",
      "> Task :processTestResources NO-SOURCE\n",
      "> Task :testClasses UP-TO-DATE\n",
      "> Task :test NO-SOURCE\n",
      "> Task :check UP-TO-DATE\n",
      "> Task :build\n",
      "\n",
      "BUILD SUCCESSFUL in 17s\n",
      "9 actionable tasks: 7 executed, 2 up-to-date\n",
      "\u001b[m\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 43M\n",
      "-rw-r--r-- 1 root root  43M Dec 27 19:14 Create1.jar\n",
      "-rw-r--r-- 1 root root 2.2K Dec 27 19:14 dataflowclass1.jar\n",
      "\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[m> Task :compileJava UP-TO-DATE\n",
      "> Task :processResources NO-SOURCE\n",
      "> Task :classes UP-TO-DATE\n",
      "> Task :shadowJar UP-TO-DATE\n",
      "> Task :startShadowScripts UP-TO-DATE\n",
      "> Task :installShadowDist\n",
      "\n",
      "> Task :runShadow\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer 05521177-bc20-499b-939c-086fb2f75c63 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer ecd5222e-5161-4fe9-b32f-e8f8f44827e8 for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.WriteFiles$WriteShardsIntoTempFilesFn processElement\n",
      "INFO: Opening writer f7e34cc6-6952-4f93-8419-2827178e5d0f for window org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92 pane PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0} destination null\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/f7e34cc6-6952-4f93-8419-2827178e5d0f\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/ecd5222e-5161-4fe9-b32f-e8f8f44827e8\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/05521177-bc20-499b-939c-086fb2f75c63\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn process\n",
      "INFO: Finalizing 3 file results\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Finalizing for destination null num shards 3.\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Creating 1 empty output shards in addition to 3 written for destination null.\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation createMissingEmptyShards\n",
      "INFO: Opening empty writer 30f531f8-6f11-4d7c-ac50-4722bf0ac522 for destination null\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$Writer close\n",
      "INFO: Successfully wrote temporary file /tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/30f531f8-6f11-4d7c-ac50-4722bf0ac522\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/05521177-bc20-499b-939c-086fb2f75c63, shard=0, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00000-of-00004\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/ecd5222e-5161-4fe9-b32f-e8f8f44827e8, shard=2, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00002-of-00004\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/f7e34cc6-6952-4f93-8419-2827178e5d0f, shard=3, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00003-of-00004\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation moveToOutputFiles\n",
      "INFO: Will copy temporary file FileResult{tempFilename=/tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/30f531f8-6f11-4d7c-ac50-4722bf0ac522, shard=1, window=org.apache.beam.sdk.transforms.windowing.GlobalWindow@7a6d7e92, paneInfo=PaneInfo{isFirst=true, isLast=true, timing=ON_TIME, index=0, onTimeIndex=0}} to final location /tmp/outputs-00001-of-00004\n",
      "Dec 27, 2021 7:14:34 PM org.apache.beam.sdk.io.FileBasedSink$WriteOperation removeTemporaryFiles\n",
      "WARNING: Failed to match temporary files under: [/tmp/.temp-beam-38b9c498-6368-4858-a330-a9d94ac183a5/].\n",
      "\n",
      "BUILD SUCCESSFUL in 5s\n",
      "5 actionable tasks: 2 executed, 3 up-to-date\n",
      "\u001b[m\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "THREE\n",
      "TWO\n",
      "FOUR\n",
      "ONE\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create1 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.into(TypeDescriptors.strings()).via((String line) -> line.toUpperCase()));\n",
    "        lines.apply(TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db7b6-c42d-4268-847c-24a9c39df7e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simple transformation using ___SimpleFunction___ instead of lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff75092-0480-4784-afba-9616e9e60d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "THREE\n",
      "TWO\n",
      "ONE\n",
      "FOUR\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create2 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return line.toUpperCase();\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27aee-6b1c-44a5-815d-31d039c24475",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Java simple transformation using ___SimpleFunction___ to wrap a User Defined Function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5c178e-2cfa-4316-95de-5779b243f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "ONE\n",
      "TWO\n",
      "FOUR\n",
      "THREE\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create3 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return upper(line);\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    public static String upper(String line) {\n",
    "        return line.toUpperCase();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5781d-6836-44ce-bca3-34585c5e352f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591af669-d68f-471e-a03a-82dbaaa7a609",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931beffe-4cf4-48e4-a28d-8a2dfaed62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. ___ReadFromText___ allows you to read a text file into a __PCollection__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db17f3-ea3a-4418-b12e-5b859d1e9856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab382f85-16e9-4544-a56b-06c6d4edc7b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### It's a good idea to start naming the steps for debugging and monitoring later. Names must be unique in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53066990-43fc-42c0-9545-ddf723145fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove '/tmp/outputs*': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(1, 'EASTERN')\n",
      "(2, 'WESTERN')\n",
      "(3, 'NORTHERN')\n",
      "(4, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "! rm /tmp/outputs*\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.Map(lambda x : x.split(','))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "          | 'Write' >> WriteToText('/tmp/outputs')\n",
    "#          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "    #p.run() # implicit in Python when using with block\n",
    "\n",
    "! cat /tmp/outputs*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88479c-60c3-48c3-b8c1-3e8113f0d39a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Read from CSV and use ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94887a8a-f945-414f-bfaa-2e72fa1aa746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Eastern')\n",
      "(2, 'Western')\n",
      "(3, 'Northern')\n",
      "(4, 'Southern')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionParseTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "#        yield (int(regionid), regionname.upper()) # Include a transformation instead of doing it as a separate step\n",
    "\n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.ParDo(RegionParseTuple())\n",
    "          #| 'Write' >> WriteToText('regions.out')\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3fd79-61c1-4d9f-acf1-5ee7af3ff832",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d05cc4-e81e-44d7-adad-d38ee19848c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Read from CSV and use Map with ___lambda___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28492eea-c43a-43ab-aa7f-ceca3f199a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "3,NORTHERN\n",
      "4,SOUTHERN\n",
      "1,EASTERN\n",
      "2,WESTERN\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "\n",
    "public class ReadRegions1 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", MapElements.into(TypeDescriptors.strings()).via((String element) -> element.toUpperCase()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd1da-0fed-43c9-8ab1-e1b73cc9534f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ___ParDo___ Example using anonymous class inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14327a97-f8cd-489b-87eb-82ad962f701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "4,Southern*\n",
      "3,Northern*\n",
      "2,Western*\n",
      "1,Eastern*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class ReadRegions2 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new DoFn<String, String>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    String element = c.element();\n",
    "                    // String[] elements = element.split(\",\");\n",
    "                    c.output(element + \"*\");\n",
    "                }\n",
    "            }));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc4515-7a9b-40f9-99cf-c456065c3e11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ___ParDo___ using a defined class instead of an anonynous class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb8543a5-9d2e-4a6e-81f4-5ae59aedcf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "4,Southern*\n",
      "3,Northern*\n",
      "1,Eastern*\n",
      "2,Western*\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class ReadRegions3 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new AddStar()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    static class AddStar extends DoFn<String, String> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String line, OutputReceiver<String> out) {\n",
    "            out.output(line + \"*\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ce401-ba9d-4fd8-a21c-670049b2a716",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889a629-d0e8-4cbc-9673-840de48cbf00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cae856-d38b-4ce9-a4c1-511284e1f9bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Parse into a model class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4b34a-2b4a-4f8f-aa9c-af369f7ef9bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebb6b4-3c55-4b79-a0d8-4d3c017162c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a model based on ___typing.NamedTuple___ so you can use properties instead of keys and use the Filter __PTransform__ with ___lambda___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0dd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter 1' >> beam.Filter(lambda x : x.regionid % 2 == 0)\n",
    "          | 'Filter 2' >> beam.Filter(lambda x : x.territoryname.startswith('S'))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230451d-cfb3-450f-82b6-e5dd24e6e2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use Filter with a UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07089b39-7ccf-42cf-830b-3189ab269566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "def startsWithS(element):\n",
    "    return element.territoryname.startswith('S')\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.Filter(startsWithS)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac3ac5-d61b-496d-bf95-2801b014b28e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use a ParDo class to accomplish filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54691011-9bfd-49d9-8992-ff1333c65824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "class StartsWithSFilter(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if element.territoryname.startswith('S'):\n",
    "            yield element\n",
    "            \n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.ParDo(StartsWithSFilter())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39807dbe-b99a-4767-be21-16b38ff287f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Put the parsing and filtering all into one ParDo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2091357-5550-42fb-8810-3e5fc8d2cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        if territoryname.startswith('S'):\n",
    "            yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "#          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7777973-1216-4e12-995f-5c5a8247b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'projectNumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-024f390cd8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# records = (p | 'Read' >> beam.io.ReadFromAvro('gs://joey-shared-bucket/datasets/northwind/AVRO/categories/categories.avro')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   records = (p | 'Read' >> beam.io.ReadFromText('gs://joey-shared-bucket/datasets/northwind/CSV/categories/categories.csv')\n\u001b[0;32m----> 4\u001b[0;31m              | beam.Map(print))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     self._latest_run_result = self.run_via_runner_api(\n\u001b[0;32m--> 196\u001b[0;31m         pipeline.to_runner_api(default_environment=self._default_environment))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latest_run_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# TODO(pabloem, BEAM-7514): Create a watermark manager (that has access to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m#   the teststream (if any), and all the stages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m           stage_results = self._run_stage(\n\u001b[0;32m--> 385\u001b[0;31m               runner_execution_context, bundle_context_manager)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m           assert (\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, runner_execution_context, bundle_context_manager)\u001b[0m\n\u001b[1;32m    651\u001b[0m               \u001b[0minput_timers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m               \u001b[0mexpected_timer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m               bundle_manager))\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatermark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwatermark_updates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, data_input, data_output, input_timers, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     result, splits = bundle_manager.process_bundle(\n\u001b[0;32m--> 770\u001b[0;31m         data_input, data_output, input_timers, expected_timer_output)\n\u001b[0m\u001b[1;32m    771\u001b[0m     \u001b[0;31m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;31m# Deferred inputs can be:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mprocess_bundle_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             cache_tokens=[next(self._cache_token_generator)]))\n\u001b[0;32m-> 1080\u001b[0;31m     \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bundle_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0msplit_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: List[beam_fn_api_pb2.ProcessBundleSplitResponse]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m       \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'control_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mControlFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mdo_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;31m# E.g. if register is set, this will call self.register(request.register))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       return getattr(self, request_type)(\n\u001b[0;32m--> 598\u001b[0;31m           getattr(request, request_type), request.instruction_id)\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m           delayed_applications, requests_finalization = (\n\u001b[0;32m--> 635\u001b[0;31m               bundle_processor.process_bundle(instruction_id))\n\u001b[0m\u001b[1;32m    636\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundle_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_cache_metrics_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m    994\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_fn_api_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             input_op_by_transform_id[element.transform_id].process_encoded(\n\u001b[0;32m--> 996\u001b[0;31m                 element.data)\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Finish all operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    219\u001b[0m       decoded_value = self.windowed_coder_impl.decode_from_stream(\n\u001b[1;32m    220\u001b[0m           input_stream, True)\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_to_pcollection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process_with_sized_restriction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputProcessor.process_outputs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/textio.py\u001b[0m in \u001b[0;36mread_records\u001b[0;34m(self, file_name, range_tracker)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mrange_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_split_points_unclaimed_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_points_unclaimed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_to_read\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m       position_after_processing_header_lines = (\n\u001b[1;32m    165\u001b[0m           self._process_header(file_to_read, read_buffer))\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/filebasedsource.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;34m'application/octet-stream'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         compression_type=self._compression_type)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcheck_accessible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_pattern'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/filesystems.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mime_type, compression_type)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \"\"\"\n\u001b[1;32m    243\u001b[0m     \u001b[0mfilesystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmime_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/gcp/gcsfilesystem.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mime_type, compression_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mclose\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmime_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_file_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_file_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/gcp/gcsfilesystem.py\u001b[0m in \u001b[0;36m_path_open\u001b[0;34m(self, path, mode, mime_type, compression_type)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mcompression_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compression_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mmime_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompressionTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmime_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmime_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mraw_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcsio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGcsIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmime_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmime_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCompressionTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNCOMPRESSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mraw_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/gcp/gcsio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, filename, mode, read_buffer_size, mime_type)\u001b[0m\n\u001b[1;32m    225\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m           \u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_buffer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m           get_project_number=self.get_project_number)\n\u001b[0m\u001b[1;32m    228\u001b[0m       return io.BufferedReader(\n\u001b[1;32m    229\u001b[0m           DownloaderStream(\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/gcp/gcsio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, client, path, buffer_size, get_project_number)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_project_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_project_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0mproject_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_project_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;31m# Create a request count metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.34.0/lib/python3.7/site-packages/apache_beam/io/gcp/gcsio.py\u001b[0m in \u001b[0;36mget_project_number\u001b[0;34m(self, bucket)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket_to_project_number\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mbucket_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket_to_project_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojectNumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket_to_project_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'projectNumber'"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "  # records = (p | 'Read' >> beam.io.ReadFromAvro('gs://joey-shared-bucket/datasets/northwind/AVRO/categories/categories.avro')\n",
    "  records = (p | 'Read' >> beam.io.ReadFromText('gs://joey-shared-bucket/datasets/northwind/CSV/categories/categories.csv')\n",
    "             | beam.Map(print))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb0592-e4b0-4204-b4f0-775e75d8f02c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e66252-cdcd-411c-866e-44857a6b4379",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using a Pardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e1e99c-eece-43f4-9b8e-2ba9df28d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", ParDo.of(new FilterTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378c125-c36c-4ac0-9443-35f54539258a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using and anonymous class to create the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7292cee7-d525-44b6-a9db-36b5f3acf839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", Filter.by(new SerializableFunction<Territory, Boolean>() {\n",
    "                @Override\n",
    "                public Boolean apply(Territory t) {\n",
    "                    return t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\");\n",
    "                }\n",
    "            }))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2fc88-b027-42bf-9136-c02d6583a04c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9339e563-880b-4fae-9cc6-3e8ba50d85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "(territoryID = 95060, territoryName = Santa Cruz, regionID = 2)\n",
      "(territoryID = 98104, territoryName = Seattle, regionID = 2)\n",
      "(territoryID = 94105, territoryName = San Francisco, regionID = 2)\n",
      "(territoryID = 48075, territoryName = Southfield, regionID = 3)\n",
      "(territoryID = 31406, territoryName = Savannah, regionID = 4)\n",
      "(territoryID = 85251, territoryName = Scottsdale, regionID = 2)\n",
      "(territoryID = 95054, territoryName = Santa Clara, regionID = 2)\n",
      "(territoryID = 90405, territoryName = Santa Monica, regionID = 2)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (territoryName.startsWith(\"S\")) {\n",
    "                    c.output(new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505552a2-9b45-48b2-a0b1-5165573d33bf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72891e0-232c-4a11-a7ec-1880c8c71425",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5c5a3-327e-4279-af35-bcf57e7ab9f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5. Create multiple outputs from a single read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc9883-ba3b-4b67-ad1c-05b281ef9474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edcd4b-aac7-412a-a728-d772fd625f56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Send the same data down multiple paths, such as to group it on two different keys with one read from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cfb9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Lower\n",
      "(1581, 'westboro', 1)\n",
      "(1730, 'bedford', 1)\n",
      "(1833, 'georgetow', 1)\n",
      "(2116, 'boston', 1)\n",
      "(2139, 'cambridge', 1)\n",
      "(2184, 'braintree', 1)\n",
      "(2903, 'providence', 1)\n",
      "(3049, 'hollis', 3)\n",
      "(3801, 'portsmouth', 3)\n",
      "(6897, 'wilton', 1)\n",
      "(7960, 'morristown', 1)\n",
      "(8837, 'edison', 1)\n",
      "(10019, 'new york', 1)\n",
      "(10038, 'new york', 1)\n",
      "(11747, 'mellvile', 1)\n",
      "(14450, 'fairport', 1)\n",
      "(19428, 'philadelphia', 3)\n",
      "(19713, 'neward', 1)\n",
      "(20852, 'rockville', 1)\n",
      "(27403, 'greensboro', 1)\n",
      "(27511, 'cary', 1)\n",
      "(29202, 'columbia', 4)\n",
      "(30346, 'atlanta', 4)\n",
      "(31406, 'savannah', 4)\n",
      "(32859, 'orlando', 4)\n",
      "(33607, 'tampa', 4)\n",
      "(40222, 'louisville', 1)\n",
      "(44122, 'beachwood', 3)\n",
      "(45839, 'findlay', 3)\n",
      "(48075, 'southfield', 3)\n",
      "(48084, 'troy', 3)\n",
      "(48304, 'bloomfield hills', 3)\n",
      "(53404, 'racine', 3)\n",
      "(55113, 'roseville', 3)\n",
      "(55439, 'minneapolis', 3)\n",
      "(60179, 'hoffman estates', 2)\n",
      "(60601, 'chicago', 2)\n",
      "(72716, 'bentonville', 4)\n",
      "(75234, 'dallas', 4)\n",
      "(78759, 'austin', 4)\n",
      "(80202, 'denver', 2)\n",
      "(80909, 'colorado springs', 2)\n",
      "(85014, 'phoenix', 2)\n",
      "(85251, 'scottsdale', 2)\n",
      "(90405, 'santa monica', 2)\n",
      "(94025, 'menlo park', 2)\n",
      "(94105, 'san francisco', 2)\n",
      "(95008, 'campbell', 2)\n",
      "(95054, 'santa clara', 2)\n",
      "(95060, 'santa cruz', 2)\n",
      "(98004, 'bellevue', 2)\n",
      "(98052, 'redmond', 2)\n",
      "(98104, 'seattle', 2)\n",
      "Upper\n",
      "(1581, 'WESTBORO', 1)\n",
      "(1730, 'BEDFORD', 1)\n",
      "(1833, 'GEORGETOW', 1)\n",
      "(2116, 'BOSTON', 1)\n",
      "(2139, 'CAMBRIDGE', 1)\n",
      "(2184, 'BRAINTREE', 1)\n",
      "(2903, 'PROVIDENCE', 1)\n",
      "(3049, 'HOLLIS', 3)\n",
      "(3801, 'PORTSMOUTH', 3)\n",
      "(6897, 'WILTON', 1)\n",
      "(7960, 'MORRISTOWN', 1)\n",
      "(8837, 'EDISON', 1)\n",
      "(10019, 'NEW YORK', 1)\n",
      "(10038, 'NEW YORK', 1)\n",
      "(11747, 'MELLVILE', 1)\n",
      "(14450, 'FAIRPORT', 1)\n",
      "(19428, 'PHILADELPHIA', 3)\n",
      "(19713, 'NEWARD', 1)\n",
      "(20852, 'ROCKVILLE', 1)\n",
      "(27403, 'GREENSBORO', 1)\n",
      "(27511, 'CARY', 1)\n",
      "(29202, 'COLUMBIA', 4)\n",
      "(30346, 'ATLANTA', 4)\n",
      "(31406, 'SAVANNAH', 4)\n",
      "(32859, 'ORLANDO', 4)\n",
      "(33607, 'TAMPA', 4)\n",
      "(40222, 'LOUISVILLE', 1)\n",
      "(44122, 'BEACHWOOD', 3)\n",
      "(45839, 'FINDLAY', 3)\n",
      "(48075, 'SOUTHFIELD', 3)\n",
      "(48084, 'TROY', 3)\n",
      "(48304, 'BLOOMFIELD HILLS', 3)\n",
      "(53404, 'RACINE', 3)\n",
      "(55113, 'ROSEVILLE', 3)\n",
      "(55439, 'MINNEAPOLIS', 3)\n",
      "(60179, 'HOFFMAN ESTATES', 2)\n",
      "(60601, 'CHICAGO', 2)\n",
      "(72716, 'BENTONVILLE', 4)\n",
      "(75234, 'DALLAS', 4)\n",
      "(78759, 'AUSTIN', 4)\n",
      "(80202, 'DENVER', 2)\n",
      "(80909, 'COLORADO SPRINGS', 2)\n",
      "(85014, 'PHOENIX', 2)\n",
      "(85251, 'SCOTTSDALE', 2)\n",
      "(90405, 'SANTA MONICA', 2)\n",
      "(94025, 'MENLO PARK', 2)\n",
      "(94105, 'SAN FRANCISCO', 2)\n",
      "(95008, 'CAMPBELL', 2)\n",
      "(95054, 'SANTA CLARA', 2)\n",
      "(95060, 'SANTA CRUZ', 2)\n",
      "(98004, 'BELLEVUE', 2)\n",
      "(98052, 'REDMOND', 2)\n",
      "(98104, 'SEATTLE', 2)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        yield Territory(int(element['territoryid']), element['territorydescription'], int(element['regionid']))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/AVRO/territories/territories.avro'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (p | 'Read' >> beam.io.ReadFromAvro(territoriesfilename)\n",
    "                     | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "                  )\n",
    "\n",
    "    # Branch 1\n",
    "    (territories \n",
    "         | 'Lowercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.lower(), x.regionid))\n",
    "         | 'Write Lower' >> WriteToText('/tmp/territories_lower.out')\n",
    "    )\n",
    "    \n",
    "    # Branch 2\n",
    "    (territories \n",
    "         | 'Uppercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.upper(), x.regionid))\n",
    "         | 'Write Upper' >> WriteToText('/tmp/territories_upper.out')\n",
    "    )\n",
    "\n",
    "! echo \"Lower\" && cat /tmp/territories_lower.out* && echo \"Upper\" && cat /tmp/territories_upper.out*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7374d-4d8b-4923-81b6-4c32e9e13c99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use TaggedOutput in the ParDo to split data into two different paths with different data on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82d221e6-669a-40eb-b2bc-7cdcf693ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'territoryid': '01581', 'territoryname': 'Westboro', 'regionid': 1}\n",
      "{'territoryid': '01730', 'territoryname': 'Bedford', 'regionid': 1}\n",
      "{'territoryid': '01833', 'territoryname': 'Georgetow', 'regionid': 1}\n",
      "{'territoryid': '02116', 'territoryname': 'Boston', 'regionid': 1}\n",
      "{'territoryid': '02139', 'territoryname': 'Cambridge', 'regionid': 1}\n",
      "{'territoryid': '02184', 'territoryname': 'Braintree', 'regionid': 1}\n",
      "{'territoryid': '02903', 'territoryname': 'Providence', 'regionid': 1}\n",
      "{'territoryid': '03049', 'territoryname': 'Hollis', 'regionid': 3}\n",
      "{'territoryid': '03801', 'territoryname': 'Portsmouth', 'regionid': 3}\n",
      "{'territoryid': '06897', 'territoryname': 'Wilton', 'regionid': 1}\n",
      "{'territoryid': '07960', 'territoryname': 'Morristown', 'regionid': 1}\n",
      "{'territoryid': '08837', 'territoryname': 'Edison', 'regionid': 1}\n",
      "{'territoryid': '10019', 'territoryname': 'New York', 'regionid': 1}\n",
      "{'territoryid': '10038', 'territoryname': 'New York', 'regionid': 1}\n",
      "{'territoryid': '11747', 'territoryname': 'Mellvile', 'regionid': 1}\n",
      "{'territoryid': '14450', 'territoryname': 'Fairport', 'regionid': 1}\n",
      "{'territoryid': '19428', 'territoryname': 'Philadelphia', 'regionid': 3}\n",
      "{'territoryid': '19713', 'territoryname': 'Neward', 'regionid': 1}\n",
      "{'territoryid': '20852', 'territoryname': 'Rockville', 'regionid': 1}\n",
      "{'territoryid': '27403', 'territoryname': 'Greensboro', 'regionid': 1}\n",
      "{'territoryid': '27511', 'territoryname': 'Cary', 'regionid': 1}\n",
      "{'territoryid': '29202', 'territoryname': 'Columbia', 'regionid': 4}\n",
      "{'territoryid': '30346', 'territoryname': 'Atlanta', 'regionid': 4}\n",
      "{'territoryid': '31406', 'territoryname': 'Savannah', 'regionid': 4}\n",
      "{'territoryid': '32859', 'territoryname': 'Orlando', 'regionid': 4}\n",
      "{'territoryid': '33607', 'territoryname': 'Tampa', 'regionid': 4}\n",
      "{'territoryid': '40222', 'territoryname': 'Louisville', 'regionid': 1}\n",
      "{'territoryid': '44122', 'territoryname': 'Beachwood', 'regionid': 3}\n",
      "{'territoryid': '45839', 'territoryname': 'Findlay', 'regionid': 3}\n",
      "{'territoryid': '48075', 'territoryname': 'Southfield', 'regionid': 3}\n",
      "{'territoryid': '48084', 'territoryname': 'Troy', 'regionid': 3}\n",
      "{'territoryid': '48304', 'territoryname': 'Bloomfield Hills', 'regionid': 3}\n",
      "{'territoryid': '53404', 'territoryname': 'Racine', 'regionid': 3}\n",
      "{'territoryid': '55113', 'territoryname': 'Roseville', 'regionid': 3}\n",
      "{'territoryid': '55439', 'territoryname': 'Minneapolis', 'regionid': 3}\n",
      "{'territoryid': '60179', 'territoryname': 'Hoffman Estates', 'regionid': 2}\n",
      "{'territoryid': '60601', 'territoryname': 'Chicago', 'regionid': 2}\n",
      "{'territoryid': '72716', 'territoryname': 'Bentonville', 'regionid': 4}\n",
      "{'territoryid': '75234', 'territoryname': 'Dallas', 'regionid': 4}\n",
      "{'territoryid': '78759', 'territoryname': 'Austin', 'regionid': 4}\n",
      "{'territoryid': '80202', 'territoryname': 'Denver', 'regionid': 2}\n",
      "{'territoryid': '80909', 'territoryname': 'Colorado Springs', 'regionid': 2}\n",
      "{'territoryid': '85014', 'territoryname': 'Phoenix', 'regionid': 2}\n",
      "{'territoryid': '85251', 'territoryname': 'Scottsdale', 'regionid': 2}\n",
      "{'territoryid': '90405', 'territoryname': 'Santa Monica', 'regionid': 2}\n",
      "{'territoryid': '94025', 'territoryname': 'Menlo Park', 'regionid': 2}\n",
      "{'territoryid': '94105', 'territoryname': 'San Francisco', 'regionid': 2}\n",
      "{'territoryid': '95008', 'territoryname': 'Campbell', 'regionid': 2}\n",
      "{'territoryid': '95054', 'territoryname': 'Santa Clara', 'regionid': 2}\n",
      "{'territoryid': '95060', 'territoryname': 'Santa Cruz', 'regionid': 2}\n",
      "{'territoryid': '98004', 'territoryname': 'Bellevue', 'regionid': 2}\n",
      "{'territoryid': '98052', 'territoryname': 'Redmond', 'regionid': 2}\n",
      "{'territoryid': '98104', 'territoryname': 'Seattle', 'regionid': 2}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/PARQUET/territories/territories.parquet'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "  records = p | 'Read' >> beam.io.ReadFromParquet(territoriesfilename) | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a7649fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Evens\n",
      "Territory(territoryid=29202, territoryname='Columbia', regionid=4)\n",
      "Territory(territoryid=30346, territoryname='Atlanta', regionid=4)\n",
      "Territory(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "Territory(territoryid=32859, territoryname='Orlando', regionid=4)\n",
      "Territory(territoryid=33607, territoryname='Tampa', regionid=4)\n",
      "Territory(territoryid=60179, territoryname='Hoffman Estates', regionid=2)\n",
      "Territory(territoryid=60601, territoryname='Chicago', regionid=2)\n",
      "Territory(territoryid=72716, territoryname='Bentonville', regionid=4)\n",
      "Territory(territoryid=75234, territoryname='Dallas', regionid=4)\n",
      "Territory(territoryid=78759, territoryname='Austin', regionid=4)\n",
      "Territory(territoryid=80202, territoryname='Denver', regionid=2)\n",
      "Territory(territoryid=80909, territoryname='Colorado Springs', regionid=2)\n",
      "Territory(territoryid=85014, territoryname='Phoenix', regionid=2)\n",
      "Territory(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "Territory(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "Territory(territoryid=94025, territoryname='Menlo Park', regionid=2)\n",
      "Territory(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "Territory(territoryid=95008, territoryname='Campbell', regionid=2)\n",
      "Territory(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "Territory(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "Territory(territoryid=98004, territoryname='Bellevue', regionid=2)\n",
      "Territory(territoryid=98052, territoryname='Redmond', regionid=2)\n",
      "Territory(territoryid=98104, territoryname='Seattle', regionid=2)\n",
      "Odds\n",
      "Territory(territoryid=1581, territoryname='Westboro', regionid=1)\n",
      "Territory(territoryid=1730, territoryname='Bedford', regionid=1)\n",
      "Territory(territoryid=1833, territoryname='Georgetow', regionid=1)\n",
      "Territory(territoryid=2116, territoryname='Boston', regionid=1)\n",
      "Territory(territoryid=2139, territoryname='Cambridge', regionid=1)\n",
      "Territory(territoryid=2184, territoryname='Braintree', regionid=1)\n",
      "Territory(territoryid=2903, territoryname='Providence', regionid=1)\n",
      "Territory(territoryid=3049, territoryname='Hollis', regionid=3)\n",
      "Territory(territoryid=3801, territoryname='Portsmouth', regionid=3)\n",
      "Territory(territoryid=6897, territoryname='Wilton', regionid=1)\n",
      "Territory(territoryid=7960, territoryname='Morristown', regionid=1)\n",
      "Territory(territoryid=8837, territoryname='Edison', regionid=1)\n",
      "Territory(territoryid=10019, territoryname='New York', regionid=1)\n",
      "Territory(territoryid=10038, territoryname='New York', regionid=1)\n",
      "Territory(territoryid=11747, territoryname='Mellvile', regionid=1)\n",
      "Territory(territoryid=14450, territoryname='Fairport', regionid=1)\n",
      "Territory(territoryid=19428, territoryname='Philadelphia', regionid=3)\n",
      "Territory(territoryid=19713, territoryname='Neward', regionid=1)\n",
      "Territory(territoryid=20852, territoryname='Rockville', regionid=1)\n",
      "Territory(territoryid=27403, territoryname='Greensboro', regionid=1)\n",
      "Territory(territoryid=27511, territoryname='Cary', regionid=1)\n",
      "Territory(territoryid=40222, territoryname='Louisville', regionid=1)\n",
      "Territory(territoryid=44122, territoryname='Beachwood', regionid=3)\n",
      "Territory(territoryid=45839, territoryname='Findlay', regionid=3)\n",
      "Territory(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "Territory(territoryid=48084, territoryname='Troy', regionid=3)\n",
      "Territory(territoryid=48304, territoryname='Bloomfield Hills', regionid=3)\n",
      "Territory(territoryid=53404, territoryname='Racine', regionid=3)\n",
      "Territory(territoryid=55113, territoryname='Roseville', regionid=3)\n",
      "Territory(territoryid=55439, territoryname='Minneapolis', regionid=3)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class OddEvenTerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = int(element['territoryid']), element['territoryname'], int(element['regionid'])\n",
    "        if int(regionid) % 2 == 0:\n",
    "            yield pvalue.TaggedOutput('Even', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "        else:\n",
    "            yield pvalue.TaggedOutput('Odd', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/PARQUET/territories/territories.parquet'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = p | 'Read' >> beam.io.ReadFromParquet(territoriesfilename) \n",
    "    # territories would return a tuple of the two tagged outputs\n",
    "    # unpack the two outputs to two separate variables to process differently\n",
    "    evens, odds = territories | 'Parse' >> beam.ParDo(OddEvenTerritoryParseClass()).with_outputs(\"Even\", \"Odd\")\n",
    "    \n",
    "    evens | 'Write Even' >> WriteToText('/tmp/territories_even.out')\n",
    "    \n",
    "    odds | 'Write Odd' >> WriteToText('/tmp/territories_odd.out')\n",
    "\n",
    "! echo \"Evens\" && cat /tmp/territories_even.out* && echo \"Odds\" && cat /tmp/territories_odd.out*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a3ae2-0add-4eaf-8515-d9420834fa34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ce4a7-eacc-41dd-b51b-1746546fcbcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Send the same output down two different paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f43ccc6-3890-4349-8482-c7c2498e9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d2295-86ea-4a50-a094-d4d8eaff9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "// incomplete AVRO example\n",
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    " Pipeline p = ...;\n",
    "\n",
    "#  // Read Avro-generated classes from files on GCS\n",
    "#  PCollection<AvroAutoGenClass> records =\n",
    "#      p.apply(AvroIO.read(AvroAutoGenClass.class).from(\"gs://my_bucket/path/to/records-*.avro\"));\n",
    "\n",
    "#  // Read GenericRecord's of the given schema from files on GCS\n",
    "#  Schema schema = new Schema.Parser().parse(new File(\"schema.avsc\"));\n",
    "#  PCollection<GenericRecord> records =\n",
    "#      p.apply(AvroIO.readGenericRecords(schema)\n",
    "#                 .from(\"gs://my_bucket/path/to/records-*.avro\"));\n",
    " \n",
    "\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/AVRO/territories/territories.avro\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<AvroAutoGenClass> records= p\n",
    "            .apply(\"Read Avro\", AvroIO.read(AvroAutoGenClass.class).from(territoriesInputFileName));\n",
    "/*\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territory\", ParDo.of(new ParseTerritories()))\n",
    "*/\n",
    "        ;                   \n",
    "        \n",
    "/*            \n",
    "        territories\n",
    "            .apply(\"Upper\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toUpperCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_upper\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        territories\n",
    "            .apply(\"Lower\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toLowerCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_lower\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    */\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9847873-48ba-4b10-9e17-9bfe3004ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rm src/main/java/samples/quickstart/*.java\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm build/libs/*.jar\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> rm -rf /tmp/outputs*\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain build\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> ls -lh build/libs/\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      ">> /opt/gradle-5.0/bin/gradle --console=plain runShadow\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territory\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "            \n",
    "        territories\n",
    "            .apply(\"Upper\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toUpperCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_upper\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        territories\n",
    "            .apply(\"Lower\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toLowerCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_lower\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae170dd2-fdd2-46fc-b741-5e8423269d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Upper\n",
      "(territoryID = 44122, territoryName = BEACHWOOD, regionID = 3)\n",
      "(territoryID = 85251, territoryName = SCOTTSDALE, regionID = 2)\n",
      "(territoryID = 20852, territoryName = ROCKVILLE, regionID = 1)\n",
      "(territoryID = 1833, territoryName = GEORGETOW, regionID = 1)\n",
      "(territoryID = 3049, territoryName = HOLLIS, regionID = 3)\n",
      "(territoryID = 10019, territoryName = NEW YORK, regionID = 1)\n",
      "(territoryID = 95054, territoryName = SANTA CLARA, regionID = 2)\n",
      "(territoryID = 53404, territoryName = RACINE, regionID = 3)\n",
      "(territoryID = 80202, territoryName = DENVER, regionID = 2)\n",
      "(territoryID = 31406, territoryName = SAVANNAH, regionID = 4)\n",
      "(territoryID = 33607, territoryName = TAMPA, regionID = 4)\n",
      "(territoryID = 90405, territoryName = SANTA MONICA, regionID = 2)\n",
      "(territoryID = 11747, territoryName = MELLVILE, regionID = 1)\n",
      "(territoryID = 27403, territoryName = GREENSBORO, regionID = 1)\n",
      "(territoryID = 98004, territoryName = BELLEVUE, regionID = 2)\n",
      "(territoryID = 2116, territoryName = BOSTON, regionID = 1)\n",
      "(territoryID = 3801, territoryName = PORTSMOUTH, regionID = 3)\n",
      "(territoryID = 10038, territoryName = NEW YORK, regionID = 1)\n",
      "(territoryID = 95060, territoryName = SANTA CRUZ, regionID = 2)\n",
      "(territoryID = 45839, territoryName = FINDLAY, regionID = 3)\n",
      "(territoryID = 55113, territoryName = ROSEVILLE, regionID = 3)\n",
      "(territoryID = 32859, territoryName = ORLANDO, regionID = 4)\n",
      "(territoryID = 40222, territoryName = LOUISVILLE, regionID = 1)\n",
      "(territoryID = 94025, territoryName = MENLO PARK, regionID = 2)\n",
      "(territoryID = 14450, territoryName = FAIRPORT, regionID = 1)\n",
      "(territoryID = 27511, territoryName = CARY, regionID = 1)\n",
      "(territoryID = 98052, territoryName = REDMOND, regionID = 2)\n",
      "(territoryID = 2139, territoryName = CAMBRIDGE, regionID = 1)\n",
      "(territoryID = 6897, territoryName = WILTON, regionID = 1)\n",
      "(territoryID = 75234, territoryName = DALLAS, regionID = 4)\n",
      "(territoryID = 48075, territoryName = SOUTHFIELD, regionID = 3)\n",
      "(territoryID = 55439, territoryName = MINNEAPOLIS, regionID = 3)\n",
      "(territoryID = 98104, territoryName = SEATTLE, regionID = 2)\n",
      "(territoryID = 60179, territoryName = HOFFMAN ESTATES, regionID = 2)\n",
      "(territoryID = 80909, territoryName = COLORADO SPRINGS, regionID = 2)\n",
      "(territoryID = 94105, territoryName = SAN FRANCISCO, regionID = 2)\n",
      "(territoryID = 19428, territoryName = PHILADELPHIA, regionID = 3)\n",
      "(territoryID = 1581, territoryName = WESTBORO, regionID = 1)\n",
      "(territoryID = 2184, territoryName = BRAINTREE, regionID = 1)\n",
      "(territoryID = 7960, territoryName = MORRISTOWN, regionID = 1)\n",
      "(territoryID = 78759, territoryName = AUSTIN, regionID = 4)\n",
      "(territoryID = 48084, territoryName = TROY, regionID = 3)\n",
      "(territoryID = 29202, territoryName = COLUMBIA, regionID = 4)\n",
      "(territoryID = 60601, territoryName = CHICAGO, regionID = 2)\n",
      "(territoryID = 85014, territoryName = PHOENIX, regionID = 2)\n",
      "(territoryID = 19713, territoryName = NEWARD, regionID = 1)\n",
      "(territoryID = 1730, territoryName = BEDFORD, regionID = 1)\n",
      "(territoryID = 2903, territoryName = PROVIDENCE, regionID = 1)\n",
      "(territoryID = 8837, territoryName = EDISON, regionID = 1)\n",
      "(territoryID = 95008, territoryName = CAMPBELL, regionID = 2)\n",
      "(territoryID = 48304, territoryName = BLOOMFIELD HILLS, regionID = 3)\n",
      "(territoryID = 30346, territoryName = ATLANTA, regionID = 4)\n",
      "(territoryID = 72716, territoryName = BENTONVILLE, regionID = 4)\n",
      "(1581, 'WESTBORO', 1)\n",
      "(1730, 'BEDFORD', 1)\n",
      "(1833, 'GEORGETOW', 1)\n",
      "(2116, 'BOSTON', 1)\n",
      "(2139, 'CAMBRIDGE', 1)\n",
      "(2184, 'BRAINTREE', 1)\n",
      "(2903, 'PROVIDENCE', 1)\n",
      "(3049, 'HOLLIS', 3)\n",
      "(3801, 'PORTSMOUTH', 3)\n",
      "(6897, 'WILTON', 1)\n",
      "(7960, 'MORRISTOWN', 1)\n",
      "(8837, 'EDISON', 1)\n",
      "(10019, 'NEW YORK', 1)\n",
      "(10038, 'NEW YORK', 1)\n",
      "(11747, 'MELLVILE', 1)\n",
      "(14450, 'FAIRPORT', 1)\n",
      "(19428, 'PHILADELPHIA', 3)\n",
      "(19713, 'NEWARD', 1)\n",
      "(20852, 'ROCKVILLE', 1)\n",
      "(27403, 'GREENSBORO', 1)\n",
      "(27511, 'CARY', 1)\n",
      "(29202, 'COLUMBIA', 4)\n",
      "(30346, 'ATLANTA', 4)\n",
      "(31406, 'SAVANNAH', 4)\n",
      "(32859, 'ORLANDO', 4)\n",
      "(33607, 'TAMPA', 4)\n",
      "(40222, 'LOUISVILLE', 1)\n",
      "(44122, 'BEACHWOOD', 3)\n",
      "(45839, 'FINDLAY', 3)\n",
      "(48075, 'SOUTHFIELD', 3)\n",
      "(48084, 'TROY', 3)\n",
      "(48304, 'BLOOMFIELD HILLS', 3)\n",
      "(53404, 'RACINE', 3)\n",
      "(55113, 'ROSEVILLE', 3)\n",
      "(55439, 'MINNEAPOLIS', 3)\n",
      "(60179, 'HOFFMAN ESTATES', 2)\n",
      "(60601, 'CHICAGO', 2)\n",
      "(72716, 'BENTONVILLE', 4)\n",
      "(75234, 'DALLAS', 4)\n",
      "(78759, 'AUSTIN', 4)\n",
      "(80202, 'DENVER', 2)\n",
      "(80909, 'COLORADO SPRINGS', 2)\n",
      "(85014, 'PHOENIX', 2)\n",
      "(85251, 'SCOTTSDALE', 2)\n",
      "(90405, 'SANTA MONICA', 2)\n",
      "(94025, 'MENLO PARK', 2)\n",
      "(94105, 'SAN FRANCISCO', 2)\n",
      "(95008, 'CAMPBELL', 2)\n",
      "(95054, 'SANTA CLARA', 2)\n",
      "(95060, 'SANTA CRUZ', 2)\n",
      "(98004, 'BELLEVUE', 2)\n",
      "(98052, 'REDMOND', 2)\n",
      "(98104, 'SEATTLE', 2)\n",
      "Lower\n",
      "(territoryID = 60601, territoryName = chicago, regionID = 2)\n",
      "(territoryID = 78759, territoryName = austin, regionID = 4)\n",
      "(territoryID = 45839, territoryName = findlay, regionID = 3)\n",
      "(territoryID = 48304, territoryName = bloomfield hills, regionID = 3)\n",
      "(territoryID = 55439, territoryName = minneapolis, regionID = 3)\n",
      "(territoryID = 1730, territoryName = bedford, regionID = 1)\n",
      "(territoryID = 2139, territoryName = cambridge, regionID = 1)\n",
      "(territoryID = 3049, territoryName = hollis, regionID = 3)\n",
      "(territoryID = 7960, territoryName = morristown, regionID = 1)\n",
      "(territoryID = 10038, territoryName = new york, regionID = 1)\n",
      "(territoryID = 95054, territoryName = santa clara, regionID = 2)\n",
      "(territoryID = 19428, territoryName = philadelphia, regionID = 3)\n",
      "(territoryID = 27403, territoryName = greensboro, regionID = 1)\n",
      "(territoryID = 85251, territoryName = scottsdale, regionID = 2)\n",
      "(territoryID = 94105, territoryName = san francisco, regionID = 2)\n",
      "(territoryID = 33607, territoryName = tampa, regionID = 4)\n",
      "(territoryID = 29202, territoryName = columbia, regionID = 4)\n",
      "(territoryID = 32859, territoryName = orlando, regionID = 4)\n",
      "(territoryID = 80202, territoryName = denver, regionID = 2)\n",
      "(territoryID = 72716, territoryName = bentonville, regionID = 4)\n",
      "(territoryID = 48075, territoryName = southfield, regionID = 3)\n",
      "(territoryID = 53404, territoryName = racine, regionID = 3)\n",
      "(territoryID = 1833, territoryName = georgetow, regionID = 1)\n",
      "(territoryID = 2184, territoryName = braintree, regionID = 1)\n",
      "(territoryID = 3801, territoryName = portsmouth, regionID = 3)\n",
      "(territoryID = 8837, territoryName = edison, regionID = 1)\n",
      "(territoryID = 95060, territoryName = santa cruz, regionID = 2)\n",
      "(territoryID = 98004, territoryName = bellevue, regionID = 2)\n",
      "(territoryID = 11747, territoryName = mellvile, regionID = 1)\n",
      "(territoryID = 19713, territoryName = neward, regionID = 1)\n",
      "(territoryID = 27511, territoryName = cary, regionID = 1)\n",
      "(territoryID = 80909, territoryName = colorado springs, regionID = 2)\n",
      "(territoryID = 90405, territoryName = santa monica, regionID = 2)\n",
      "(territoryID = 40222, territoryName = louisville, regionID = 1)\n",
      "(territoryID = 98104, territoryName = seattle, regionID = 2)\n",
      "(territoryID = 30346, territoryName = atlanta, regionID = 4)\n",
      "(territoryID = 60179, territoryName = hoffman estates, regionID = 2)\n",
      "(territoryID = 75234, territoryName = dallas, regionID = 4)\n",
      "(territoryID = 48084, territoryName = troy, regionID = 3)\n",
      "(territoryID = 55113, territoryName = roseville, regionID = 3)\n",
      "(territoryID = 1581, territoryName = westboro, regionID = 1)\n",
      "(territoryID = 2116, territoryName = boston, regionID = 1)\n",
      "(territoryID = 2903, territoryName = providence, regionID = 1)\n",
      "(territoryID = 6897, territoryName = wilton, regionID = 1)\n",
      "(territoryID = 10019, territoryName = new york, regionID = 1)\n",
      "(territoryID = 95008, territoryName = campbell, regionID = 2)\n",
      "(territoryID = 98052, territoryName = redmond, regionID = 2)\n",
      "(territoryID = 14450, territoryName = fairport, regionID = 1)\n",
      "(territoryID = 20852, territoryName = rockville, regionID = 1)\n",
      "(territoryID = 85014, territoryName = phoenix, regionID = 2)\n",
      "(territoryID = 94025, territoryName = menlo park, regionID = 2)\n",
      "(territoryID = 31406, territoryName = savannah, regionID = 4)\n",
      "(territoryID = 44122, territoryName = beachwood, regionID = 3)\n",
      "(1581, 'westboro', 1)\n",
      "(1730, 'bedford', 1)\n",
      "(1833, 'georgetow', 1)\n",
      "(2116, 'boston', 1)\n",
      "(2139, 'cambridge', 1)\n",
      "(2184, 'braintree', 1)\n",
      "(2903, 'providence', 1)\n",
      "(3049, 'hollis', 3)\n",
      "(3801, 'portsmouth', 3)\n",
      "(6897, 'wilton', 1)\n",
      "(7960, 'morristown', 1)\n",
      "(8837, 'edison', 1)\n",
      "(10019, 'new york', 1)\n",
      "(10038, 'new york', 1)\n",
      "(11747, 'mellvile', 1)\n",
      "(14450, 'fairport', 1)\n",
      "(19428, 'philadelphia', 3)\n",
      "(19713, 'neward', 1)\n",
      "(20852, 'rockville', 1)\n",
      "(27403, 'greensboro', 1)\n",
      "(27511, 'cary', 1)\n",
      "(29202, 'columbia', 4)\n",
      "(30346, 'atlanta', 4)\n",
      "(31406, 'savannah', 4)\n",
      "(32859, 'orlando', 4)\n",
      "(33607, 'tampa', 4)\n",
      "(40222, 'louisville', 1)\n",
      "(44122, 'beachwood', 3)\n",
      "(45839, 'findlay', 3)\n",
      "(48075, 'southfield', 3)\n",
      "(48084, 'troy', 3)\n",
      "(48304, 'bloomfield hills', 3)\n",
      "(53404, 'racine', 3)\n",
      "(55113, 'roseville', 3)\n",
      "(55439, 'minneapolis', 3)\n",
      "(60179, 'hoffman estates', 2)\n",
      "(60601, 'chicago', 2)\n",
      "(72716, 'bentonville', 4)\n",
      "(75234, 'dallas', 4)\n",
      "(78759, 'austin', 4)\n",
      "(80202, 'denver', 2)\n",
      "(80909, 'colorado springs', 2)\n",
      "(85014, 'phoenix', 2)\n",
      "(85251, 'scottsdale', 2)\n",
      "(90405, 'santa monica', 2)\n",
      "(94025, 'menlo park', 2)\n",
      "(94105, 'san francisco', 2)\n",
      "(95008, 'campbell', 2)\n",
      "(95054, 'santa clara', 2)\n",
      "(95060, 'santa cruz', 2)\n",
      "(98004, 'bellevue', 2)\n",
      "(98052, 'redmond', 2)\n",
      "(98104, 'seattle', 2)\n"
     ]
    }
   ],
   "source": [
    "! echo \"Upper\" && cat /tmp/territories_upper* && echo \"Lower\" && cat /tmp/territories_lower*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c0f98-4b4b-4253-8045-4bb46bebfa7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use TupleTag to split the output into two separate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25158a5b-169d-4672-9683-38732dbca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde632-b934-4bf6-9a58-b551ab264385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    final static TupleTag<Territory> evenTag = new TupleTag<Territory>() {};\n",
    "    final static TupleTag<Territory> oddTag = new TupleTag<Territory>() {};\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollectionTuple territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"OddEvenSplit\", ParDo.of(new ParseTerritoriesOddEvenSplit()).withOutputTags(evenTag, TupleTagList.of(oddTag)))\n",
    "        ;                   \n",
    "        \n",
    "        PCollection<Territory> evenTerritories = territories.get(evenTag);\n",
    "        evenTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_even\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        PCollection<Territory> oddTerritories = territories.get(oddTag);\n",
    "        oddTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_odd\").withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritoriesOddEvenSplit extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritoriesOddEvenSplit.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "\n",
    "\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (regionID % 2 == 0) {\n",
    "                    c.output(evenTag, new Territory(territoryID, territoryName, regionID));\n",
    "                } else {\n",
    "                    c.output(oddTag, new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d6ae9-a392-4d7f-9222-017e3f2a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"Odd\" && cat /tmp/outputs_odd* && echo \"Even\" && cat /tmp/outputs_even*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6574254-039b-49ee-b81d-c12aec4d740d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64199d-86e5-4a52-b8d5-e56b34685278",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184af67-b4bc-4dfc-b8c8-a85735022725",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 6. To use Group, Join, Sort you need to reshape the data into a KV pair first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c69d69-d541-4d25-aae0-6a165c2f6531",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040dd12-e0d2-4eeb-ba6f-ec490542e822",
   "metadata": {
    "tags": []
   },
   "source": [
    "## WithKeys will reshape your data first, then GroupByKey will cluster the elements as a list under each unique key. The data must be in a KV tuple pair first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6f82f-8a76-49b2-9fc6-d5c8c9651d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x.regionid)\n",
    "#                    | 'Group Territories' >> beam.GroupByKey() \n",
    "                    | 'Print Territories' >> beam.Map(print)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fce976-9609-402f-b2ec-a129351ec8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'One'), (2, 'Two'), (4, 'Four')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : beam.Row(parent_id = x[0], parent_name = x[1]))\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Uno', 1), ('Due', 2), ('Eins', 1), ('Una', 1), ('Dos', 2), ('Tres', 3)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : beam.Row(child_name = x[0], parent_id = x[1]))\n",
    "    )\n",
    "    \n",
    "    result = ( {'parent': parent, 'child' : child} \n",
    "         | SqlTransform(\"\"\"\n",
    "             SELECT p.parent_id, p.parent_name, c.child_name \n",
    "             FROM parent as p \n",
    "             INNER JOIN child as c ON p.parent_id = c.parent_id\n",
    "             \"\"\")\n",
    "        | 'Map Join Output' >> beam.Map(lambda x : f'{x.parent_id} {x.parent_name} {x.child_name}')\n",
    "        | 'Print Join' >> beam.Map(print)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d90731-bacc-4b09-82d1-c16f19dce311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "\n",
    "class Parent(typing.NamedTuple):\n",
    "    parent_id: int\n",
    "    parent_name: str\n",
    "beam.coders.registry.register_coder(Parent, beam.coders.RowCoder)\n",
    "\n",
    "class Child(typing.NamedTuple):\n",
    "    child_name: str\n",
    "    parent_id: int\n",
    "beam.coders.registry.register_coder(Child, beam.coders.RowCoder)\n",
    "        \n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'One'), (2, 'Two')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : Parent(parent_id = x[0], parent_name = x[1])).with_output_types(Parent)\n",
    "              | 'Print 1' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Uno', 1), ('Due', 2), ('Eins', 1), ('Una', 1), ('Dos', 2)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : Child(child_name = x[0], parent_id = x[1])).with_output_types(Child)\n",
    "              | 'SQL Child' >> SqlTransform(\"\"\"SELECT parent_id, count(*) as cnt from PCOLLECTION GROUP BY parent_id\"\"\")\n",
    "              | 'Map for Print 2' >> beam.Map(lambda x : f'Parent {x.parent_id} count = {x.cnt}')\n",
    "              | 'Print 2' >> beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbd91-e4b8-4bd1-8c75-89064613bbd8",
   "metadata": {},
   "source": [
    "## Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030bb71-8ee0-48e6-aa39-284b2c65c042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62fc2a94-7ddf-4a23-8581-e58bac8e7240",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548cd66-511d-460d-ab91-42090216ba1e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaad46b-2a1d-40df-a573-02e5716279c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. BeamSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07e256-d80c-4465-a6cf-8930c1825f2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986c8bd-d52f-40f8-9638-ef5ccfeb59d5",
   "metadata": {},
   "source": [
    "### SQL Transform uses PCOLLECTION as the name of a single source passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "391af3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regionid = 1 count = 19\n",
      "regionid = 3 count = 11\n",
      "regionid = 4 count = 8\n",
      "regionid = 2 count = 15\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'territoryid = {self.territoryid} territoryname = {self.territoryname} regionid = {self.regionid}'\n",
    "coders.registry.register_coder(Territory, coders.RowCoder)\n",
    "        \n",
    "@beam.typehints.with_output_types(Territory)\n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname.title(), int(regionid))\n",
    "    \n",
    "class RegionCount(typing.NamedTuple):\n",
    "    regionid: int\n",
    "    count: int\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'regionid = {self.regionid} count = {self.count}'\n",
    "coders.registry.register_coder(RegionCount, coders.RowCoder)\n",
    "        \n",
    "        \n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "#                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass()).with_output_types(Territory) # if we didn't have with_output_types decorator\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                    | 'SQL Territories' >> SqlTransform(\"\"\"SELECT regionid, count(*) as `count` FROM PCOLLECTION GROUP BY regionid\"\"\")\n",
    "#                    | 'Map Territories for Print' >> beam.Map(lambda x : f'regionid = {x.regionid}  count = {x.count}')\n",
    "#                    | 'Convert to RegionCount Class' >> beam.Map(lambda x : RegionCount(x.regionid, x.count))\n",
    "                    | 'Print SQL' >> beam.Map(print)\n",
    "                    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c3a7c-0584-4268-a2f5-fbc04534eacc",
   "metadata": {},
   "source": [
    "### For a SQL query that has more than one source, bundle the sources together in a dictionary, they keys become the table names inside the SQL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adc93081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Vowel Alpha\n",
      "1 Vowel Epsilon\n",
      "2 Consonant Beta\n",
      "2 Consonant Gamma\n",
      "2 Consonant Delta\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'Vowel'), (2, 'Consonant'), (4, 'Unknown')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : beam.Row(parent_id = x[0], parent_name = x[1]))\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Alpha', 1), ('Beta', 2), ('Gamma', 2), ('Delta', 2), ('Epsilon', 1), ('Pi', 3)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : beam.Row(child_name = x[0], parent_id = x[1]))\n",
    "    )\n",
    "    \n",
    "    result = ( {'parent': parent, 'child' : child} \n",
    "         | SqlTransform(\"\"\"\n",
    "             SELECT p.parent_id, p.parent_name, c.child_name \n",
    "             FROM parent as p \n",
    "             INNER JOIN child as c ON p.parent_id = c.parent_id\n",
    "             \"\"\")\n",
    "        | 'Map Join' >> beam.Map(lambda x : f'{x.parent_id}, {x.parent_name} {x.child_name}')\n",
    "        | 'Print Join' >> beam.Map(print)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2ffb3-9158-4ae6-9c8e-999f9a0ab3b8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a8d33-1cd4-42c6-8277-da98c7cf15a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f139a1-db8c-41b5-9881-1a5eb2570f5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 8. DoFn Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cb066-030c-4846-a446-eeada7ddd4af",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb832c-8881-412b-8874-6247b75392b7",
   "metadata": {},
   "source": [
    "### There are five methods in a DoFn that get called at various points in its lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b4447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsList\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Region(typing.NamedTuple):\n",
    "    regionid: int\n",
    "    regionname: str\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'regionid = {self.regionid} regionname = {self.regionname}'\n",
    "beam.coders.registry.register_coder(Region, beam.coders.RowCoder)\n",
    "        \n",
    "@beam.typehints.with_output_types(Region)\n",
    "class RegionParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname,  = element.split(',')\n",
    "        yield Region(int(regionid), regionname)\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'territoryid = {self.territoryid} territoryname = {self.territoryname} regionid = {self.regionid}'\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "@beam.typehints.with_output_types(Territory)\n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "        \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        print('init')\n",
    "\n",
    "    def called_once(self, lookuptable):\n",
    "        print('called_once')\n",
    "        self.lookup = { e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "        self.init_semaphore = False\n",
    "\n",
    "    def setup(self):\n",
    "        print('setup')\n",
    "        self.init_semaphore = True\n",
    "        #self.lookup = {1:'NORTH', 2:'South', 3:'East', 4:'West'}\n",
    "\n",
    "    def start_bundle(self):\n",
    "        print('start bundle')\n",
    "\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'north'}, {'regionid':2, 'regionname':'south'}]):\n",
    "        if self.init_semaphore:\n",
    "            self.called_once(lookuptable)\n",
    "        territoryid, territoryname, regionid = element\n",
    "        yield(territoryid, territoryname, regionid, self.lookup.get(regionid, 'No Region'))\n",
    "\n",
    "    def finish_bundle(self):\n",
    "        print('finish bundle')\n",
    "\n",
    "    def teardown(self):\n",
    "        print('teardown')\n",
    "        del self.lookup\n",
    "        del self.init_semaphore\n",
    "                \n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Parse Regions' >> beam.ParDo(RegionParseDict())\n",
    "    )\n",
    "\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Spare Territories' >> beam.ParDo(TerritoryParseTuple())\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "        | 'Print Loopup' >> beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c622d-8a76-41da-afb2-60258b499577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ac07ff-2799-4372-8e75-9c35d849a6d6",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a99c8-0cad-4c18-ad35-579923651e25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b896875-2400-4228-aec6-a8abaca08cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Apache Beam 2.34.0 for Python 3",
   "language": "python",
   "name": "01-apache-beam-2.34.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
