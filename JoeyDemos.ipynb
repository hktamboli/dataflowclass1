{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3550510",
   "metadata": {},
   "source": [
    "## Simple transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0ecf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var import_html = () => {\n",
       "          ['https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html'].forEach(href => {\n",
       "            var link = document.createElement('link');\n",
       "            link.rel = 'import'\n",
       "            link.href = href;\n",
       "            document.head.appendChild(link);\n",
       "          });\n",
       "        }\n",
       "        if ('import' in document.createElement('link')) {\n",
       "          import_html();\n",
       "        } else {\n",
       "          var webcomponentScript = document.createElement('script');\n",
       "          webcomponentScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js';\n",
       "          webcomponentScript.type = 'text/javascript';\n",
       "          webcomponentScript.onload = function(){\n",
       "            import_html();\n",
       "          };\n",
       "          document.head.appendChild(webcomponentScript);\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE\n",
      "TWO\n",
      "THREE\n",
      "FOUR\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | 'Create' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | 'Uppercase' >> beam.Map(str.upper)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3e72a",
   "metadata": {},
   "source": [
    "## The pipe | is actually just an operator overload to call the apply method of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae32d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = p | 'Create' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "        lines2 = (\n",
    "            p.apply(beam.Map(str.title), lines, 'titlecase')\n",
    "             .apply(beam.Map(print))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c224b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JoeyDemos.ipynb       leftjoin.py    simple3-dataflow.sh  territories.csv\n",
      "README.md\t      products.json  simple3-local.sh\t  territories.py\n",
      "aggregate1.py\t      regions.csv    simple3.py\t\t  wordcount-dataflow.sh\n",
      "aggregate2.py\t      simple1.py     simple3_custom.py\t  wordcount.py\n",
      "dataflow_template.py  simple2.py     territories.avro\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb00603",
   "metadata": {},
   "source": [
    "## Read from CSV and use Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e089f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'EASTERN')\n",
      "(20, 'WESTERN')\n",
      "(30, 'NORTHERN')\n",
      "(40, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.Map(lambda x : tuple(x.split(',')))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]) * 10, x[1].upper()))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f161f",
   "metadata": {},
   "source": [
    "## Read from CSV and use ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c44b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.ParDo(RegionSplit())\n",
    "          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c555733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Eastern')\n",
      "(2, 'Western')\n",
      "(3, 'Northern')\n",
      "(4, 'Southern')\n"
     ]
    }
   ],
   "source": [
    "! cat regions.out*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008cd9e5",
   "metadata": {},
   "source": [
    "## Template showing a full program that can read the command line args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c309a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A template to import the default package and parse the arguments\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "\n",
    "#from past.builtins import unicode\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(regionid, regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "def run(argv=None, save_main_session=True):\n",
    "  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--input',\n",
    "      dest='input',\n",
    "      default='gs://dataflowclass1-bucket/regions.csv',\n",
    "      help='Input file to process.')\n",
    "  parser.add_argument(\n",
    "      '--output',\n",
    "      dest='output',\n",
    "      default = 'gs://dataflowclass1-bucket/regions_output',      \n",
    "      help='Output file to write results to.')\n",
    "  known_args, pipeline_args = parser.parse_known_args(argv)\n",
    "\n",
    "  # We use the save_main_session option because one or more DoFn's in this\n",
    "  # workflow rely on global context (e.g., a module imported at module level).\n",
    "  pipeline_options = PipelineOptions(pipeline_args)\n",
    "  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n",
    "\n",
    "  # The pipeline will be run on exiting the with block.\n",
    "  with beam.Pipeline(options=pipeline_options) as p:\n",
    "    lines = p | 'Read' >> ReadFromText(known_args.input)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    uppercase = records | 'Uppercase' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "    uppercase | 'Write' >> WriteToText(known_args.output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  logging.getLogger().setLevel(logging.INFO)\n",
    "  run()\n",
    "\n",
    "\n",
    "filename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(filename)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    records | 'Write' >> WriteToText('regions2.out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce60cb2",
   "metadata": {},
   "source": [
    "## Example of how to create a split ParDo with multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca76def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evens\n",
      "Odds\n",
      "(1, 'Eastern', 'Odd')\n",
      "(2, 'Western', 'Even')\n",
      "(3, 'Northern', 'Odd')\n",
      "(4, 'Southern', 'Even')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "class OddEvenRegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        if int(regionid) % 2 == 0:\n",
    "            yield pvalue.TaggedOutput('Even', (int(regionid), regionname, 'Even'))\n",
    "        else:\n",
    "            yield pvalue.TaggedOutput('Odd', (int(regionid), regionname, 'Odd'))\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(regionsfilename)\n",
    "    evens, odds = lines | 'Split' >> beam.ParDo(OddEvenRegionSplit()).with_outputs(\"Even\", \"Odd\")\n",
    "    \n",
    "    print('Evens')\n",
    "    evens | 'Print Evens' >> beam.Map(print)\n",
    "\n",
    "    print('Odds')\n",
    "    odds | 'Print Odds' >> beam.Map(print)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e66f1",
   "metadata": {},
   "source": [
    "## Example of branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac24165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'EASTERN')\n",
      "(20, 'WESTERN')\n",
      "(30, 'NORTHERN')\n",
      "(40, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    )\n",
    "    # Branch 1\n",
    "    (regions \n",
    "         | 'Lowercase regions' >> beam.Map(lambda x : (x[0] * 100, x[1].lower()))\n",
    "         | 'Write' >> WriteToText('regions2.out')\n",
    "    )\n",
    "    \n",
    "    (regions \n",
    "         | 'Uppercase regions' >> beam.Map(lambda x : (x[0] * 10, x[1].upper()))\n",
    "         | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a928ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 'eastern')\n",
      "(200, 'western')\n",
      "(300, 'northern')\n",
      "(400, 'southern')\n"
     ]
    }
   ],
   "source": [
    "! cat regions2*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10cd6e",
   "metadata": {},
   "source": [
    "## WithKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9955b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01581', 'Westboro', '1')\n",
      "1\n",
      "('1', ('01581', 'Westboro', '1'))\n",
      "('01730', 'Bedford', '1')\n",
      "1\n",
      "('1', ('01730', 'Bedford', '1'))\n",
      "('01833', 'Georgetow', '1')\n",
      "1\n",
      "('1', ('01833', 'Georgetow', '1'))\n",
      "('02116', 'Boston', '1')\n",
      "1\n",
      "('1', ('02116', 'Boston', '1'))\n",
      "('02139', 'Cambridge', '1')\n",
      "1\n",
      "('1', ('02139', 'Cambridge', '1'))\n",
      "('02184', 'Braintree', '1')\n",
      "1\n",
      "('1', ('02184', 'Braintree', '1'))\n",
      "('02903', 'Providence', '1')\n",
      "1\n",
      "('1', ('02903', 'Providence', '1'))\n",
      "('03049', 'Hollis', '3')\n",
      "3\n",
      "('3', ('03049', 'Hollis', '3'))\n",
      "('03801', 'Portsmouth', '3')\n",
      "3\n",
      "('3', ('03801', 'Portsmouth', '3'))\n",
      "('06897', 'Wilton', '1')\n",
      "1\n",
      "('1', ('06897', 'Wilton', '1'))\n",
      "('07960', 'Morristown', '1')\n",
      "1\n",
      "('1', ('07960', 'Morristown', '1'))\n",
      "('08837', 'Edison', '1')\n",
      "1\n",
      "('1', ('08837', 'Edison', '1'))\n",
      "('10019', 'New York', '1')\n",
      "1\n",
      "('1', ('10019', 'New York', '1'))\n",
      "('10038', 'New York', '1')\n",
      "1\n",
      "('1', ('10038', 'New York', '1'))\n",
      "('11747', 'Mellvile', '1')\n",
      "1\n",
      "('1', ('11747', 'Mellvile', '1'))\n",
      "('14450', 'Fairport', '1')\n",
      "1\n",
      "('1', ('14450', 'Fairport', '1'))\n",
      "('19428', 'Philadelphia', '3')\n",
      "3\n",
      "('3', ('19428', 'Philadelphia', '3'))\n",
      "('19713', 'Neward', '1')\n",
      "1\n",
      "('1', ('19713', 'Neward', '1'))\n",
      "('20852', 'Rockville', '1')\n",
      "1\n",
      "('1', ('20852', 'Rockville', '1'))\n",
      "('27403', 'Greensboro', '1')\n",
      "1\n",
      "('1', ('27403', 'Greensboro', '1'))\n",
      "('27511', 'Cary', '1')\n",
      "1\n",
      "('1', ('27511', 'Cary', '1'))\n",
      "('29202', 'Columbia', '4')\n",
      "4\n",
      "('4', ('29202', 'Columbia', '4'))\n",
      "('30346', 'Atlanta', '4')\n",
      "4\n",
      "('4', ('30346', 'Atlanta', '4'))\n",
      "('31406', 'Savannah', '4')\n",
      "4\n",
      "('4', ('31406', 'Savannah', '4'))\n",
      "('32859', 'Orlando', '4')\n",
      "4\n",
      "('4', ('32859', 'Orlando', '4'))\n",
      "('33607', 'Tampa', '4')\n",
      "4\n",
      "('4', ('33607', 'Tampa', '4'))\n",
      "('40222', 'Louisville', '1')\n",
      "1\n",
      "('1', ('40222', 'Louisville', '1'))\n",
      "('44122', 'Beachwood', '3')\n",
      "3\n",
      "('3', ('44122', 'Beachwood', '3'))\n",
      "('45839', 'Findlay', '3')\n",
      "3\n",
      "('3', ('45839', 'Findlay', '3'))\n",
      "('48075', 'Southfield', '3')\n",
      "3\n",
      "('3', ('48075', 'Southfield', '3'))\n",
      "('48084', 'Troy', '3')\n",
      "3\n",
      "('3', ('48084', 'Troy', '3'))\n",
      "('48304', 'Bloomfield Hills', '3')\n",
      "3\n",
      "('3', ('48304', 'Bloomfield Hills', '3'))\n",
      "('53404', 'Racine', '3')\n",
      "3\n",
      "('3', ('53404', 'Racine', '3'))\n",
      "('55113', 'Roseville', '3')\n",
      "3\n",
      "('3', ('55113', 'Roseville', '3'))\n",
      "('55439', 'Minneapolis', '3')\n",
      "3\n",
      "('3', ('55439', 'Minneapolis', '3'))\n",
      "('60179', 'Hoffman Estates', '2')\n",
      "2\n",
      "('2', ('60179', 'Hoffman Estates', '2'))\n",
      "('60601', 'Chicago', '2')\n",
      "2\n",
      "('2', ('60601', 'Chicago', '2'))\n",
      "('72716', 'Bentonville', '4')\n",
      "4\n",
      "('4', ('72716', 'Bentonville', '4'))\n",
      "('75234', 'Dallas', '4')\n",
      "4\n",
      "('4', ('75234', 'Dallas', '4'))\n",
      "('78759', 'Austin', '4')\n",
      "4\n",
      "('4', ('78759', 'Austin', '4'))\n",
      "('80202', 'Denver', '2')\n",
      "2\n",
      "('2', ('80202', 'Denver', '2'))\n",
      "('80909', 'Colorado Springs', '2')\n",
      "2\n",
      "('2', ('80909', 'Colorado Springs', '2'))\n",
      "('85014', 'Phoenix', '2')\n",
      "2\n",
      "('2', ('85014', 'Phoenix', '2'))\n",
      "('85251', 'Scottsdale', '2')\n",
      "2\n",
      "('2', ('85251', 'Scottsdale', '2'))\n",
      "('90405', 'Santa Monica', '2')\n",
      "2\n",
      "('2', ('90405', 'Santa Monica', '2'))\n",
      "('94025', 'Menlo Park', '2')\n",
      "2\n",
      "('2', ('94025', 'Menlo Park', '2'))\n",
      "('94105', 'San Francisco', '2')\n",
      "2\n",
      "('2', ('94105', 'San Francisco', '2'))\n",
      "('95008', 'Campbell', '2')\n",
      "2\n",
      "('2', ('95008', 'Campbell', '2'))\n",
      "('95054', 'Santa Clara', '2')\n",
      "2\n",
      "('2', ('95054', 'Santa Clara', '2'))\n",
      "('95060', 'Santa Cruz', '2')\n",
      "2\n",
      "('2', ('95060', 'Santa Cruz', '2'))\n",
      "('98004', 'Bellevue', '2')\n",
      "2\n",
      "('2', ('98004', 'Bellevue', '2'))\n",
      "('98052', 'Redmond', '2')\n",
      "2\n",
      "('2', ('98052', 'Redmond', '2'))\n",
      "('98104', 'Seattle', '2')\n",
      "2\n",
      "('2', ('98104', 'Seattle', '2'))\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield (territoryid, territoryname, regionid)\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText(territoriesfilename)\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x[2])\n",
    "#                    | 'With Keys Manually' >> beam.Map(lambda x : (x[2], x))\n",
    "                  )\n",
    "    territories | 'Print KV' >> beam.Map(print)\n",
    "    territories | beam.util.Keys() | 'Print Keys' >> beam.Map(print)\n",
    "    territories | beam.util.Values() | 'Print Values' >> beam.Map(print)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0d5ed",
   "metadata": {},
   "source": [
    "## GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c590504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', [('01581', 'Westboro', '1'), ('01730', 'Bedford', '1'), ('01833', 'Georgetow', '1'), ('02116', 'Boston', '1'), ('02139', 'Cambridge', '1'), ('02184', 'Braintree', '1'), ('02903', 'Providence', '1'), ('06897', 'Wilton', '1'), ('07960', 'Morristown', '1'), ('08837', 'Edison', '1'), ('10019', 'New York', '1'), ('10038', 'New York', '1'), ('11747', 'Mellvile', '1'), ('14450', 'Fairport', '1'), ('19713', 'Neward', '1'), ('20852', 'Rockville', '1'), ('27403', 'Greensboro', '1'), ('27511', 'Cary', '1'), ('40222', 'Louisville', '1')])\n",
      "('3', [('03049', 'Hollis', '3'), ('03801', 'Portsmouth', '3'), ('19428', 'Philadelphia', '3'), ('44122', 'Beachwood', '3'), ('45839', 'Findlay', '3'), ('48075', 'Southfield', '3'), ('48084', 'Troy', '3'), ('48304', 'Bloomfield Hills', '3'), ('53404', 'Racine', '3'), ('55113', 'Roseville', '3'), ('55439', 'Minneapolis', '3')])\n",
      "('4', [('29202', 'Columbia', '4'), ('30346', 'Atlanta', '4'), ('31406', 'Savannah', '4'), ('32859', 'Orlando', '4'), ('33607', 'Tampa', '4'), ('72716', 'Bentonville', '4'), ('75234', 'Dallas', '4'), ('78759', 'Austin', '4')])\n",
      "('2', [('60179', 'Hoffman Estates', '2'), ('60601', 'Chicago', '2'), ('80202', 'Denver', '2'), ('80909', 'Colorado Springs', '2'), ('85014', 'Phoenix', '2'), ('85251', 'Scottsdale', '2'), ('90405', 'Santa Monica', '2'), ('94025', 'Menlo Park', '2'), ('94105', 'San Francisco', '2'), ('95008', 'Campbell', '2'), ('95054', 'Santa Clara', '2'), ('95060', 'Santa Cruz', '2'), ('98004', 'Bellevue', '2'), ('98052', 'Redmond', '2'), ('98104', 'Seattle', '2')])\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield (territoryid, territoryname, regionid)\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x[2])\n",
    "                    | 'Group Territories' >> beam.GroupByKey() \n",
    "                    | 'Print Territories' >> beam.Map(print)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c47601",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "alpha\n",
      "beta\n",
      "gamma\n",
      "delta\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines1 = p | 'Create 1' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "    lines2 = p | 'Create 2' >> beam.Create(['alpha', 'beta', 'gamma', 'delta'])\n",
    "\n",
    "    merged = ((lines1, lines2) | 'Merge PCollections' >> beam.Flatten())\n",
    "    merged | beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754602af",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d27356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 90)\n",
      "('b', 70)\n",
      "('c', 50)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', 10), ('a', 20), ('b', 30), ('b', 40), ('c', 50), ('a', 60)])\n",
    "          | 'Combine' >> beam.CombinePerKey(sum)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f19ae",
   "metadata": {},
   "source": [
    "## Custom Combine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc8d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (6, 90, 3, 30.0), 'b': (4, 70, 2, 35.0), 'c': (5, 50, 1, 50.0)}\n"
     ]
    }
   ],
   "source": [
    "#mport apache_beam as beam\n",
    "\n",
    "class CustomCombine(beam.CombineFn):\n",
    "\n",
    "  def create_accumulator(self):\n",
    "    return {}\n",
    "\n",
    "  def add_input(self, accumulator, input):\n",
    "    k, v = input\n",
    "    x, y, z = accumulator.get(k, (0, 0, 0))\n",
    "\n",
    "    # take the max for the first element of the tuple and sum the second element and count for the third\n",
    "    accumulator[k] = (v[0] if v[0] > x else x, y + v[1], z + 1)\n",
    "    return accumulator\n",
    "\n",
    "  def merge_accumulators(self, accumulators):\n",
    "    merged = {}\n",
    "    for accum in accumulators:\n",
    "      for k, v in accum.items():\n",
    "        x, y, z = merged.get(k, (0, 0, 0))\n",
    "        merged[k] = (v[0] if v[0] > x else x, y + v[1], z + v[2])\n",
    "    return merged\n",
    "\n",
    "  def extract_output(self, accumulator):\n",
    "    # return the max, the sum, the count and the average for the key\n",
    "    return {k : (v[0], v[1], v[2], v[1]/v[2]) for k, v in accumulator.items()}\n",
    "    return accumulator\n",
    "    \n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', (1, 10)), ('a', (2, 20)), ('b', (3, 30)), ('b', (4, 40)), ('c', (5, 50)), ('a', (6, 60))])\n",
    "          | 'Combine' >> beam.CombineGlobally(CustomCombine())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b02592",
   "metadata": {},
   "source": [
    "## Map vs FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "837a6c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strawberry\n",
      "Carrot\n",
      "Eggplant\n",
      "Tomato\n",
      "Potato\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  plants = (\n",
    "      pipeline\n",
    "      | 'Gardening plants' >> beam.Create(['Strawberry,Carrot,Eggplant','Tomato,Potato'])\n",
    "      | 'Split words' >> beam.Map(lambda x : x.split(','))\n",
    "#      | 'Split words' >> beam.FlatMap(lambda x : x.split(','))\n",
    "      | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15219f0c",
   "metadata": {},
   "source": [
    "## Side Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb269fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1581, 'Westboro', 1, 'NORTH')\n",
      "(1730, 'Bedford', 1, 'NORTH')\n",
      "(1833, 'Georgetow', 1, 'NORTH')\n",
      "(2116, 'Boston', 1, 'NORTH')\n",
      "(2139, 'Cambridge', 1, 'NORTH')\n",
      "(2184, 'Braintree', 1, 'NORTH')\n",
      "(2903, 'Providence', 1, 'NORTH')\n",
      "(3049, 'Hollis', 3, 'EAST')\n",
      "(3801, 'Portsmouth', 3, 'EAST')\n",
      "(6897, 'Wilton', 1, 'NORTH')\n",
      "(7960, 'Morristown', 1, 'NORTH')\n",
      "(8837, 'Edison', 1, 'NORTH')\n",
      "(10019, 'New York', 1, 'NORTH')\n",
      "(10038, 'New York', 1, 'NORTH')\n",
      "(11747, 'Mellvile', 1, 'NORTH')\n",
      "(14450, 'Fairport', 1, 'NORTH')\n",
      "(19428, 'Philadelphia', 3, 'EAST')\n",
      "(19713, 'Neward', 1, 'NORTH')\n",
      "(20852, 'Rockville', 1, 'NORTH')\n",
      "(27403, 'Greensboro', 1, 'NORTH')\n",
      "(27511, 'Cary', 1, 'NORTH')\n",
      "(29202, 'Columbia', 4, 'WEST')\n",
      "(30346, 'Atlanta', 4, 'WEST')\n",
      "(31406, 'Savannah', 4, 'WEST')\n",
      "(32859, 'Orlando', 4, 'WEST')\n",
      "(33607, 'Tampa', 4, 'WEST')\n",
      "(40222, 'Louisville', 1, 'NORTH')\n",
      "(44122, 'Beachwood', 3, 'EAST')\n",
      "(45839, 'Findlay', 3, 'EAST')\n",
      "(48075, 'Southfield', 3, 'EAST')\n",
      "(48084, 'Troy', 3, 'EAST')\n",
      "(48304, 'Bloomfield Hills', 3, 'EAST')\n",
      "(53404, 'Racine', 3, 'EAST')\n",
      "(55113, 'Roseville', 3, 'EAST')\n",
      "(55439, 'Minneapolis', 3, 'EAST')\n",
      "(60179, 'Hoffman Estates', 2, 'SOUTH')\n",
      "(60601, 'Chicago', 2, 'SOUTH')\n",
      "(72716, 'Bentonville', 4, 'WEST')\n",
      "(75234, 'Dallas', 4, 'WEST')\n",
      "(78759, 'Austin', 4, 'WEST')\n",
      "(80202, 'Denver', 2, 'SOUTH')\n",
      "(80909, 'Colorado Springs', 2, 'SOUTH')\n",
      "(85014, 'Phoenix', 2, 'SOUTH')\n",
      "(85251, 'Scottsdale', 2, 'SOUTH')\n",
      "(90405, 'Santa Monica', 2, 'SOUTH')\n",
      "(94025, 'Menlo Park', 2, 'SOUTH')\n",
      "(94105, 'San Francisco', 2, 'SOUTH')\n",
      "(95008, 'Campbell', 2, 'SOUTH')\n",
      "(95054, 'Santa Clara', 2, 'SOUTH')\n",
      "(95060, 'Santa Cruz', 2, 'SOUTH')\n",
      "(98004, 'Bellevue', 2, 'SOUTH')\n",
      "(98052, 'Redmond', 2, 'SOUTH')\n",
      "(98104, 'Seattle', 2, 'SOUTH')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsSingleton, AsDict\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplitTuple(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, uppercase = 0):\n",
    "        lookuptable = {1:'North', 2:'South', 3:'East', 4:'West'}\n",
    "        territoryid, territoryname, regionid = element\n",
    "        region = lookuptable.get(regionid, 'No Region')\n",
    "        if uppercase == 1:\n",
    "            region = region.upper()\n",
    "        yield(territoryid, territoryname, regionid, region)\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplitTuple())\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "#        | beam.ParDo(LookupRegion())\n",
    "        | beam.ParDo(LookupRegion(), uppercase = 1 ) \n",
    "        #beam.pvalue.AsSingleton(int(1)))\n",
    "        | 'Print Loopup' >> beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21d88565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1581, 'Westboro', 1, 'Eastern')\n",
      "(1730, 'Bedford', 1, 'Eastern')\n",
      "(1833, 'Georgetow', 1, 'Eastern')\n",
      "(2116, 'Boston', 1, 'Eastern')\n",
      "(2139, 'Cambridge', 1, 'Eastern')\n",
      "(2184, 'Braintree', 1, 'Eastern')\n",
      "(2903, 'Providence', 1, 'Eastern')\n",
      "(3049, 'Hollis', 3, 'Northern')\n",
      "(3801, 'Portsmouth', 3, 'Northern')\n",
      "(6897, 'Wilton', 1, 'Eastern')\n",
      "(7960, 'Morristown', 1, 'Eastern')\n",
      "(8837, 'Edison', 1, 'Eastern')\n",
      "(10019, 'New York', 1, 'Eastern')\n",
      "(10038, 'New York', 1, 'Eastern')\n",
      "(11747, 'Mellvile', 1, 'Eastern')\n",
      "(14450, 'Fairport', 1, 'Eastern')\n",
      "(19428, 'Philadelphia', 3, 'Northern')\n",
      "(19713, 'Neward', 1, 'Eastern')\n",
      "(20852, 'Rockville', 1, 'Eastern')\n",
      "(27403, 'Greensboro', 1, 'Eastern')\n",
      "(27511, 'Cary', 1, 'Eastern')\n",
      "(29202, 'Columbia', 4, 'Southern')\n",
      "(30346, 'Atlanta', 4, 'Southern')\n",
      "(31406, 'Savannah', 4, 'Southern')\n",
      "(32859, 'Orlando', 4, 'Southern')\n",
      "(33607, 'Tampa', 4, 'Southern')\n",
      "(40222, 'Louisville', 1, 'Eastern')\n",
      "(44122, 'Beachwood', 3, 'Northern')\n",
      "(45839, 'Findlay', 3, 'Northern')\n",
      "(48075, 'Southfield', 3, 'Northern')\n",
      "(48084, 'Troy', 3, 'Northern')\n",
      "(48304, 'Bloomfield Hills', 3, 'Northern')\n",
      "(53404, 'Racine', 3, 'Northern')\n",
      "(55113, 'Roseville', 3, 'Northern')\n",
      "(55439, 'Minneapolis', 3, 'Northern')\n",
      "(60179, 'Hoffman Estates', 2, 'Western')\n",
      "(60601, 'Chicago', 2, 'Western')\n",
      "(72716, 'Bentonville', 4, 'Southern')\n",
      "(75234, 'Dallas', 4, 'Southern')\n",
      "(78759, 'Austin', 4, 'Southern')\n",
      "(80202, 'Denver', 2, 'Western')\n",
      "(80909, 'Colorado Springs', 2, 'Western')\n",
      "(85014, 'Phoenix', 2, 'Western')\n",
      "(85251, 'Scottsdale', 2, 'Western')\n",
      "(90405, 'Santa Monica', 2, 'Western')\n",
      "(94025, 'Menlo Park', 2, 'Western')\n",
      "(94105, 'San Francisco', 2, 'Western')\n",
      "(95008, 'Campbell', 2, 'Western')\n",
      "(95054, 'Santa Clara', 2, 'Western')\n",
      "(95060, 'Santa Cruz', 2, 'Western')\n",
      "(98004, 'Bellevue', 2, 'Western')\n",
      "(98052, 'Redmond', 2, 'Western')\n",
      "(98104, 'Seattle', 2, 'Western')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsList\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname.title()}\n",
    "\n",
    "class TerritorySplitTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]):\n",
    "        territoryid, territoryname, regionid = element\n",
    "        lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "        yield(territoryid, territoryname, regionid, lookup.get(regionid, 'No Region'))\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "#          | 'Print Regions' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplitTuple())\n",
    "#          | 'Print Territories' >> beam.Map(print)\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "        | 'Print Loopup' >> beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda42d1",
   "metadata": {},
   "source": [
    "## Simulate an Outer Join with CoGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22fbdb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'territoryid': 1581, 'territoryname': 'Westboro', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 1730, 'territoryname': 'Bedford', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 1833, 'territoryname': 'Georgetow', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2116, 'territoryname': 'Boston', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2139, 'territoryname': 'Cambridge', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2184, 'territoryname': 'Braintree', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2903, 'territoryname': 'Providence', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 6897, 'territoryname': 'Wilton', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 7960, 'territoryname': 'Morristown', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 8837, 'territoryname': 'Edison', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 10019, 'territoryname': 'New York', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 10038, 'territoryname': 'New York', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 11747, 'territoryname': 'Mellvile', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 14450, 'territoryname': 'Fairport', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 19713, 'territoryname': 'Neward', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 20852, 'territoryname': 'Rockville', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 27403, 'territoryname': 'Greensboro', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 27511, 'territoryname': 'Cary', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 40222, 'territoryname': 'Louisville', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 3049, 'territoryname': 'Hollis', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 3801, 'territoryname': 'Portsmouth', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 19428, 'territoryname': 'Philadelphia', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 44122, 'territoryname': 'Beachwood', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 45839, 'territoryname': 'Findlay', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48075, 'territoryname': 'Southfield', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48084, 'territoryname': 'Troy', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48304, 'territoryname': 'Bloomfield Hills', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 53404, 'territoryname': 'Racine', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 55113, 'territoryname': 'Roseville', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 55439, 'territoryname': 'Minneapolis', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 29202, 'territoryname': 'Columbia', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 30346, 'territoryname': 'Atlanta', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 31406, 'territoryname': 'Savannah', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 32859, 'territoryname': 'Orlando', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 33607, 'territoryname': 'Tampa', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 72716, 'territoryname': 'Bentonville', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 75234, 'territoryname': 'Dallas', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 78759, 'territoryname': 'Austin', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 60179, 'territoryname': 'Hoffman Estates', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 60601, 'territoryname': 'Chicago', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 80202, 'territoryname': 'Denver', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 80909, 'territoryname': 'Colorado Springs', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 85014, 'territoryname': 'Phoenix', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 85251, 'territoryname': 'Scottsdale', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 90405, 'territoryname': 'Santa Monica', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 94025, 'territoryname': 'Menlo Park', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 94105, 'territoryname': 'San Francisco', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95008, 'territoryname': 'Campbell', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95054, 'territoryname': 'Santa Clara', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95060, 'territoryname': 'Santa Cruz', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98004, 'territoryname': 'Bellevue', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98052, 'territoryname': 'Redmond', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98104, 'territoryname': 'Seattle', 'regionid': 2, 'regionname': 'Western'}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid':int(regionid), 'regionname':regionname.title()}\n",
    "\n",
    "class TerritorySplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "\n",
    "class UnnestCoGrouped(beam.DoFn):\n",
    "    def process(self, item, child_pipeline, parent_pipeline):\n",
    "        k, v = item\n",
    "        child_dict = v[child_pipeline]\n",
    "        parent_dict = v[parent_pipeline]\n",
    "        for child in child_dict:\n",
    "            try:\n",
    "                child.update(parent_dict[0])\n",
    "                yield child\n",
    "            except IndexError:\n",
    "                yield child\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    def __init__(self, parent_pipeline_name, parent_data, parent_key, child_pipeline_name, child_data,  child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_data = parent_data\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_data = child_data\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def _format_as_common_key_tuple(child_dict, child_key):\n",
    "            return (child_dict[child_key], child_dict)\n",
    "\n",
    "        return ({\n",
    "                pipeline_name: pcol1 | f'Convert to ({self.parent_key} = {self.child_key}, object) for {pipeline_name}' \n",
    "                >> beam.Map(_format_as_common_key_tuple, self.child_key)\n",
    "                for (pipeline_name, pcol1) in pcols.items()}\n",
    "                | f'CoGroupByKeey {pcols.keys()}' >> beam.CoGroupByKey()\n",
    "                | 'Unnest Cogrouped' >> beam.ParDo(UnnestCoGrouped(), self.child_pipeline_name, self.parent_pipeline_name)\n",
    "        )\n",
    "        \n",
    "regionsfilename = 'regions.csv'\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "                #| 'Print Regions' >> beam.Map(print)\n",
    "              )\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplitDict())\n",
    "                    #| 'Print Territories' >> beam.Map(print)\n",
    "                  )\n",
    "\n",
    "    leftjoin = {'regions':regions, 'territories':territories} | LeftJoin('regions', regions, 'regionid', 'territories', territories, 'regionid')\n",
    "    leftjoin | 'print left join' >> beam.Map(print)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bc734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614313ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'create parent' >> beam.Create([(1, 'One'), (2, 'Two')])\n",
    "              | 'map parent' >> beam.Map(lambda x : beam.Row(parent_id = x[0], parent_name = x[1]))\n",
    "#              | 'print parent' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'create child' >> beam.Create([('Uno', 1), ('Due', 2), ('Eins', 1)])\n",
    "              | 'map child' >> beam.Map(lambda x : beam.Row(child_name = x[0], parent_id = x[1]))\n",
    "#              | 'print child' >> beam.Map(print)\n",
    "\n",
    "    )\n",
    "    \n",
    "    ( {'parent': parent, 'child' : child} | SqlTransform(\"\"\"SELECT p.parent_id, p.parent_name, c.child_name \n",
    "    FROM parent as p \n",
    "    INNER JOIN child as c ON p.parent_id = c.parent_id\"\"\")\n",
    "    | 'map join' >> beam.Map(lambda x : ','.join(x))\n",
    "    | 'print join' >> beam.Map(print)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4aa4550",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9d459fedddd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#                     | 'SQL Territories' >> SqlTransform(\"\"\"SELECT regionid, territoryid, territoryname FROM PCOLLECTION\"\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#                     | 'Map Territories for Print' >> beam.Map(lambda x : f'{x.regionid} - {x.territoryid} - {x.territoryname}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0;34m|\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_tempdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     self._latest_run_result = self.run_via_runner_api(\n\u001b[0;32m--> 176\u001b[0;31m         pipeline.to_runner_api(default_environment=self._default_environment))\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latest_run_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# TODO(pabloem, BEAM-7514): Create a watermark manager (that has access to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m#   the teststream (if any), and all the stages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    344\u001b[0m           stage_results = self._run_stage(\n\u001b[1;32m    345\u001b[0m               \u001b[0mrunner_execution_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m               \u001b[0mbundle_context_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m           )\n\u001b[1;32m    348\u001b[0m           monitoring_infos_by_stage[stage.name] = (\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, runner_execution_context, bundle_context_manager)\u001b[0m\n\u001b[1;32m    532\u001b[0m               \u001b[0minput_timers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m               \u001b[0mexpected_timer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m               bundle_manager)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, data_input, data_output, input_timers, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     result, splits = bundle_manager.process_bundle(\n\u001b[0;32m--> 572\u001b[0;31m         data_input, data_output, input_timers, expected_timer_output)\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0;31m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Deferred inputs can be:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m    868\u001b[0m           \u001b[0mprocess_bundle_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m           \u001b[0mexpect_reads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m           \u001b[0mabort_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m           (result_future.is_done() and result_future.get().error)):\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_fn_api_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/runners/worker/data_plane.py\u001b[0m in \u001b[0;36minput_elements\u001b[0;34m(self, instruction_id, expected_inputs, abort_callback)\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m           \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceived\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "\n",
    "coders.registry.register_coder(Territory, coders.RowCoder)\n",
    "        \n",
    "class TerritorySplitClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname.title(), int(regionid))\n",
    "\n",
    "        \n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplitClass()).with_output_types(Territory)\n",
    "                    | 'SQL Territories' >> SqlTransform(\"\"\"SELECT regionid, count(*) as `cnt` FROM PCOLLECTION GROUP BY regionid\"\"\")\n",
    "                    | 'Map Territories for Print' >> beam.Map(lambda x : f'{x.regionid} - {x.cnt}')\n",
    "#                     | 'SQL Territories' >> SqlTransform(\"\"\"SELECT regionid, territoryid, territoryname FROM PCOLLECTION\"\"\")\n",
    "#                     | 'Map Territories for Print' >> beam.Map(lambda x : f'{x.regionid} - {x.territoryid} - {x.territoryname}')\n",
    "                    | beam.Map(print)\n",
    "                    )\n",
    "    \n",
    "#https://www.youtube.com/watch?v=zx4p-UNSmrA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac3991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d6654c",
   "metadata": {},
   "source": [
    "## BeamSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f517eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "TerritorySchema(territoryid=1581, territoryname='Westboro', regionid=1)\n",
      "TerritorySchema(territoryid=1730, territoryname='Bedford', regionid=1)\n",
      "TerritorySchema(territoryid=1833, territoryname='Georgetow', regionid=1)\n",
      "TerritorySchema(territoryid=2116, territoryname='Boston', regionid=1)\n",
      "TerritorySchema(territoryid=2139, territoryname='Cambridge', regionid=1)\n",
      "TerritorySchema(territoryid=2184, territoryname='Braintree', regionid=1)\n",
      "TerritorySchema(territoryid=2903, territoryname='Providence', regionid=1)\n",
      "TerritorySchema(territoryid=3049, territoryname='Hollis', regionid=3)\n",
      "TerritorySchema(territoryid=3801, territoryname='Portsmouth', regionid=3)\n",
      "TerritorySchema(territoryid=6897, territoryname='Wilton', regionid=1)\n",
      "TerritorySchema(territoryid=7960, territoryname='Morristown', regionid=1)\n",
      "TerritorySchema(territoryid=8837, territoryname='Edison', regionid=1)\n",
      "TerritorySchema(territoryid=10019, territoryname='New York', regionid=1)\n",
      "TerritorySchema(territoryid=10038, territoryname='New York', regionid=1)\n",
      "TerritorySchema(territoryid=11747, territoryname='Mellvile', regionid=1)\n",
      "TerritorySchema(territoryid=14450, territoryname='Fairport', regionid=1)\n",
      "TerritorySchema(territoryid=19428, territoryname='Philadelphia', regionid=3)\n",
      "TerritorySchema(territoryid=19713, territoryname='Neward', regionid=1)\n",
      "TerritorySchema(territoryid=20852, territoryname='Rockville', regionid=1)\n",
      "TerritorySchema(territoryid=27403, territoryname='Greensboro', regionid=1)\n",
      "TerritorySchema(territoryid=27511, territoryname='Cary', regionid=1)\n",
      "TerritorySchema(territoryid=29202, territoryname='Columbia', regionid=4)\n",
      "TerritorySchema(territoryid=30346, territoryname='Atlanta', regionid=4)\n",
      "TerritorySchema(territoryid=31406, territoryname='Savannah', regionid=4)\n",
      "TerritorySchema(territoryid=32859, territoryname='Orlando', regionid=4)\n",
      "TerritorySchema(territoryid=33607, territoryname='Tampa', regionid=4)\n",
      "TerritorySchema(territoryid=40222, territoryname='Louisville', regionid=1)\n",
      "TerritorySchema(territoryid=44122, territoryname='Beachwood', regionid=3)\n",
      "TerritorySchema(territoryid=45839, territoryname='Findlay', regionid=3)\n",
      "TerritorySchema(territoryid=48075, territoryname='Southfield', regionid=3)\n",
      "TerritorySchema(territoryid=48084, territoryname='Troy', regionid=3)\n",
      "TerritorySchema(territoryid=48304, territoryname='Bloomfield Hills', regionid=3)\n",
      "TerritorySchema(territoryid=53404, territoryname='Racine', regionid=3)\n",
      "TerritorySchema(territoryid=55113, territoryname='Roseville', regionid=3)\n",
      "TerritorySchema(territoryid=55439, territoryname='Minneapolis', regionid=3)\n",
      "TerritorySchema(territoryid=60179, territoryname='Hoffman Estates', regionid=2)\n",
      "TerritorySchema(territoryid=60601, territoryname='Chicago', regionid=2)\n",
      "TerritorySchema(territoryid=72716, territoryname='Bentonville', regionid=4)\n",
      "TerritorySchema(territoryid=75234, territoryname='Dallas', regionid=4)\n",
      "TerritorySchema(territoryid=78759, territoryname='Austin', regionid=4)\n",
      "TerritorySchema(territoryid=80202, territoryname='Denver', regionid=2)\n",
      "TerritorySchema(territoryid=80909, territoryname='Colorado Springs', regionid=2)\n",
      "TerritorySchema(territoryid=85014, territoryname='Phoenix', regionid=2)\n",
      "TerritorySchema(territoryid=85251, territoryname='Scottsdale', regionid=2)\n",
      "TerritorySchema(territoryid=90405, territoryname='Santa Monica', regionid=2)\n",
      "TerritorySchema(territoryid=94025, territoryname='Menlo Park', regionid=2)\n",
      "TerritorySchema(territoryid=94105, territoryname='San Francisco', regionid=2)\n",
      "TerritorySchema(territoryid=95008, territoryname='Campbell', regionid=2)\n",
      "TerritorySchema(territoryid=95054, territoryname='Santa Clara', regionid=2)\n",
      "TerritorySchema(territoryid=95060, territoryname='Santa Cruz', regionid=2)\n",
      "TerritorySchema(territoryid=98004, territoryname='Bellevue', regionid=2)\n",
      "TerritorySchema(territoryid=98052, territoryname='Redmond', regionid=2)\n",
      "TerritorySchema(territoryid=98104, territoryname='Seattle', regionid=2)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "#from collections import namedtuple\n",
    "from typing import NamedTuple\n",
    "from apache_beam import coders\n",
    "\n",
    "\n",
    "RegionSchema = namedtuple(\"RegionSchema\", (\"regionid\", \"regionname\"))\n",
    "#coders.registry.register_coder(RegionSchema, coders.RowCoder)\n",
    "class RegionSplitSchema(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield RegionSchema(int(regionid), regionname.title())\n",
    "\n",
    "#TerritorySchema = namedtuple(\"TerritorySchema\", (\"territoryid\", \"territoryname\", \"regionid\"))\n",
    "TerritorySchema = NamedTuple(\"TerritorySchema\", [(\"territoryid\", int), (\"territoryname\", str), (\"regionid\", int)])\n",
    "coders.registry.register_coder(TerritorySchema, coders.RowCoder)\n",
    "class TerritorySplitSchema(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield TerritorySchema(int(territoryid), territoryname.title(), int(regionid))\n",
    "\n",
    "        \n",
    "# class TerritorySplitNamedTuple(beam.DoFn):\n",
    "#     def process(self, element):\n",
    "#         territoryid, territoryname, regionid = element.split(',')\n",
    "#         yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "territoriesfilename = 'territories.csv'\n",
    "print('Start')\n",
    "with beam.Pipeline() as p:\n",
    "#     regions = (\n",
    "#               p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "#                 | 'Split Regions' >> beam.ParDo(RegionSplitSchema()).with_output_types(RegionSchema)\n",
    "#               )\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplitSchema()) #.with_output_types(TerritorySchema)\n",
    "#                    | beam.Map(lambda x: TerritorySchema(x.territoryid, x.territoryname, x.regionid)).with_output_types(TerritorySchema)\n",
    "#         Map(lambda x: PythonSchema(f_int32=x)).with_output_types(PythonSchema)\n",
    "#                     | 'Apply Territories Schema' >> beam.Map(lambda x : beam.Row(territoryid = int(x.territoryid)\n",
    "#                                                                                  , territoryname = str(x.territoryname)\n",
    "#                                                                                  , regionid = int(x.regionid)))\n",
    "#                    | 'Convert to Dictionary' >> beam.Map(lambda row : {\"regionid\" : row.regionid, \"territoryid\" : row.territoryid, \"territoryname\" : row.territoryname})\n",
    "#                     | SqlTransform(\"\"\"\n",
    "#                         SELECT regionid, territoryname as name, territoryid \n",
    "#                         FROM PCOLLECTION\n",
    "#                         \"\"\")\n",
    "#                    | 'Split Territories' >> beam.ParDo(TerritorySplitSchema()).with_output_types(TerritorySchema)\n",
    "#                     | SqlTransform(\"\"\"\n",
    "#                         SELECT regionid, count(*) as territories\n",
    "#                         FROM PCOLLECTION\n",
    "#                         GROUP BY regionID\n",
    "#                         ORDER BY territories DESC\n",
    "#                         \"\"\")\n",
    "#                    | 'Convert to dictionary' >> beam.Map(lambda row : {\"regionid\": row.regionid, \"territories\": row.territories})\n",
    "                    \n",
    "#             })\n",
    "                  )\n",
    "\n",
    "#     regions | 'Print regions' >> beam.Map(print)\n",
    "    territories | 'Print territories' >> beam.Map(print)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9904973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with beam.Pipeline() as pipeline:\n",
    "#     _ = (\n",
    "#         pipeline\n",
    "#         | beam.io.ReadFromPubSub(\n",
    "#             topic='projects/pubsub-public-data/topics/taxirides-realtime',\n",
    "#             timestamp_attribute=\"ts\").with_output_types(bytes)\n",
    "#         | \"Parse JSON payload\" >> beam.Map(json.loads)\n",
    "#         # Use beam.Row to create a schema-aware PCollection\n",
    "#         | \"Create beam Row\" >> beam.Map(\n",
    "#             lambda x: beam.Row(\n",
    "#                 ride_status=str(x['ride_status']),\n",
    "#                 passenger_count=int(x['passenger_count'])))\n",
    "#         # SqlTransform will computes result within an existing window\n",
    "#         | \"15s fixed windows\" >> beam.WindowInto(beam.window.FixedWindows(15))\n",
    "#         # Aggregate drop offs and pick ups that occur within each 15s window\n",
    "#         | SqlTransform(\n",
    "#             \"\"\"\n",
    "#              SELECT\n",
    "#                ride_status,\n",
    "#                COUNT(*) AS num_rides,\n",
    "#                SUM(passenger_count) AS total_passengers\n",
    "#              FROM PCOLLECTION\n",
    "#              WHERE NOT ride_status = 'enroute'\n",
    "#              GROUP BY ride_status\"\"\")\n",
    "#         # SqlTransform yields python objects with attributes corresponding to\n",
    "#         # the outputs of the query.\n",
    "#         # Collect those attributes, as well as window information, into a dict\n",
    "#         | \"Assemble Dictionary\" >> beam.Map(\n",
    "#             lambda row,\n",
    "#             window=beam.DoFn.WindowParam: {\n",
    "#                 \"ride_status\": row.ride_status,\n",
    "#                 \"num_rides\": row.num_rides,\n",
    "#                 \"total_passengers\": row.total_passengers,\n",
    "#                 \"window_start\": window.start.to_rfc3339(),\n",
    "#                 \"window_end\": window.end.to_rfc3339()\n",
    "#             })\n",
    "#         | \"Convert to JSON\" >> beam.Map(json.dumps)\n",
    "#         | \"UTF-8 encode\" >> beam.Map(lambda s: s.encode(\"utf-8\"))\n",
    "#         | beam.Map(print)\n",
    "#         #| beam.io.WriteToPubSub(topic=output_topic))\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   logging.getLogger().setLevel(logging.INFO)\n",
    "#   import argparse\n",
    "\n",
    "#   parser = argparse.ArgumentParser()\n",
    "#   parser.add_argument(\n",
    "#       '--output_topic',\n",
    "#       dest='output_topic',\n",
    "#       required=True,\n",
    "#       help=(\n",
    "#           'Cloud PubSub topic to write to (e.g. '\n",
    "#           'projects/my-project/topics/my-topic), must be created prior to '\n",
    "#           'running the pipeline.'))\n",
    "#   known_args, pipeline_args = parser.parse_known_args()\n",
    "\n",
    "#   run(known_args.output_topic, pipeline_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941584b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e3e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'North', 2: 'South'}\n"
     ]
    }
   ],
   "source": [
    "lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]\n",
    "lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "print(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade7df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsIter, AsSingleton, AsList, AsDict\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "from apache_beam.io import ReadFromAvro, WriteToAvro\n",
    "from collections import namedtuple\n",
    "from apache_beam import coders\n",
    "from apache_beam.typehints.decorators import with_output_types\n",
    "\n",
    "\n",
    "class Region:\n",
    "    def __init__(self, regionid, regionname):\n",
    "        self.regionid = regionid\n",
    "        self.regionname = regionname\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.regionid}|{self.regionname}'\n",
    "\n",
    "#     def encode(self, o):\n",
    "#         \"\"\"Encode to bytes with a trace that coder was used.\"\"\"\n",
    "#         # Our encoding prepends an 'x:' prefix.\n",
    "#         return b'x:%s' % o.encode('utf-8')\n",
    "\n",
    "#     def decode(self, s):\n",
    "#         # To decode, we strip off the prepended 'x:' prefix.\n",
    "#         s = s.decode('utf-8')\n",
    "#         #assert s[0:2] == 'x:'\n",
    "#         params = s[0:2].split('|')\n",
    "#         return Region(*params)\n",
    "\n",
    "#     def is_deterministic(self):\n",
    "#         # Since coded Player objects are used as keys below with\n",
    "#         # beam.CombinePerKey(sum), we require that this coder is deterministic\n",
    "#         # (i.e., two equivalent instances of the classes are encoded into the same\n",
    "#         # byte string) in order to guarantee consistent results.\n",
    "#         return True\n",
    "    \n",
    "class RegionSplitClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield Region(int(regionid), regionname.title())\n",
    "\n",
    "# class RegionCoder(coders.Coder):\n",
    "#   \"\"\"A custom coder for the RegionSchema\"\"\"\n",
    "#   def encode(self, o):\n",
    "#     \"\"\"Encode to bytes with a trace that coder was used.\"\"\"\n",
    "#     # Our encoding prepends an 'x:' prefix.\n",
    "#     return b'x:%s' % o.encode('utf-8')\n",
    "\n",
    "#   def decode(self, s):\n",
    "#     # To decode, we strip off the prepended 'x:' prefix.\n",
    "#     s = s.decode('utf-8')\n",
    "#     #assert s[0:2] == 'x:'\n",
    "#     params = s[0:2].split('|')\n",
    "#     return Region(*params)\n",
    "\n",
    "#   def is_deterministic(self):\n",
    "#     # Since coded Player objects are used as keys below with\n",
    "#     # beam.CombinePerKey(sum), we require that this coder is deterministic\n",
    "#     # (i.e., two equivalent instances of the classes are encoded into the same\n",
    "#     # byte string) in order to guarantee consistent results.\n",
    "#     return True\n",
    "# coders.registry.register_coder(Region, RegionCoder)\n",
    "\n",
    "# @with_output_types(typing.Tuple[Region, int])\n",
    "# def get_regions(descriptor):\n",
    "#   name, points = descriptor.split(',')\n",
    "#   return Player(name), int(points)\n",
    "\n",
    "\n",
    "# RegionSchema = namedtuple(\"RegionSchema\", (\"regionid\", \"regionname\"))\n",
    "# class RegionSplitSchema(beam.DoFn):\n",
    "#     def process(self, element):\n",
    "#         regionid, regionname = element.split(',')\n",
    "#         yield RegionSchema(int(regionid), regionname.title())\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname.title()}\n",
    "\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "#        yield (int(regionid), (territoryid, territoryname.title())) \n",
    "        \n",
    "                \n",
    "def lookup_region(left, right):\n",
    "    territoryid, territoryname, regionid = left\n",
    "    yield territoryid, territoryname, regionid\n",
    "#    yield (territoryid, territorynme, regionid, right.get(regionid, 'No Region'))\n",
    "\n",
    "\n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]):\n",
    "#        yield element\n",
    "        territoryid, territoryname, regionid = element\n",
    "        lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "        yield(territoryid, territoryname, regionid, lookup.get(regionid, 'No Region'))\n",
    "# #        yield (int(regionid), (territoryid, territoryname.title())) \n",
    "\n",
    "\n",
    "# def dummy(element):\n",
    "#     return element\n",
    "# #     regionid = element[0]\n",
    "# #     territoryid, territoryname = element[1]\n",
    "# #     return (territoryid, territoryname, regionid)\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "          #| 'Split Regions' >> beam.ParDo(RegionSplitClass())\n",
    "#          | 'Print Regions' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "#     regions = {1:\"North\", 2:\"South\", 3:\"East\", 4:\"West\"}\n",
    "#     regions = p | 'Create Regions' >> beam.Create([(1, 'North'), (2, 'South')])\n",
    "\n",
    "    \n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "#          | 'Print Territories' >> beam.Map(print)\n",
    "    )\n",
    "    \n",
    "    join = (\n",
    "        territories\n",
    "          #| 'Lookup Region' >> beam.Map(dummy)\n",
    "#          | 'Lookup Region' >> beam.Map(lookup_region, right = beam.pvalue.AsList(regions))\n",
    "#        | beam.ParDo(LookupRegion())\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "        | beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Beam 2.25.0 for Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
