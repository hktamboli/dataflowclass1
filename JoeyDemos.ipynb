{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11547544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var import_html = () => {\n",
       "          ['https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html'].forEach(href => {\n",
       "            var link = document.createElement('link');\n",
       "            link.rel = 'import'\n",
       "            link.href = href;\n",
       "            document.head.appendChild(link);\n",
       "          });\n",
       "        }\n",
       "        if ('import' in document.createElement('link')) {\n",
       "          import_html();\n",
       "        } else {\n",
       "          var webcomponentScript = document.createElement('script');\n",
       "          webcomponentScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js';\n",
       "          webcomponentScript.type = 'text/javascript';\n",
       "          webcomponentScript.onload = function(){\n",
       "            import_html();\n",
       "          };\n",
       "          document.head.appendChild(webcomponentScript);\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE\n",
      "TWO\n",
      "THREE\n",
      "FOUR\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | 'Create' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | 'Uppercase' >> beam.Map(str.upper)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441cf5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Word_Count.ipynb\t\t       Visualize_Data.ipynb\n",
      "02-Streaming_Word_Count.ipynb\t       products.json\n",
      "03-Streaming_NYC_Taxi_Ride_Data.ipynb  regions.csv\n",
      "Dataflow_Word_Count.ipynb\t       regions.out-00000-of-00001\n",
      "JoeyDemos.ipynb\t\t\t       territories.avro\n",
      "Use_GPUs_with_Apache_Beam.ipynb\n"
     ]
    }
   ],
   "source": [
    "#! gsutil cp gs://qwiklabs-gcp-02-7b5be618aa6e/* .\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaceec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'EASTERN')\n",
      "(20, 'WESTERN')\n",
      "(30, 'NORTHERN')\n",
      "(40, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "filename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(filename)\n",
    "          | 'Split' >> beam.Map(lambda x : tuple(x.split(',')))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]) * 10, x[1].upper()))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e622a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(regionid, regionname)] # ParDo's need to return a list\n",
    "        yield (regionid, regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "# using a ParDo and DoFn instead of a Map\n",
    "filename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(filename)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    records | 'Write' >> WriteToText('regions.out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ebac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'Eastern')\n",
      "('2', 'Western')\n",
      "('3', 'Northern')\n",
      "('4', 'Southern')\n"
     ]
    }
   ],
   "source": [
    "! cat regions.out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d935f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n"
     ]
    },
    {
     "ename": "BeamIOError",
     "evalue": "Match operation failed with exceptions {'gs://dataflowclass1-bucket/regions.csv': HttpForbiddenError('HttpError accessing <https://www.googleapis.com/storage/v1/b/dataflowclass1-bucket/o/regions.csv?alt=json>: response: <{\\'x-guploader-uploadid\\': \\'ABg5-UzAM1SOZOrl9b_Po2CsZygbcsMmlbQej79BuI-X_awFRYqPPcfTE43HGNhsDR1-gQipv_JnluiV3r4vPaJM5-c\\', \\'content-type\\': \\'application/json; charset=UTF-8\\', \\'date\\': \\'Sat, 17 Apr 2021 21:02:20 GMT\\', \\'vary\\': \\'Origin, X-Origin\\', \\'cache-control\\': \\'no-cache, no-store, max-age=0, must-revalidate\\', \\'expires\\': \\'Mon, 01 Jan 1990 00:00:00 GMT\\', \\'pragma\\': \\'no-cache\\', \\'content-length\\': \\'430\\', \\'server\\': \\'UploadServer\\', \\'status\\': \\'403\\'}>, content <{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"537607295389-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.\",\\n    \"errors\": [\\n      {\\n        \"message\": \"537607295389-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.\",\\n        \"domain\": \"global\",\\n        \"reason\": \"forbidden\"\\n      }\\n    ]\\n  }\\n}\\n>')}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBeamIOError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-228712b3063c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-228712b3063c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(argv, save_main_session)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m# The pipeline will be run on exiting the with block.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_options\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'Read'\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mReadFromText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'Split'\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParDo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegionSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0muppercase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'Uppercase'\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/textio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_pattern, min_bundle_size, compression_type, strip_trailing_newlines, coder, validate, skip_header_lines, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         skip_header_lines=skip_header_lines)\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/textio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_pattern, min_bundle_size, compression_type, strip_trailing_newlines, coder, buffer_size, validate, skip_header_lines, header_processor_fns)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mmin_bundle_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mcompression_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         validate=validate)\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strip_trailing_newlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_trailing_newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/filebasedsource.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_pattern, min_bundle_size, compression_type, splittable, validate)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_splittable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_accessible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/options/value_provider.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_accessible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRuntimeValueProviderError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not accessible'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/filebasedsource.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# Limit the responses as we only want to check if something exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mmatch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No files found based on the file pattern %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/filesystems.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(patterns, limits)\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mfilesystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apache-beam-2.25.0/packages/beam/sdks/python/apache_beam/io/filesystem.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, patterns, limits)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mBeamIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Match operation failed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBeamIOError\u001b[0m: Match operation failed with exceptions {'gs://dataflowclass1-bucket/regions.csv': HttpForbiddenError('HttpError accessing <https://www.googleapis.com/storage/v1/b/dataflowclass1-bucket/o/regions.csv?alt=json>: response: <{\\'x-guploader-uploadid\\': \\'ABg5-UzAM1SOZOrl9b_Po2CsZygbcsMmlbQej79BuI-X_awFRYqPPcfTE43HGNhsDR1-gQipv_JnluiV3r4vPaJM5-c\\', \\'content-type\\': \\'application/json; charset=UTF-8\\', \\'date\\': \\'Sat, 17 Apr 2021 21:02:20 GMT\\', \\'vary\\': \\'Origin, X-Origin\\', \\'cache-control\\': \\'no-cache, no-store, max-age=0, must-revalidate\\', \\'expires\\': \\'Mon, 01 Jan 1990 00:00:00 GMT\\', \\'pragma\\': \\'no-cache\\', \\'content-length\\': \\'430\\', \\'server\\': \\'UploadServer\\', \\'status\\': \\'403\\'}>, content <{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"537607295389-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.\",\\n    \"errors\": [\\n      {\\n        \"message\": \"537607295389-compute@developer.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.\",\\n        \"domain\": \"global\",\\n        \"reason\": \"forbidden\"\\n      }\\n    ]\\n  }\\n}\\n>')}"
     ]
    }
   ],
   "source": [
    "\"\"\"A template to import the default package and parse the arguments\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "\n",
    "#from past.builtins import unicode\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(regionid, regionname)] # ParDo's need to return a list\n",
    "        yield (regionid, regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "def run(argv=None, save_main_session=True):\n",
    "  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--input',\n",
    "      dest='input',\n",
    "      default='gs://dataflowclass1-bucket/regions.csv',\n",
    "      help='Input file to process.')\n",
    "  parser.add_argument(\n",
    "      '--output',\n",
    "      dest='output',\n",
    "      default = 'gs://dataflowclass1-bucket/regions_output',      \n",
    "      help='Output file to write results to.')\n",
    "  known_args, pipeline_args = parser.parse_known_args(argv)\n",
    "\n",
    "  # We use the save_main_session option because one or more DoFn's in this\n",
    "  # workflow rely on global context (e.g., a module imported at module level).\n",
    "  pipeline_options = PipelineOptions(pipeline_args)\n",
    "  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n",
    "\n",
    "  # The pipeline will be run on exiting the with block.\n",
    "  with beam.Pipeline(options=pipeline_options) as p:\n",
    "    lines = p | 'Read' >> ReadFromText(known_args.input)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    uppercase = records | 'Uppercase' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "    uppercase | 'Write' >> WriteToText(known_args.output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  logging.getLogger().setLevel(logging.INFO)\n",
    "  run()\n",
    "\n",
    "\n",
    "# using a ParDo and DoFn instead of a Map\n",
    "filename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(filename)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    records | 'Write' >> WriteToText('regions2.out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1596d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Beam 2.25.0 for Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
