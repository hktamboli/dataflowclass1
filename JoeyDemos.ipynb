{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9457e4c3",
   "metadata": {},
   "source": [
    "## Simple transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752e8cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var import_html = () => {\n",
       "          ['https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html'].forEach(href => {\n",
       "            var link = document.createElement('link');\n",
       "            link.rel = 'import'\n",
       "            link.href = href;\n",
       "            document.head.appendChild(link);\n",
       "          });\n",
       "        }\n",
       "        if ('import' in document.createElement('link')) {\n",
       "          import_html();\n",
       "        } else {\n",
       "          var webcomponentScript = document.createElement('script');\n",
       "          webcomponentScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js';\n",
       "          webcomponentScript.type = 'text/javascript';\n",
       "          webcomponentScript.onload = function(){\n",
       "            import_html();\n",
       "          };\n",
       "          document.head.appendChild(webcomponentScript);\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE\n",
      "TWO\n",
      "THREE\n",
      "FOUR\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | 'Create' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | 'Uppercase' >> beam.Map(str.upper)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970bba1",
   "metadata": {},
   "source": [
    "## The pipe | is actually just an operator overload to call the apply method of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41535267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "Three\n",
      "Four\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = p | 'Create' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "        lines2 = (\n",
    "            p.apply(beam.Map(str.title), lines, 'titlecase')\n",
    "             .apply(beam.Map(print))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd48769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JoeyDemos.ipynb       leftjoin.py    simple3-dataflow.sh  territories.csv\n",
      "README.md\t      products.json  simple3-local.sh\t  territories.py\n",
      "aggregate1.py\t      regions.csv    simple3.py\t\t  wordcount-dataflow.sh\n",
      "aggregate2.py\t      simple1.py     simple3_custom.py\t  wordcount.py\n",
      "dataflow_template.py  simple2.py     territories.avro\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55030ad0",
   "metadata": {},
   "source": [
    "## Read from CSV and use Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749dc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'EASTERN')\n",
      "(20, 'WESTERN')\n",
      "(30, 'NORTHERN')\n",
      "(40, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.Map(lambda x : tuple(x.split(',')))\n",
    "          | 'Transform' >> beam.Map(lambda x : (int(x[0]) * 10, x[1].upper()))\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a85d6f",
   "metadata": {},
   "source": [
    "## Read from CSV and use ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fbcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.ParDo(RegionSplit())\n",
    "          | 'Write' >> WriteToText('regions.out')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf875cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Eastern')\n",
      "(2, 'Western')\n",
      "(3, 'Northern')\n",
      "(4, 'Southern')\n"
     ]
    }
   ],
   "source": [
    "! cat regions.out*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61722a62",
   "metadata": {},
   "source": [
    "## Template showing a full program that can read the command line args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05947a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A template to import the default package and parse the arguments\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "\n",
    "#from past.builtins import unicode\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(regionid, regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "def run(argv=None, save_main_session=True):\n",
    "  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--input',\n",
    "      dest='input',\n",
    "      default='gs://dataflowclass1-bucket/regions.csv',\n",
    "      help='Input file to process.')\n",
    "  parser.add_argument(\n",
    "      '--output',\n",
    "      dest='output',\n",
    "      default = 'gs://dataflowclass1-bucket/regions_output',      \n",
    "      help='Output file to write results to.')\n",
    "  known_args, pipeline_args = parser.parse_known_args(argv)\n",
    "\n",
    "  # We use the save_main_session option because one or more DoFn's in this\n",
    "  # workflow rely on global context (e.g., a module imported at module level).\n",
    "  pipeline_options = PipelineOptions(pipeline_args)\n",
    "  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n",
    "\n",
    "  # The pipeline will be run on exiting the with block.\n",
    "  with beam.Pipeline(options=pipeline_options) as p:\n",
    "    lines = p | 'Read' >> ReadFromText(known_args.input)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    uppercase = records | 'Uppercase' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "    uppercase | 'Write' >> WriteToText(known_args.output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  logging.getLogger().setLevel(logging.INFO)\n",
    "  run()\n",
    "\n",
    "\n",
    "filename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(filename)\n",
    "    records = lines | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    records | 'Write' >> WriteToText('regions2.out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204204a2",
   "metadata": {},
   "source": [
    "## Example of how to create a split ParDo with multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0565b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evens\n",
      "Odds\n",
      "(1, 'Eastern', 'Odd')\n",
      "(2, 'Western', 'Even')\n",
      "(3, 'Northern', 'Odd')\n",
      "(4, 'Southern', 'Even')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "class OddEvenRegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        if int(regionid) % 2 == 0:\n",
    "            yield pvalue.TaggedOutput('Even', (int(regionid), regionname, 'Even'))\n",
    "        else:\n",
    "            yield pvalue.TaggedOutput('Odd', (int(regionid), regionname, 'Odd'))\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    lines = p | 'Read' >> ReadFromText(regionsfilename)\n",
    "    evens, odds = lines | 'Split' >> beam.ParDo(OddEvenRegionSplit()).with_outputs(\"Even\", \"Odd\")\n",
    "    \n",
    "    print('Evens')\n",
    "    evens | 'Print Evens' >> beam.Map(print)\n",
    "\n",
    "    print('Odds')\n",
    "    odds | 'Print Odds' >> beam.Map(print)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf43205",
   "metadata": {},
   "source": [
    "## Example of branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70937bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'EASTERN')\n",
      "(20, 'WESTERN')\n",
      "(30, 'NORTHERN')\n",
      "(40, 'SOUTHERN')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        #return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Split' >> beam.ParDo(RegionSplit())\n",
    "    )\n",
    "    # Branch 1\n",
    "    (regions \n",
    "         | 'Lowercase regions' >> beam.Map(lambda x : (x[0] * 100, x[1].lower()))\n",
    "         | 'Write' >> WriteToText('regions2.out')\n",
    "    )\n",
    "    \n",
    "    (regions \n",
    "         | 'Uppercase regions' >> beam.Map(lambda x : (x[0] * 10, x[1].upper()))\n",
    "         | 'Print' >> beam.Map(print)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2503bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 'eastern')\n",
      "(200, 'western')\n",
      "(300, 'northern')\n",
      "(400, 'southern')\n"
     ]
    }
   ],
   "source": [
    "! cat regions2*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab7977",
   "metadata": {},
   "source": [
    "## WithKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4839c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01581', 'Westboro', '1')\n",
      "1\n",
      "('1', ('01581', 'Westboro', '1'))\n",
      "('01730', 'Bedford', '1')\n",
      "1\n",
      "('1', ('01730', 'Bedford', '1'))\n",
      "('01833', 'Georgetow', '1')\n",
      "1\n",
      "('1', ('01833', 'Georgetow', '1'))\n",
      "('02116', 'Boston', '1')\n",
      "1\n",
      "('1', ('02116', 'Boston', '1'))\n",
      "('02139', 'Cambridge', '1')\n",
      "1\n",
      "('1', ('02139', 'Cambridge', '1'))\n",
      "('02184', 'Braintree', '1')\n",
      "1\n",
      "('1', ('02184', 'Braintree', '1'))\n",
      "('02903', 'Providence', '1')\n",
      "1\n",
      "('1', ('02903', 'Providence', '1'))\n",
      "('03049', 'Hollis', '3')\n",
      "3\n",
      "('3', ('03049', 'Hollis', '3'))\n",
      "('03801', 'Portsmouth', '3')\n",
      "3\n",
      "('3', ('03801', 'Portsmouth', '3'))\n",
      "('06897', 'Wilton', '1')\n",
      "1\n",
      "('1', ('06897', 'Wilton', '1'))\n",
      "('07960', 'Morristown', '1')\n",
      "1\n",
      "('1', ('07960', 'Morristown', '1'))\n",
      "('08837', 'Edison', '1')\n",
      "1\n",
      "('1', ('08837', 'Edison', '1'))\n",
      "('10019', 'New York', '1')\n",
      "1\n",
      "('1', ('10019', 'New York', '1'))\n",
      "('10038', 'New York', '1')\n",
      "1\n",
      "('1', ('10038', 'New York', '1'))\n",
      "('11747', 'Mellvile', '1')\n",
      "1\n",
      "('1', ('11747', 'Mellvile', '1'))\n",
      "('14450', 'Fairport', '1')\n",
      "1\n",
      "('1', ('14450', 'Fairport', '1'))\n",
      "('19428', 'Philadelphia', '3')\n",
      "3\n",
      "('3', ('19428', 'Philadelphia', '3'))\n",
      "('19713', 'Neward', '1')\n",
      "1\n",
      "('1', ('19713', 'Neward', '1'))\n",
      "('20852', 'Rockville', '1')\n",
      "1\n",
      "('1', ('20852', 'Rockville', '1'))\n",
      "('27403', 'Greensboro', '1')\n",
      "1\n",
      "('1', ('27403', 'Greensboro', '1'))\n",
      "('27511', 'Cary', '1')\n",
      "1\n",
      "('1', ('27511', 'Cary', '1'))\n",
      "('29202', 'Columbia', '4')\n",
      "4\n",
      "('4', ('29202', 'Columbia', '4'))\n",
      "('30346', 'Atlanta', '4')\n",
      "4\n",
      "('4', ('30346', 'Atlanta', '4'))\n",
      "('31406', 'Savannah', '4')\n",
      "4\n",
      "('4', ('31406', 'Savannah', '4'))\n",
      "('32859', 'Orlando', '4')\n",
      "4\n",
      "('4', ('32859', 'Orlando', '4'))\n",
      "('33607', 'Tampa', '4')\n",
      "4\n",
      "('4', ('33607', 'Tampa', '4'))\n",
      "('40222', 'Louisville', '1')\n",
      "1\n",
      "('1', ('40222', 'Louisville', '1'))\n",
      "('44122', 'Beachwood', '3')\n",
      "3\n",
      "('3', ('44122', 'Beachwood', '3'))\n",
      "('45839', 'Findlay', '3')\n",
      "3\n",
      "('3', ('45839', 'Findlay', '3'))\n",
      "('48075', 'Southfield', '3')\n",
      "3\n",
      "('3', ('48075', 'Southfield', '3'))\n",
      "('48084', 'Troy', '3')\n",
      "3\n",
      "('3', ('48084', 'Troy', '3'))\n",
      "('48304', 'Bloomfield Hills', '3')\n",
      "3\n",
      "('3', ('48304', 'Bloomfield Hills', '3'))\n",
      "('53404', 'Racine', '3')\n",
      "3\n",
      "('3', ('53404', 'Racine', '3'))\n",
      "('55113', 'Roseville', '3')\n",
      "3\n",
      "('3', ('55113', 'Roseville', '3'))\n",
      "('55439', 'Minneapolis', '3')\n",
      "3\n",
      "('3', ('55439', 'Minneapolis', '3'))\n",
      "('60179', 'Hoffman Estates', '2')\n",
      "2\n",
      "('2', ('60179', 'Hoffman Estates', '2'))\n",
      "('60601', 'Chicago', '2')\n",
      "2\n",
      "('2', ('60601', 'Chicago', '2'))\n",
      "('72716', 'Bentonville', '4')\n",
      "4\n",
      "('4', ('72716', 'Bentonville', '4'))\n",
      "('75234', 'Dallas', '4')\n",
      "4\n",
      "('4', ('75234', 'Dallas', '4'))\n",
      "('78759', 'Austin', '4')\n",
      "4\n",
      "('4', ('78759', 'Austin', '4'))\n",
      "('80202', 'Denver', '2')\n",
      "2\n",
      "('2', ('80202', 'Denver', '2'))\n",
      "('80909', 'Colorado Springs', '2')\n",
      "2\n",
      "('2', ('80909', 'Colorado Springs', '2'))\n",
      "('85014', 'Phoenix', '2')\n",
      "2\n",
      "('2', ('85014', 'Phoenix', '2'))\n",
      "('85251', 'Scottsdale', '2')\n",
      "2\n",
      "('2', ('85251', 'Scottsdale', '2'))\n",
      "('90405', 'Santa Monica', '2')\n",
      "2\n",
      "('2', ('90405', 'Santa Monica', '2'))\n",
      "('94025', 'Menlo Park', '2')\n",
      "2\n",
      "('2', ('94025', 'Menlo Park', '2'))\n",
      "('94105', 'San Francisco', '2')\n",
      "2\n",
      "('2', ('94105', 'San Francisco', '2'))\n",
      "('95008', 'Campbell', '2')\n",
      "2\n",
      "('2', ('95008', 'Campbell', '2'))\n",
      "('95054', 'Santa Clara', '2')\n",
      "2\n",
      "('2', ('95054', 'Santa Clara', '2'))\n",
      "('95060', 'Santa Cruz', '2')\n",
      "2\n",
      "('2', ('95060', 'Santa Cruz', '2'))\n",
      "('98004', 'Bellevue', '2')\n",
      "2\n",
      "('2', ('98004', 'Bellevue', '2'))\n",
      "('98052', 'Redmond', '2')\n",
      "2\n",
      "('2', ('98052', 'Redmond', '2'))\n",
      "('98104', 'Seattle', '2')\n",
      "2\n",
      "('2', ('98104', 'Seattle', '2'))\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield (territoryid, territoryname, regionid)\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText(territoriesfilename)\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x[2])\n",
    "#                    | 'With Keys Manually' >> beam.Map(lambda x : (x[2], x))\n",
    "                  )\n",
    "    territories | 'Print KV' >> beam.Map(print)\n",
    "    territories | beam.util.Keys() | 'Print Keys' >> beam.Map(print)\n",
    "    territories | beam.util.Values() | 'Print Values' >> beam.Map(print)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ec95a",
   "metadata": {},
   "source": [
    "## GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33cd2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', [('01581', 'Westboro', '1'), ('01730', 'Bedford', '1'), ('01833', 'Georgetow', '1'), ('02116', 'Boston', '1'), ('02139', 'Cambridge', '1'), ('02184', 'Braintree', '1'), ('02903', 'Providence', '1'), ('06897', 'Wilton', '1'), ('07960', 'Morristown', '1'), ('08837', 'Edison', '1'), ('10019', 'New York', '1'), ('10038', 'New York', '1'), ('11747', 'Mellvile', '1'), ('14450', 'Fairport', '1'), ('19713', 'Neward', '1'), ('20852', 'Rockville', '1'), ('27403', 'Greensboro', '1'), ('27511', 'Cary', '1'), ('40222', 'Louisville', '1')])\n",
      "('3', [('03049', 'Hollis', '3'), ('03801', 'Portsmouth', '3'), ('19428', 'Philadelphia', '3'), ('44122', 'Beachwood', '3'), ('45839', 'Findlay', '3'), ('48075', 'Southfield', '3'), ('48084', 'Troy', '3'), ('48304', 'Bloomfield Hills', '3'), ('53404', 'Racine', '3'), ('55113', 'Roseville', '3'), ('55439', 'Minneapolis', '3')])\n",
      "('4', [('29202', 'Columbia', '4'), ('30346', 'Atlanta', '4'), ('31406', 'Savannah', '4'), ('32859', 'Orlando', '4'), ('33607', 'Tampa', '4'), ('72716', 'Bentonville', '4'), ('75234', 'Dallas', '4'), ('78759', 'Austin', '4')])\n",
      "('2', [('60179', 'Hoffman Estates', '2'), ('60601', 'Chicago', '2'), ('80202', 'Denver', '2'), ('80909', 'Colorado Springs', '2'), ('85014', 'Phoenix', '2'), ('85251', 'Scottsdale', '2'), ('90405', 'Santa Monica', '2'), ('94025', 'Menlo Park', '2'), ('94105', 'San Francisco', '2'), ('95008', 'Campbell', '2'), ('95054', 'Santa Clara', '2'), ('95060', 'Santa Cruz', '2'), ('98004', 'Bellevue', '2'), ('98052', 'Redmond', '2'), ('98104', 'Seattle', '2')])\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield (territoryid, territoryname, regionid)\n",
    "\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "                    | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x[2])\n",
    "                    | 'Group Territories' >> beam.GroupByKey() \n",
    "                    | 'Print Territories' >> beam.Map(print)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005554ad",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e86c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "alpha\n",
      "beta\n",
      "gamma\n",
      "delta\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines1 = p | 'Create 1' >> beam.Create(['one', 'two', 'three', 'four'])\n",
    "    lines2 = p | 'Create 2' >> beam.Create(['alpha', 'beta', 'gamma', 'delta'])\n",
    "\n",
    "    merged = ((lines1, lines2) | 'Merge PCollections' >> beam.Flatten())\n",
    "    merged | beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5dc05",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c76fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 90)\n",
      "('b', 70)\n",
      "('c', 50)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', 10), ('a', 20), ('b', 30), ('b', 40), ('c', 50), ('a', 60)])\n",
    "          | 'Combine' >> beam.CombinePerKey(sum)\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665ddd2",
   "metadata": {},
   "source": [
    "## Custom Combine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ccd286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (6, 90, 3, 30.0), 'b': (4, 70, 2, 35.0), 'c': (5, 50, 1, 50.0)}\n"
     ]
    }
   ],
   "source": [
    "#mport apache_beam as beam\n",
    "\n",
    "class CustomCombine(beam.CombineFn):\n",
    "\n",
    "  def create_accumulator(self):\n",
    "    return {}\n",
    "\n",
    "  def add_input(self, accumulator, input):\n",
    "    k, v = input\n",
    "    x, y, z = accumulator.get(k, (0, 0, 0))\n",
    "\n",
    "    # take the max for the first element of the tuple and sum the second element and count for the third\n",
    "    accumulator[k] = (v[0] if v[0] > x else x, y + v[1], z + 1)\n",
    "    return accumulator\n",
    "\n",
    "  def merge_accumulators(self, accumulators):\n",
    "    merged = {}\n",
    "    for accum in accumulators:\n",
    "      for k, v in accum.items():\n",
    "        x, y, z = merged.get(k, (0, 0, 0))\n",
    "        merged[k] = (v[0] if v[0] > x else x, y + v[1], z + v[2])\n",
    "    return merged\n",
    "\n",
    "  def extract_output(self, accumulator):\n",
    "    # return the max, the sum, the count and the average for the key\n",
    "    return {k : (v[0], v[1], v[2], v[1]/v[2]) for k, v in accumulator.items()}\n",
    "    return accumulator\n",
    "    \n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', (1, 10)), ('a', (2, 20)), ('b', (3, 30)), ('b', (4, 40)), ('c', (5, 50)), ('a', (6, 60))])\n",
    "          | 'Combine' >> beam.CombineGlobally(CustomCombine())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68167c",
   "metadata": {},
   "source": [
    "## Map vs FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44450b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strawberry\n",
      "Carrot\n",
      "Eggplant\n",
      "Tomato\n",
      "Potato\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  plants = (\n",
    "      pipeline\n",
    "      | 'Gardening plants' >> beam.Create(['Strawberry,Carrot,Eggplant','Tomato,Potato'])\n",
    "      | 'Split words' >> beam.Map(lambda x : x.split(','))\n",
    "#      | 'Split words' >> beam.FlatMap(lambda x : x.split(','))\n",
    "      | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27230201",
   "metadata": {},
   "source": [
    "## Side Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17599a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1581, 'Westboro', 1, 'NORTH')\n",
      "(1730, 'Bedford', 1, 'NORTH')\n",
      "(1833, 'Georgetow', 1, 'NORTH')\n",
      "(2116, 'Boston', 1, 'NORTH')\n",
      "(2139, 'Cambridge', 1, 'NORTH')\n",
      "(2184, 'Braintree', 1, 'NORTH')\n",
      "(2903, 'Providence', 1, 'NORTH')\n",
      "(3049, 'Hollis', 3, 'EAST')\n",
      "(3801, 'Portsmouth', 3, 'EAST')\n",
      "(6897, 'Wilton', 1, 'NORTH')\n",
      "(7960, 'Morristown', 1, 'NORTH')\n",
      "(8837, 'Edison', 1, 'NORTH')\n",
      "(10019, 'New York', 1, 'NORTH')\n",
      "(10038, 'New York', 1, 'NORTH')\n",
      "(11747, 'Mellvile', 1, 'NORTH')\n",
      "(14450, 'Fairport', 1, 'NORTH')\n",
      "(19428, 'Philadelphia', 3, 'EAST')\n",
      "(19713, 'Neward', 1, 'NORTH')\n",
      "(20852, 'Rockville', 1, 'NORTH')\n",
      "(27403, 'Greensboro', 1, 'NORTH')\n",
      "(27511, 'Cary', 1, 'NORTH')\n",
      "(29202, 'Columbia', 4, 'WEST')\n",
      "(30346, 'Atlanta', 4, 'WEST')\n",
      "(31406, 'Savannah', 4, 'WEST')\n",
      "(32859, 'Orlando', 4, 'WEST')\n",
      "(33607, 'Tampa', 4, 'WEST')\n",
      "(40222, 'Louisville', 1, 'NORTH')\n",
      "(44122, 'Beachwood', 3, 'EAST')\n",
      "(45839, 'Findlay', 3, 'EAST')\n",
      "(48075, 'Southfield', 3, 'EAST')\n",
      "(48084, 'Troy', 3, 'EAST')\n",
      "(48304, 'Bloomfield Hills', 3, 'EAST')\n",
      "(53404, 'Racine', 3, 'EAST')\n",
      "(55113, 'Roseville', 3, 'EAST')\n",
      "(55439, 'Minneapolis', 3, 'EAST')\n",
      "(60179, 'Hoffman Estates', 2, 'SOUTH')\n",
      "(60601, 'Chicago', 2, 'SOUTH')\n",
      "(72716, 'Bentonville', 4, 'WEST')\n",
      "(75234, 'Dallas', 4, 'WEST')\n",
      "(78759, 'Austin', 4, 'WEST')\n",
      "(80202, 'Denver', 2, 'SOUTH')\n",
      "(80909, 'Colorado Springs', 2, 'SOUTH')\n",
      "(85014, 'Phoenix', 2, 'SOUTH')\n",
      "(85251, 'Scottsdale', 2, 'SOUTH')\n",
      "(90405, 'Santa Monica', 2, 'SOUTH')\n",
      "(94025, 'Menlo Park', 2, 'SOUTH')\n",
      "(94105, 'San Francisco', 2, 'SOUTH')\n",
      "(95008, 'Campbell', 2, 'SOUTH')\n",
      "(95054, 'Santa Clara', 2, 'SOUTH')\n",
      "(95060, 'Santa Cruz', 2, 'SOUTH')\n",
      "(98004, 'Bellevue', 2, 'SOUTH')\n",
      "(98052, 'Redmond', 2, 'SOUTH')\n",
      "(98104, 'Seattle', 2, 'SOUTH')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsSingleton, AsDict\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritorySplitTuple(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, uppercase = 0):\n",
    "        lookuptable = {1:'North', 2:'South', 3:'East', 4:'West'}\n",
    "        territoryid, territoryname, regionid = element\n",
    "        region = lookuptable.get(regionid, 'No Region')\n",
    "        if uppercase == 1:\n",
    "            region = region.upper()\n",
    "        yield(territoryid, territoryname, regionid, region)\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplitTuple())\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "#        | beam.ParDo(LookupRegion())\n",
    "        | beam.ParDo(LookupRegion(), uppercase = 1 ) \n",
    "        #beam.pvalue.AsSingleton(int(1)))\n",
    "        | 'Print Loopup' >> beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c0e142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1581, 'Westboro', 1, 'Eastern')\n",
      "(1730, 'Bedford', 1, 'Eastern')\n",
      "(1833, 'Georgetow', 1, 'Eastern')\n",
      "(2116, 'Boston', 1, 'Eastern')\n",
      "(2139, 'Cambridge', 1, 'Eastern')\n",
      "(2184, 'Braintree', 1, 'Eastern')\n",
      "(2903, 'Providence', 1, 'Eastern')\n",
      "(3049, 'Hollis', 3, 'Northern')\n",
      "(3801, 'Portsmouth', 3, 'Northern')\n",
      "(6897, 'Wilton', 1, 'Eastern')\n",
      "(7960, 'Morristown', 1, 'Eastern')\n",
      "(8837, 'Edison', 1, 'Eastern')\n",
      "(10019, 'New York', 1, 'Eastern')\n",
      "(10038, 'New York', 1, 'Eastern')\n",
      "(11747, 'Mellvile', 1, 'Eastern')\n",
      "(14450, 'Fairport', 1, 'Eastern')\n",
      "(19428, 'Philadelphia', 3, 'Northern')\n",
      "(19713, 'Neward', 1, 'Eastern')\n",
      "(20852, 'Rockville', 1, 'Eastern')\n",
      "(27403, 'Greensboro', 1, 'Eastern')\n",
      "(27511, 'Cary', 1, 'Eastern')\n",
      "(29202, 'Columbia', 4, 'Southern')\n",
      "(30346, 'Atlanta', 4, 'Southern')\n",
      "(31406, 'Savannah', 4, 'Southern')\n",
      "(32859, 'Orlando', 4, 'Southern')\n",
      "(33607, 'Tampa', 4, 'Southern')\n",
      "(40222, 'Louisville', 1, 'Eastern')\n",
      "(44122, 'Beachwood', 3, 'Northern')\n",
      "(45839, 'Findlay', 3, 'Northern')\n",
      "(48075, 'Southfield', 3, 'Northern')\n",
      "(48084, 'Troy', 3, 'Northern')\n",
      "(48304, 'Bloomfield Hills', 3, 'Northern')\n",
      "(53404, 'Racine', 3, 'Northern')\n",
      "(55113, 'Roseville', 3, 'Northern')\n",
      "(55439, 'Minneapolis', 3, 'Northern')\n",
      "(60179, 'Hoffman Estates', 2, 'Western')\n",
      "(60601, 'Chicago', 2, 'Western')\n",
      "(72716, 'Bentonville', 4, 'Southern')\n",
      "(75234, 'Dallas', 4, 'Southern')\n",
      "(78759, 'Austin', 4, 'Southern')\n",
      "(80202, 'Denver', 2, 'Western')\n",
      "(80909, 'Colorado Springs', 2, 'Western')\n",
      "(85014, 'Phoenix', 2, 'Western')\n",
      "(85251, 'Scottsdale', 2, 'Western')\n",
      "(90405, 'Santa Monica', 2, 'Western')\n",
      "(94025, 'Menlo Park', 2, 'Western')\n",
      "(94105, 'San Francisco', 2, 'Western')\n",
      "(95008, 'Campbell', 2, 'Western')\n",
      "(95054, 'Santa Clara', 2, 'Western')\n",
      "(95060, 'Santa Cruz', 2, 'Western')\n",
      "(98004, 'Bellevue', 2, 'Western')\n",
      "(98052, 'Redmond', 2, 'Western')\n",
      "(98104, 'Seattle', 2, 'Western')\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsList\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname.title()}\n",
    "\n",
    "class TerritorySplitTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]):\n",
    "        territoryid, territoryname, regionid = element\n",
    "        lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "        yield(territoryid, territoryname, regionid, lookup.get(regionid, 'No Region'))\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "#          | 'Print Regions' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplitTuple())\n",
    "#          | 'Print Territories' >> beam.Map(print)\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "        | 'Print Loopup' >> beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b067a7",
   "metadata": {},
   "source": [
    "## Simulate an Outer Join with CoGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ec9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'territoryid': 1581, 'territoryname': 'Westboro', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 1730, 'territoryname': 'Bedford', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 1833, 'territoryname': 'Georgetow', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2116, 'territoryname': 'Boston', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2139, 'territoryname': 'Cambridge', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2184, 'territoryname': 'Braintree', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 2903, 'territoryname': 'Providence', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 6897, 'territoryname': 'Wilton', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 7960, 'territoryname': 'Morristown', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 8837, 'territoryname': 'Edison', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 10019, 'territoryname': 'New York', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 10038, 'territoryname': 'New York', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 11747, 'territoryname': 'Mellvile', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 14450, 'territoryname': 'Fairport', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 19713, 'territoryname': 'Neward', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 20852, 'territoryname': 'Rockville', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 27403, 'territoryname': 'Greensboro', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 27511, 'territoryname': 'Cary', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 40222, 'territoryname': 'Louisville', 'regionid': 1, 'regionname': 'Eastern'}\n",
      "{'territoryid': 3049, 'territoryname': 'Hollis', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 3801, 'territoryname': 'Portsmouth', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 19428, 'territoryname': 'Philadelphia', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 44122, 'territoryname': 'Beachwood', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 45839, 'territoryname': 'Findlay', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48075, 'territoryname': 'Southfield', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48084, 'territoryname': 'Troy', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 48304, 'territoryname': 'Bloomfield Hills', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 53404, 'territoryname': 'Racine', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 55113, 'territoryname': 'Roseville', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 55439, 'territoryname': 'Minneapolis', 'regionid': 3, 'regionname': 'Northern'}\n",
      "{'territoryid': 29202, 'territoryname': 'Columbia', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 30346, 'territoryname': 'Atlanta', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 31406, 'territoryname': 'Savannah', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 32859, 'territoryname': 'Orlando', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 33607, 'territoryname': 'Tampa', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 72716, 'territoryname': 'Bentonville', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 75234, 'territoryname': 'Dallas', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 78759, 'territoryname': 'Austin', 'regionid': 4, 'regionname': 'Southern'}\n",
      "{'territoryid': 60179, 'territoryname': 'Hoffman Estates', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 60601, 'territoryname': 'Chicago', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 80202, 'territoryname': 'Denver', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 80909, 'territoryname': 'Colorado Springs', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 85014, 'territoryname': 'Phoenix', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 85251, 'territoryname': 'Scottsdale', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 90405, 'territoryname': 'Santa Monica', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 94025, 'territoryname': 'Menlo Park', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 94105, 'territoryname': 'San Francisco', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95008, 'territoryname': 'Campbell', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95054, 'territoryname': 'Santa Clara', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 95060, 'territoryname': 'Santa Cruz', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98004, 'territoryname': 'Bellevue', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98052, 'territoryname': 'Redmond', 'regionid': 2, 'regionname': 'Western'}\n",
      "{'territoryid': 98104, 'territoryname': 'Seattle', 'regionid': 2, 'regionname': 'Western'}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid':int(regionid), 'regionname':regionname.title()}\n",
    "\n",
    "class TerritorySplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "\n",
    "class UnnestCoGrouped(beam.DoFn):\n",
    "    def process(self, item, child_pipeline, parent_pipeline):\n",
    "        k, v = item\n",
    "        child_dict = v[child_pipeline]\n",
    "        parent_dict = v[parent_pipeline]\n",
    "        for child in child_dict:\n",
    "            try:\n",
    "                child.update(parent_dict[0])\n",
    "                yield child\n",
    "            except IndexError:\n",
    "                yield child\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    def __init__(self, parent_pipeline_name, parent_data, parent_key, child_pipeline_name, child_data,  child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_data = parent_data\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_data = child_data\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def _format_as_common_key_tuple(child_dict, child_key):\n",
    "            return (child_dict[child_key], child_dict)\n",
    "\n",
    "        return ({\n",
    "                pipeline_name: pcol1 | f'Convert to ({self.parent_key} = {self.child_key}, object) for {pipeline_name}' \n",
    "                >> beam.Map(_format_as_common_key_tuple, self.child_key)\n",
    "                for (pipeline_name, pcol1) in pcols.items()}\n",
    "                | f'CoGroupByKeey {pcols.keys()}' >> beam.CoGroupByKey()\n",
    "                | 'Unnest Cogrouped' >> beam.ParDo(UnnestCoGrouped(), self.child_pipeline_name, self.parent_pipeline_name)\n",
    "        )\n",
    "        \n",
    "regionsfilename = 'regions.csv'\n",
    "territoriesfilename = 'territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "                #| 'Print Regions' >> beam.Map(print)\n",
    "              )\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplitDict())\n",
    "                    #| 'Print Territories' >> beam.Map(print)\n",
    "                  )\n",
    "\n",
    "    leftjoin = {'regions':regions, 'territories':territories} | LeftJoin('regions', regions, 'regionid', 'territories', territories, 'regionid')\n",
    "    leftjoin | 'print left join' >> beam.Map(print)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0ba3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25593594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7574900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a48d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e40a408c",
   "metadata": {},
   "source": [
    "## BeamSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ab96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "from collections import namedtuple\n",
    "from apache_beam import coders\n",
    "\n",
    "\n",
    "RegionSchema = namedtuple(\"RegionSchema\", (\"regionid\", \"regionname\"))\n",
    "#coders.registry.register_coder(RegionSchema, coders.RowCoder)\n",
    "class RegionSplitSchema(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield RegionSchema(int(regionid), regionname.title())\n",
    "\n",
    "TerritorySchema = namedtuple(\"TerritorySchema\", (\"territoryid\", \"territoryname\", \"regionid\"))\n",
    "#coders.registry.register_coder(TerritorySchema, coders.RowCoder)\n",
    "class TerritorySplitSchema(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield TerritorySchema(int(territoryid), territoryname.title(), int(regionid))\n",
    "\n",
    "        \n",
    "# class TerritorySplitNamedTuple(beam.DoFn):\n",
    "#     def process(self, element):\n",
    "#         territoryid, territoryname, regionid = element.split(',')\n",
    "#         yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "\n",
    "regionsfilename = 'regions.csv'\n",
    "territoriesfilename = 'territories.csv'\n",
    "print('Start')\n",
    "with beam.Pipeline() as p:\n",
    "#     regions = (\n",
    "#               p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "#                 | 'Split Regions' >> beam.ParDo(RegionSplitSchema()).with_output_types(RegionSchema)\n",
    "#               )\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Split Territories' >> beam.ParDo(TerritorySplitSchema())\n",
    "                    | 'Apply Territories Schema' >> beam.Map(lambda x : beam.Row(territoryid = int(x.territoryid)\n",
    "                                                                                 , territoryname = str(x.territoryname)\n",
    "                                                                                 , regionid = int(x.regionid)))\n",
    "#                    | 'Convert to Dictionary' >> beam.Map(lambda row : {\"regionid\" : row.regionid, \"territoryid\" : row.territoryid, \"territoryname\" : row.territoryname})\n",
    "                    | SqlTransform(\"\"\"\n",
    "                        SELECT regionid, UPPER(territoryname) as name, territoryid \n",
    "                        FROM PCOLLECTION\n",
    "                        \"\"\")\n",
    "#                    | 'Split Territories' >> beam.ParDo(TerritorySplitSchema()).with_output_types(TerritorySchema)\n",
    "#                     | SqlTransform(\"\"\"\n",
    "#                         SELECT regionid, count(*) as territories\n",
    "#                         FROM PCOLLECTION\n",
    "#                         GROUP BY regionID\n",
    "#                         ORDER BY territories DESC\n",
    "#                         \"\"\")\n",
    "#                    | 'Convert to dictionary' >> beam.Map(lambda row : {\"regionid\": row.regionid, \"territories\": row.territories})\n",
    "                    \n",
    "#             })\n",
    "                  )\n",
    "\n",
    "#     regions | 'Print regions' >> beam.Map(print)\n",
    "    territories | 'Print territories' >> beam.Map(print)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with beam.Pipeline() as pipeline:\n",
    "#     _ = (\n",
    "#         pipeline\n",
    "#         | beam.io.ReadFromPubSub(\n",
    "#             topic='projects/pubsub-public-data/topics/taxirides-realtime',\n",
    "#             timestamp_attribute=\"ts\").with_output_types(bytes)\n",
    "#         | \"Parse JSON payload\" >> beam.Map(json.loads)\n",
    "#         # Use beam.Row to create a schema-aware PCollection\n",
    "#         | \"Create beam Row\" >> beam.Map(\n",
    "#             lambda x: beam.Row(\n",
    "#                 ride_status=str(x['ride_status']),\n",
    "#                 passenger_count=int(x['passenger_count'])))\n",
    "#         # SqlTransform will computes result within an existing window\n",
    "#         | \"15s fixed windows\" >> beam.WindowInto(beam.window.FixedWindows(15))\n",
    "#         # Aggregate drop offs and pick ups that occur within each 15s window\n",
    "#         | SqlTransform(\n",
    "#             \"\"\"\n",
    "#              SELECT\n",
    "#                ride_status,\n",
    "#                COUNT(*) AS num_rides,\n",
    "#                SUM(passenger_count) AS total_passengers\n",
    "#              FROM PCOLLECTION\n",
    "#              WHERE NOT ride_status = 'enroute'\n",
    "#              GROUP BY ride_status\"\"\")\n",
    "#         # SqlTransform yields python objects with attributes corresponding to\n",
    "#         # the outputs of the query.\n",
    "#         # Collect those attributes, as well as window information, into a dict\n",
    "#         | \"Assemble Dictionary\" >> beam.Map(\n",
    "#             lambda row,\n",
    "#             window=beam.DoFn.WindowParam: {\n",
    "#                 \"ride_status\": row.ride_status,\n",
    "#                 \"num_rides\": row.num_rides,\n",
    "#                 \"total_passengers\": row.total_passengers,\n",
    "#                 \"window_start\": window.start.to_rfc3339(),\n",
    "#                 \"window_end\": window.end.to_rfc3339()\n",
    "#             })\n",
    "#         | \"Convert to JSON\" >> beam.Map(json.dumps)\n",
    "#         | \"UTF-8 encode\" >> beam.Map(lambda s: s.encode(\"utf-8\"))\n",
    "#         | beam.Map(print)\n",
    "#         #| beam.io.WriteToPubSub(topic=output_topic))\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   logging.getLogger().setLevel(logging.INFO)\n",
    "#   import argparse\n",
    "\n",
    "#   parser = argparse.ArgumentParser()\n",
    "#   parser.add_argument(\n",
    "#       '--output_topic',\n",
    "#       dest='output_topic',\n",
    "#       required=True,\n",
    "#       help=(\n",
    "#           'Cloud PubSub topic to write to (e.g. '\n",
    "#           'projects/my-project/topics/my-topic), must be created prior to '\n",
    "#           'running the pipeline.'))\n",
    "#   known_args, pipeline_args = parser.parse_known_args()\n",
    "\n",
    "#   run(known_args.output_topic, pipeline_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcd2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f71c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'North', 2: 'South'}\n"
     ]
    }
   ],
   "source": [
    "lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]\n",
    "lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "print(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b363b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb266f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsIter, AsSingleton, AsList, AsDict\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "from apache_beam.io import ReadFromAvro, WriteToAvro\n",
    "from collections import namedtuple\n",
    "from apache_beam import coders\n",
    "from apache_beam.typehints.decorators import with_output_types\n",
    "\n",
    "\n",
    "class Region:\n",
    "    def __init__(self, regionid, regionname):\n",
    "        self.regionid = regionid\n",
    "        self.regionname = regionname\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.regionid}|{self.regionname}'\n",
    "\n",
    "#     def encode(self, o):\n",
    "#         \"\"\"Encode to bytes with a trace that coder was used.\"\"\"\n",
    "#         # Our encoding prepends an 'x:' prefix.\n",
    "#         return b'x:%s' % o.encode('utf-8')\n",
    "\n",
    "#     def decode(self, s):\n",
    "#         # To decode, we strip off the prepended 'x:' prefix.\n",
    "#         s = s.decode('utf-8')\n",
    "#         #assert s[0:2] == 'x:'\n",
    "#         params = s[0:2].split('|')\n",
    "#         return Region(*params)\n",
    "\n",
    "#     def is_deterministic(self):\n",
    "#         # Since coded Player objects are used as keys below with\n",
    "#         # beam.CombinePerKey(sum), we require that this coder is deterministic\n",
    "#         # (i.e., two equivalent instances of the classes are encoded into the same\n",
    "#         # byte string) in order to guarantee consistent results.\n",
    "#         return True\n",
    "    \n",
    "class RegionSplitClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield Region(int(regionid), regionname.title())\n",
    "\n",
    "# class RegionCoder(coders.Coder):\n",
    "#   \"\"\"A custom coder for the RegionSchema\"\"\"\n",
    "#   def encode(self, o):\n",
    "#     \"\"\"Encode to bytes with a trace that coder was used.\"\"\"\n",
    "#     # Our encoding prepends an 'x:' prefix.\n",
    "#     return b'x:%s' % o.encode('utf-8')\n",
    "\n",
    "#   def decode(self, s):\n",
    "#     # To decode, we strip off the prepended 'x:' prefix.\n",
    "#     s = s.decode('utf-8')\n",
    "#     #assert s[0:2] == 'x:'\n",
    "#     params = s[0:2].split('|')\n",
    "#     return Region(*params)\n",
    "\n",
    "#   def is_deterministic(self):\n",
    "#     # Since coded Player objects are used as keys below with\n",
    "#     # beam.CombinePerKey(sum), we require that this coder is deterministic\n",
    "#     # (i.e., two equivalent instances of the classes are encoded into the same\n",
    "#     # byte string) in order to guarantee consistent results.\n",
    "#     return True\n",
    "# coders.registry.register_coder(Region, RegionCoder)\n",
    "\n",
    "# @with_output_types(typing.Tuple[Region, int])\n",
    "# def get_regions(descriptor):\n",
    "#   name, points = descriptor.split(',')\n",
    "#   return Player(name), int(points)\n",
    "\n",
    "\n",
    "# RegionSchema = namedtuple(\"RegionSchema\", (\"regionid\", \"regionname\"))\n",
    "# class RegionSplitSchema(beam.DoFn):\n",
    "#     def process(self, element):\n",
    "#         regionid, regionname = element.split(',')\n",
    "#         yield RegionSchema(int(regionid), regionname.title())\n",
    "\n",
    "class RegionSplitDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname.title()}\n",
    "\n",
    "\n",
    "class TerritorySplit(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "#        yield (int(regionid), (territoryid, territoryname.title())) \n",
    "        \n",
    "                \n",
    "def lookup_region(left, right):\n",
    "    territoryid, territoryname, regionid = left\n",
    "    yield territoryid, territoryname, regionid\n",
    "#    yield (territoryid, territorynme, regionid, right.get(regionid, 'No Region'))\n",
    "\n",
    "\n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]):\n",
    "#        yield element\n",
    "        territoryid, territoryname, regionid = element\n",
    "        lookup = {e['regionid'] : e['regionname'] for e in lookuptable }\n",
    "        yield(territoryid, territoryname, regionid, lookup.get(regionid, 'No Region'))\n",
    "# #        yield (int(regionid), (territoryid, territoryname.title())) \n",
    "\n",
    "\n",
    "# def dummy(element):\n",
    "#     return element\n",
    "# #     regionid = element[0]\n",
    "# #     territoryid, territoryname = element[1]\n",
    "# #     return (territoryid, territoryname, regionid)\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Split Regions' >> beam.ParDo(RegionSplitDict())\n",
    "          #| 'Split Regions' >> beam.ParDo(RegionSplitClass())\n",
    "#          | 'Print Regions' >> beam.Map(print)\n",
    "    )\n",
    "\n",
    "#     regions = {1:\"North\", 2:\"South\", 3:\"East\", 4:\"West\"}\n",
    "#     regions = p | 'Create Regions' >> beam.Create([(1, 'North'), (2, 'South')])\n",
    "\n",
    "    \n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Split Territories' >> beam.ParDo(TerritorySplit())\n",
    "#          | 'Print Territories' >> beam.Map(print)\n",
    "    )\n",
    "    \n",
    "    join = (\n",
    "        territories\n",
    "          #| 'Lookup Region' >> beam.Map(dummy)\n",
    "#          | 'Lookup Region' >> beam.Map(lookup_region, right = beam.pvalue.AsList(regions))\n",
    "#        | beam.ParDo(LookupRegion())\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "        | beam.Map(print)\n",
    "    )\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Beam 2.25.0 for Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
